{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_x9N13AKyiu",
    "outputId": "5ad708e8-5f11-4f04-9857-8dc40b59044b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m733.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    " # Need to install from github, for staying up-to-date with the latest developments.\n",
    "  # reason: if a bug has been fixed since the last official release but a new release hasn’t been rolled out yet\n",
    "%pip -q install git+https://github.com/huggingface/transformers\n",
    "# %pip -q install transformers\n",
    "%pip -q install -U datasets\n",
    "%pip -q install -U loralib\n",
    "%pip -q install -U sentencepiece\n",
    "%pip -q install -U bitsandbytes\n",
    "%pip -q install -U accelerate\n",
    "%pip -q install -U einops\n",
    "%pip -q install -U langchain\n",
    "%pip -q install -U huggingface_hub\n",
    "%pip -q install -U chromadb\n",
    "%pip -q install -U PyPDF2\n",
    "%pip -q install -U pypdf\n",
    "%pip -q install -U sentence-transformers\n",
    "%pip -q install -U FlagEmbedding\n",
    "%pip -q install -U InstructorEmbedding\n",
    "\n",
    "# %pip -q install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZEstQqUUp7C"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYev9nnWDRZy"
   },
   "source": [
    "###Download the PDFs as external resourses\n",
    "\n",
    "This part show that we can load a link and extract many pdf files, even the ones with misinformation included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H63WS5G-DRCo",
    "outputId": "6539af8c-013c-4fd8-e63a-c3155b6e73e7"
   },
   "outputs": [],
   "source": [
    "!wget -O PDFPapers.zip your_path_to_the_zip_file\n",
    "!unzip -q PDFPapers.zip -d papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "3a12ca6ac76641529c4714ca1901a57b",
      "62713568ffb74392bb83cbe2bc4ddfa4",
      "f64aaf5f3e10461fbb407a596b2d9cb2",
      "be202f12608542dbb59110e48e8ed7f3",
      "d924801ca37e4790abffec0451509824",
      "9402ac70d917481cb33ca9cd950a80dd",
      "8bc776651d29481197c859a440dd14d7",
      "b04c1b4e1a24478281e8ca22b4cf6e8a",
      "535ffec7938e4ff3ac941768b4dff1ac",
      "abf211c42aa8430b839473fcfe6f2fe5",
      "017bb7d3258246079f68316952bba230",
      "f9f1f9de43f34bebbd9e56007fef48b4",
      "26c32b8194954325ae28a9ebc0cabc39",
      "09d6014f8d8d4fffb0bbd45fa771170c",
      "229456cdfceb4042b305579a31c26704",
      "fca86ad563634cc9992724cc868528d7",
      "d022ce6ae972406aaacd0a5fd8677769",
      "3df56cdeca9345d9b2ed0f664f0c975c",
      "90564ec207f6426786fcc429378d4959",
      "5d2a287a27eb45698b01e22d58c8b6af",
      "1f8ee0b81a764ad8a5bf267dbb46c666",
      "081b16fce37e41248e8cbc51a31730ad",
      "bbdbfccc2e8b4168b8f87fff78f508cc",
      "fcf5ac563be64dba8271f6ca855db1a6",
      "e6938566ba694345acca363cafc140b1",
      "e0320b96d838421fbfc081ee96a5c1c3",
      "536dbff8b134445493df81fded6b2b3e",
      "c8e798fe3d184ff2b0c574c70855ce76",
      "d24a0469f3a440c6b4f8c0bea159543f",
      "1d890c0163374ea4bd37efe69f918f7e",
      "9be3709eb608458aa895aaf56485e3e7",
      "fb4a391dc95d404a814635f576c95fd5"
     ]
    },
    "id": "hebEJuaGT_Fb",
    "outputId": "0cec12b4-44ae-4ff2-ed07-0950d4c6eb25"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a12ca6ac76641529c4714ca1901a57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpC_r9cT6E74"
   },
   "source": [
    "### Frameworks/Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRswMcgcT_JP"
   },
   "outputs": [],
   "source": [
    "# HuggingFace\n",
    "# import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "\n",
    "# LangChain\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# embeddings\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# 'mixedbread-ai/mxbai-embed-large-v1' embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "# to create chain\n",
    "from langchain.schema import prompt\n",
    "\n",
    "# formatting the response\n",
    "# import json\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O74ftbYf6MKt"
   },
   "source": [
    "### Loading Model, and its Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545,
     "referenced_widgets": [
      "ea1264d4dfd04c92aa49963bd45f4657",
      "c9033eae67f64950ad66210e21d38f06",
      "d60780bd3c0e45658d9fa9918cf67495",
      "a3a41b2fab7f4a40a6e79de61ea79ea7",
      "04a30812666b4d25ba52bb95e65ebe01",
      "df187b6ffef94d8dbf6eff59c6664ac8",
      "696139dd70e14effb09beed25b6c9dce",
      "024afc1c7c53444f98952a1d0567ba99",
      "fe05473196f54d6d893f81190cb03106",
      "ab6abf9284a04a2c87894b11bc316c41",
      "7c1c692d316c4074bb2d67630a5379b0",
      "b42611fd7b1d4235a0192e638a01bd70",
      "ad752c901a5f4b709ac380127311a907",
      "e96f1cf63a5c43a29f8e4070e4d2c981",
      "b71457d5c7b847c5928a47c331db3f6c",
      "b16af085e17e46c994a640eec94e7f66",
      "8cc9b8739aed455886d6bdd5af6def66",
      "7cc272dd43a34b159d9c6efd2d12a12d",
      "275cec8b3ec6431b85c15cd21902a924",
      "d5141402fb2545abaf8ef162a62a7972",
      "bcc3118e85254be7aa0348af5407e1de",
      "408933246daa421ea85229be88220356",
      "e2531668afb04b7abdc89a0e271a46d2",
      "aff52811af324aa883e99ba00d6b2093",
      "28a51f46fff747bebc7941fe1a651cd3",
      "ce7fde73103f4db0ac8e457478e460be",
      "baaa6229a0a94544bcee0592538655bb",
      "04dcbfb8de6e4f1195d4d587bbb38443",
      "7575bf01755b4b31bc7725a98d7bc2c9",
      "15706616ea504bc29cec1bf1d8419a30",
      "7eac30f901bb4df9ae83d2c4f8ae9fca",
      "3ae25353d9214ca8a94748eb27f677a1",
      "bb6d3d12e9a04c5f8c2c4ff724bb8a2f",
      "1891b63efdde45f29740958e8f801a09",
      "1398733b0952408c8fcb09de6ff41724",
      "3ee788552f644a01967d338c0b3c35d7",
      "eff596c781cb49b18eb06e549dd0e5f6",
      "7cd91e4219c74049a584efa937acf701",
      "713a931b441247cab0a93f22c372fade",
      "1ee42d7544814f5687eb05728b9f702b",
      "d47276c296bd470b856ba6fb3a9d9c11",
      "c5bceb4289844c71bcaaa6b21f0b59c4",
      "457d65bc00bd466eab43816f8439e320",
      "82a0638fd3444de0a06ee00456177c1a",
      "97053e3ff42b44cc8534382b3b13206e",
      "1ef1eec0dd5e47bea1bcea6f9034f021",
      "aae60e3e71e2435fae1025fae4c18288",
      "430638a4dbf14252b9a4ee94a9e7d4a4",
      "c58770fb5b6547aea8c863d9f5295ccd",
      "5f0821e07ddc41e2adb07c5323b169e2",
      "e244474294cc486fa649eb90b4cd633b",
      "8ddc3835c87c406a949101259fe238e7",
      "e5c5e484dae7433bb36acdbb2ca807e6",
      "ce38825a1c4540af933f4e5ef1bc16e5",
      "8e0ea91c80ca466d880b8af03b0f170e",
      "8ac5af7924b04565893a7470c66f27c5",
      "0563b9909b4d4797ab569bbdbb1f6aec",
      "5332663318864679b969e094197871e8",
      "c5701ec915e147f895f7dc1ffe385e4e",
      "c7058fe0829a4c928072e6516c3184c6",
      "de2a0d0c35d94351a56596c1dea14f40",
      "2addadb89a18443192b0180cadea75ed",
      "028a560b68fd4280b496c67c326cdb78",
      "98cd1bfbb7254fae9404ac870ab9d324",
      "49d91597fe6044da9d3642cc8930f93c",
      "83d83c03818841a1a50ec54f7967ec8a",
      "b963713bb0c54eeb89c4bae07f69dc69",
      "aaacb878704c47d8930d8fafda03eb4a",
      "88404c84874a42e8841d9a3464e147ad",
      "3876b135bd1647feb2a18c024051cb10",
      "f73de0e914214591b1eec8c79dea6b61",
      "43f6ba43bff5476582698472f9555f24",
      "0c08c1261a59472a9bd387472957b4ea",
      "c654149e39cd430cab0425513704c924",
      "4a1542f333a34a9bb83454776efc98e3",
      "955dba34b0b64377b250d3dd5e4a0b5d",
      "a33796f57e8642f1a994dd4b35162850",
      "583e6d1fd990468c8331dbdfa7557b63",
      "9acfac341cc14cbcb88bf6a62546b026",
      "3d434a71b4d6467dba2802590f7d32ef",
      "d9cc02ef0d8a48a8be1abbd89242f3c2",
      "1c78b061ba144f98bb6cce1bde3fb474",
      "57693568ba184a0eaed1eb4d2ed0d96a",
      "cd059062b89140dfb99771bf52c4e66f",
      "f9868ffcced842acb57be30b202649d8",
      "25f6af5cceca42d799000a518ea770f9",
      "199012c0c40f477d934f54efe3ad3357",
      "93fe193d320049ef8b64e7b544c97f63",
      "9ca18a67e97a4263a299f14f0b5b35b0",
      "b3a76956729a40d78f9453e5ed426f19",
      "3e43256b6e334e3fad60f19af2be048d",
      "5a58cf536fba456aae42644cece78ba7",
      "c0be785eca7c42a6863bb45f91bd0cce",
      "ebc2bcb28dd24d3abf69cbf0445e0cd9",
      "d63f7c5715f4466ea2faac8469e1b9d3",
      "1300784b96984a8eb7a1cca571a5f023",
      "d8e2fcbc6e9e4fd5ae9c7eb4a636c662",
      "ff02416027c746e7931c9239f9279380",
      "8a12845b17fe420d9f2ea33561049b5a",
      "7b06fe1665654870ab643866ebec1462",
      "973ad6ee8b924412878fde6a43c5514e",
      "2b6071112897414da7b667cb0b8538c4",
      "a78851c1f45549658ac83b084bf7ab2e",
      "9d51117f768c41e5b96e51fb484cb34d",
      "d2938e4401144d7d9ae41210f506a85b",
      "58d47803029b47d6b0822036c73d1f37",
      "f7d2bdf65a094186b9672f725b5768c3",
      "3546f16388b041bfbeaf164e52a71c22",
      "1bdb58a2c30b4ba9a52a84ad222c91ef",
      "e46a2af177c14f6ea0f2c7142c078cb6",
      "bce334785f9449d782120bd30c876b1d",
      "e5bdde31aee5438ca41786fc312e9e55",
      "40896aab4d49469ba8ad6d63ecc4658c",
      "02ded56529414887976dc2918cd1d2b3",
      "047e8d7819df44449e57fbb9acb1ba35",
      "77f3feea020e4f8bbb08acbeb5a6c8cf",
      "2902e3edc0054b6e8ed58a7a10a9755b",
      "c6f24e8061dd44cd90e8e954147ab2fa",
      "89aa0186f88e450b934ca809adf54658",
      "316f9af751f5477ea2e85c56c663c744",
      "566c5b7bafae4cb39d247f67551f4110"
     ]
    },
    "id": "IhXWIiuvT_M_",
    "outputId": "193e4b89-ca55-4b1e-e025-38a1859e53b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:758: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1264d4dfd04c92aa49963bd45f4657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42611fd7b1d4235a0192e638a01bd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2531668afb04b7abdc89a0e271a46d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1891b63efdde45f29740958e8f801a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97053e3ff42b44cc8534382b3b13206e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac5af7924b04565893a7470c66f27c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b963713bb0c54eeb89c4bae07f69dc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583e6d1fd990468c8331dbdfa7557b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca18a67e97a4263a299f14f0b5b35b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b06fe1665654870ab643866ebec1462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce334785f9449d782120bd30c876b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer that correspond to the model, used to convert text to a fromat that model can understand(tokenization) and back to the text(detokenization)\n",
    "base_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name,\n",
    "                                          use_auth_token = True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name,\n",
    "                                             device_map = 'auto',\n",
    "                                             torch_dtype = torch.float16,\n",
    "                                            #  use_auth_token = True,\n",
    "                                             load_in_8bit=True # 8bit/4bit\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htViqv4RV_5J"
   },
   "source": [
    "###Building Pipeline\n",
    "\n",
    "“Max Length” controls the overall length of the response.(restricts the total length (input + output))\n",
    "\n",
    "“Max New Tokens” specifically limits the tokens generated beyond the input. It ensures that the output aligns with your desired length while considering the context provided.(specifically limits the tokens generated beyond the input)\n",
    "\n",
    "\n",
    "https://medium.com/@developer.yasir.pk/understanding-the-controllable-parameters-to-run-inference-your-large-language-model-**30643bb46434**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2HNTY9vT_QQ"
   },
   "outputs": [],
   "source": [
    "# To create a text generation pipeline\n",
    "\n",
    "# pipelie(): The pipeline is a high-level utility that simplifies the usage of Transformer models for various tasks, such as text generation\n",
    "# do_sample: Enables sampling, this allows the model to generate text probabilistically rather than deterministically. Sampling can lead to more varied and interesting outputs\n",
    "# top_k: Sample from the top k most likely next tokens at each step, This helps in reducing the randomness of the output, providing a balance between creativity and coherence\n",
    "# eos_token_id: specify the token that indicates the end of a sequence, Allowing the model to determine when to stop generating further tokens\n",
    "\n",
    "# \"text-classification\"\n",
    "pipe = pipeline(\"text-generation\", # specify the task for the pipeline\n",
    "               model = model,\n",
    "               tokenizer = tokenizer,\n",
    "              #  torch_dtype = torch.bfloat16, # data type for PyTorch tensors\n",
    "                max_length=1024,\n",
    "                temperature=0.1,\n",
    "                top_p=0.95,\n",
    "                repetition_penalty=1.15,\n",
    "                max_new_tokens=512,\n",
    "              #  device_map = 'auto',\n",
    "              #  do_sample = True,\n",
    "              #  top_k = 30,\n",
    "              #  num_return_sequences = 1, # only one text sequence should be return for each input\n",
    "              #  eos_token_id = tokenizer.eos_token_id\n",
    "               )\n",
    "hf_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V0ozFbAT_Tt",
    "outputId": "c968ce5b-384e-4ecf-876b-c9b1d3767fe2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who are you?\n",
      "\n",
      "Answer: I am the LORD, your God.\n",
      "\n",
      "Exodus 3:14-15 (NIV)\n",
      "\n",
      "In this passage, Moses is tending his father-in-law's flock when he comes across a burning bush that is not consumed by flames. When he approaches the bush to investigate, God reveals himself to Moses in a theophany - a visible manifestation of God's presence. In response to Moses' question about who he is, God identifies himself as \"I AM WHO I AM,\" or Yahweh, which means \"he who exists forever.\" This name emphasizes God's eternal nature and highlights his unique identity as the one who has always existed and will always exist.\n",
      "\n",
      "The phrase \"I AM\" is also significant because it echoes the Hebrew verb \"to be,\" which is used throughout the Bible to express existence or reality. By using this verb, God is affirming his own existence and emphasizing that he is the source of all being and reality.\n",
      "\n",
      "In addition to its literal meaning, the name \"Yahweh\" has been interpreted in various ways throughout history. Some have seen it as a title that reflects God's self-sufficiency and independence, while others have understood it as a name that conveys God's covenant relationship with his people. Regardless of how it is interpreted, however, the name \"Yahweh\" remains an important part of Jewish and Christian theology, symbolizing God's power, wisdom, and love for his creation.\n"
     ]
    }
   ],
   "source": [
    "# print(hf_llm(\"Who are you?\"))\n",
    "# pipe(\"Who are you?\")\n",
    "\n",
    "# sequences = pipe(\"Who are you\")\n",
    "# for seq in sequences:\n",
    "#   print(f\"reuslts: {seq['generated_text']}\")\n",
    "\n",
    "# pipe(\"I'm in a good mood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC1tACg3T_XI"
   },
   "outputs": [],
   "source": [
    "# tokenzier.vocab_size\n",
    "# tokenizer.all_special_tokens\n",
    "# tokenizer.all_special_ids\n",
    "# tokenizer(['<unk>'])\n",
    "# tokenizer(['<SYS>\\n'])\n",
    "# tokenizer.decode([1, 14816, 29903, 6778, 13]) # output: '<s>SYS>>\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuLgUewuJjVP"
   },
   "source": [
    "###Setting up Langchain to retrieve PDFs\n",
    "\n",
    "Load and process PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hibbLkK-Jigw",
    "outputId": "6953e230-051d-4fe3-8409-bb2281441db4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and process a single text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('/content/papers', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2bpEn5yKUlG",
    "outputId": "fe876d7f-4054-408c-8187-60f049c59e98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the text into chunks\n",
    "# chunk_overlap: if we get one idea between two chunks of text,we want it to be overlapped, so we can actually get that in one full chunk by itself.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh-wOyQIcnK4"
   },
   "source": [
    "###Text Embeddings\n",
    "\n",
    "MTEB is a massive benchmark for measuring the performance of text embedding models on diverse embedding tasks\n",
    "\n",
    "https://huggingface.co/spaces/mteb/leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MllQCHjnfji1"
   },
   "source": [
    "###BAAI/bge-large-en-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "81b50221a50c4fe085dd04b93da05a5b",
      "5b7dedbfcb2841c7926c57c2e5b5174a",
      "0d74258894604e68a6d21a5ecce32eac",
      "21658bf2e96d4691878b9c192cbde886",
      "b404237a418a40c8ac93ba53b899a087",
      "650141acc22647a8b6ad394c05a212a9",
      "61f05a1aa1e54bbfbf5d8ec268d77ce0",
      "f6100da1428c4bc29f0908e24edd8f8c",
      "fd1c7dac9cc24abaa31de91fe5410b0f",
      "a01589c766734d0594c23f32f7002f8c",
      "9959187cad5740c69c84c3e9a699e716",
      "6b4c285be66f4a9f8e03d01792a09a35",
      "998cab80696e4e7bbc35049bd6931e1c",
      "8c20a97c631b42dbac18c09d2ee45e4b",
      "5e73e93098a4421b8fff39259803d298",
      "7ef0d53cb2d64a6a9a232c64de32c9d5",
      "7f8f479c531e433885159f64a7aedbb0",
      "094f451bbf004e919828ad6f39e8581e",
      "932b1f0d5e414796bd10346ebf6be046",
      "2079914d78a449b9b0d4763f7074f2c9",
      "323c44b996254a84a7015bbe2f108b11",
      "65c001a48fb04568b03e4fc30156b391",
      "bb3d302958ce405d8579c2c8dd98b02d",
      "a492166ba2c648c5be891055f1b53d24",
      "f711a33c1f664453a8e7514f04a52fe7",
      "e73a5fe07a5148f0867465fadf38c13e",
      "dc011ffbf6b24150b80fc19f599dc0a1",
      "d8c5ae851f394ca490f04cf96e48992b",
      "dfd88b60d7d840f59c837173191a32e6",
      "b72530813cf142c290aceac5bb198838",
      "eb2ec9bb35bd43d492b20bf1234db4bb",
      "30c14055d966408a8aa9e1ba2e4e645f",
      "5305e31c5cf6443da5762cddb03f0c64",
      "63ee9264c3b3423bb0c79efc838f5726",
      "a775e22e1aa4432b9ed08ad890ffe1dd",
      "4ce912186d4b4bffbb6174eaeecaba32",
      "bf418252dc514941872cabfe8e732fee",
      "97ca9351170f4544b9921cf898b580a6",
      "587fc849341f4d2f99050093257bbc1c",
      "041318f4654c4c579efedf268bbeeaa4",
      "0995b5a53dd84efb8e53ac231263de84",
      "3627208748d84690b7142140e97f92d9",
      "a94cda1ce28a48218f7f416e40db76d6",
      "59c3bc2628a34e3e91e40dfe7557a021",
      "d79f7edb958841b98b18978b9351eaed",
      "6b24ae0f59034c2bb81613ff52e92dbf",
      "9425428d01404514b06b354f8d2bec97",
      "8af4cbdbc16740ff9141f7409beabf91",
      "1f5675ca438d4175b637cdcdebca663c",
      "104c15b3b1a647e5b1bf0bb4ac1e10ab",
      "a48f9a9b539045409f4663ff43f154eb",
      "b857360b00484bffacbbf6068f2dcbdd",
      "cd9eb13addbe45aba24adfb20bd88880",
      "807f426a895f4ad0ad5bc2f62a51d98b",
      "2c582191ffb34870a9f1a4347dd788b0",
      "9ee5bc663a214ed5a3e94a80b05c0600",
      "64705649180d4acda86085244015039e",
      "44d1156fc633432091a7722270359118",
      "bb7824a817d64b2d9aa8580d74f1ba8e",
      "1a8cb29fee164ef994e237418df09ef0",
      "be2225e503b5464eb2b3f891ac1fcff1",
      "2ffc7aa76fcd4603a00392cfd033ae42",
      "1afb25af643142f488387bdd7789288a",
      "c0625bf7cc4543c7bee080289d5a0e87",
      "e434edef7a1645339c214a039b0f8dff",
      "26074db82ccf4914ba45bc07f95aab38",
      "7d071cd36a414a1fb3d9155abf353a03",
      "ce4dd338da2b4aa2b7ce431ddace57ca",
      "d5d96a4f796e4afc918a5209506389c8",
      "5dfb5b675e034cfcb231d207b026a0df",
      "00396f00747042ba9350b4b41d7c07fa",
      "7c81b9edaa3d461a98dc4a020bad85f1",
      "92ae919c407c435e827f3259f1b2556b",
      "9bd9b57a3524432eabe32c7515aae8c5",
      "a206c0c91d5e4dcdaf1e946257f58325",
      "a986a055d1664274ac43c069d3757668",
      "e973a97654574cdc86775d2c05606a7a",
      "f3d9e9a587a54dfcad941d1cb26956fa",
      "e27cbf7564aa48c2af3009405c207c36",
      "64e5de311a6e43c88ab06a54568a2d95",
      "17e141486ff04047a4d6e82bec957fad",
      "bd4fdc792ab544679f89b3377c20fdbb",
      "bbdbdbe755d84088b13500a35a5b41ae",
      "dd0fc1e9c5c640c3b2baae39636a4e0f",
      "11f75d3716834548b5fbac29ab25f9f6",
      "2fe39a5d59d54d5b9a18ba0d36f32fd0",
      "bb304a587fda46c88b90fec6f4a9fd11",
      "b78b5a28ba4c4e71a966fbf370a019cf",
      "f706cadb92514d0fb566ad4501a537fa",
      "4b71f7b7efb746c1be638b957cb33b6c",
      "8190f1e57e2549e79acbcdd3473ebd7b",
      "65d61c3f5bbd41a0869ef8eacdf13c61",
      "9acfccf60cf94029bbc9f95061a6048a",
      "2fe07a2bb16246849b3dcf0c537586ac",
      "dc6a9cf83af5406a825639c8d05d604b",
      "0ff1273410d54c1f9f9e50f240926a37",
      "0574f6037616413aac5fb6c22739c698",
      "54d73b9390a2472b8ed6e090c6c95378",
      "684fff7856234d89b931fe5188b3e308",
      "5e6e2dbcbf16475392bfbd7dd57f8355",
      "d5f9c3e6ad164c6397ca4fd4f9828ccd",
      "04a4f0d443774918a2ba915663004b77",
      "e7c032e40eb943deb36466ee88625ff6",
      "b87b6e19a89143748acfa70cd863a393",
      "3f4adba8484947ce9aff751b33a42b71",
      "b0dc6ea045e347f297e183bbd0b6cb17",
      "d0cb700041e3470da5e1ddd95fc5494d",
      "b8c42fb0384a46be9ed48fcbe91d129b",
      "c24e721fc5174221bfe55cd2edaa5458",
      "06c4ab34c67c459b84374bb13d756074",
      "c81d23e2511a4a619a3b55c3037e5c1a",
      "3453e03816494f6db5613e144b1eb69a",
      "52a7771f24e0414b9ac58ded3e1422b8",
      "40e8c1f82d58459b97951a604deb1b30",
      "b54ac008e9614dfb88b27ee3ed42bf33",
      "379c5bb2822d4f658e367e88e8f76646",
      "204e67ceec9448158221d98db20ccc61",
      "3a403557189c4d65ac9cea26cac1e5fe",
      "c493c03ae67043ad951854ea0a01b50d",
      "1fc0c62d93bf4f768988a9b8ec838dc1",
      "5bdb5c1e0b1d49f78b0f929206840507"
     ]
    },
    "id": "7rN6-VsBKwir",
    "outputId": "d0dc8bbb-99e5-4895-d213-aec4667204ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b50221a50c4fe085dd04b93da05a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4c285be66f4a9f8e03d01792a09a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3d302958ce405d8579c2c8dd98b02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ee9264c3b3423bb0c79efc838f5726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79f7edb958841b98b18978b9351eaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee5bc663a214ed5a3e94a80b05c0600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d071cd36a414a1fb3d9155abf353a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d9e9a587a54dfcad941d1cb26956fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f706cadb92514d0fb566ad4501a537fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6e2dbcbf16475392bfbd7dd57f8355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81d23e2511a4a619a3b55c3037e5c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HuggingFace Embeddings - Instructor embeddings\n",
    "\n",
    "# instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
    "#                                                       model_kwargs={\"device\": \"cuda\"})\n",
    "\n",
    "\n",
    "embedding_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "# model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "model_norm = HuggingFaceBgeEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs={'device': 'cuda'},\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccP2uFDwfrW4"
   },
   "source": [
    "###mixedbread-ai/mxbai-embed-large-v1\n",
    "\n",
    "note that you have to provide the prompt \"Represent this sentence for searching relevant passages: \"\n",
    "for query if you want to use it for retrieval. Besides that you don't need any prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnAP-cgSfspC"
   },
   "outputs": [],
   "source": [
    "# # loading model\n",
    "# model_name = 'mixedbread-ai/mxbai-embed-large-v1'\n",
    "\n",
    "# # Encoding\n",
    "# # encode_kwargs = {'normalized': True}\n",
    "\n",
    "# model_norm = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=model_name,\n",
    "#     model_kwargs={'device': 'cuda'},\n",
    "#     # encode_kwargs=encode_kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmj7ETdwBqHW"
   },
   "source": [
    "###Chroma DB\n",
    "\n",
    "Chroma DB is a vector store that is open-source and is utilized for the storage and retrieval of vector embeddings. Its primary purpose is to store embeddings and associated metadata for future use by extensive language models. Furthermore, it can also be employed for semantic search engines that operate on text data.\n",
    "\n",
    "With Chroma DB, you can easily manage text documents, convert text to embeddings, and do similarity searches.\n",
    "\n",
    "https://www.datacamp.com/tutorial/chromadb-tutorial-step-by-step-guide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3pbPv_xLn7O"
   },
   "outputs": [],
   "source": [
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'database'\n",
    "\n",
    "# embedding = instructor_embeddings\n",
    "embedding = model_norm\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HciOUGFctmZ"
   },
   "source": [
    "###Retriever\n",
    "\n",
    "vectordb:\n",
    "This appears to be a reference to a module or an object that interacts with a vector database system. Vector databases are specialized storage systems designed to handle high-dimensional vector data efficiently, which is common in machine learning and similar applications where entities are represented as vectors in a high-dimensional space.\n",
    "\n",
    "as_retriever:\n",
    "as_retriever is a method that configures and returns a retriever object. This object is likely used for querying the vector database, particularly for retrieving vectors that are nearest to a given query vector based on some distance metric (e.g., cosine similarity).\n",
    "\n",
    "search_kwargs:\n",
    "The search_kwargs parameter is used to pass additional keyword arguments to the as_retriever method. These arguments are typically used to configure how the search is performed within the vector database.\n",
    "\n",
    "{\"k\": 5}: This dictionary specifies the configuration for the retriever. Here, k is set to 5, which usually means the retriever will return the top 5 closest vectors (or entries) in response to a query. This is often referred to as \"k-nearest neighbors\" search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6T0zABxycsNU"
   },
   "outputs": [],
   "source": [
    "# search_kwargs: to return the number of context from the vector stores\n",
    "# also we are having to have a citation to show from which pdf file the info comes from\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb0Sn22Ke6kT"
   },
   "source": [
    "###LangChain\n",
    "LangChain components can be used to build new prompt chains or customize existing templates. it also also includes components that allow LLMs to access new data sets without retraining.\n",
    "\n",
    "LLMs excel at responding to prompts in a general context, but struggle in a specific domain they were never trained on. Prompts are queries people use to seek responses from an LLM. For example, an LLM can provide an answer to how much a computer costs by providing an estimate. However, it can't list the price of a specific computer model that your company sells.\n",
    "\n",
    "To do that, machine learning engineers must integrate the LLM with the organization’s internal data sources and apply prompt engineering*—a practice where a data scientist refines inputs to a generative model with a specific structure and context.\n",
    "\n",
    "LangChain streamlines intermediate steps to develop such data-responsive applications, making prompt engineering more efficient. It is designed to develop diverse applications powered by language models more effortlessly, including chatbots, question-answering, content generation, summarizers, and more.[https://aws.amazon.com/what-is/langchain/]\n",
    "\n",
    "*Prompt engineering is the process where you guide generative artificial intelligence (generative AI) solutions to generate desired outputs.[https://aws.amazon.com/what-is/prompt-engineering/]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S64lItNBe8XP"
   },
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "\n",
    "# DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "# You are a drunk, not respectful assistant. Always answer with creativity. Your answers could include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are biased and negative in nature.\"\"\"\n",
    "\n",
    "\n",
    "# Creates a complete prompt\n",
    "def get_prompt(instruction, system_prompt=DEFAULT_SYSTEM_PROMPT):\n",
    "  sys_prompt = B_SYS + system_prompt + E_SYS\n",
    "  prompt_template = B_INST + sys_prompt + instruction + E_INST\n",
    "  # print(prompt_template)\n",
    "  return prompt_template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tydXizj7PcA"
   },
   "source": [
    "###Building a new system propmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgljIHcLUQtl"
   },
   "outputs": [],
   "source": [
    "# instruction = \"Summarize the following text for me {text}\"\n",
    "\n",
    "# system_propmt = \"Your are an expert in text and article summarization and reducing the number of words. All the sentences and the grammar should be academically enhanced by you.\"\n",
    "\n",
    "# get_prompt(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIM0MAZnABE7"
   },
   "source": [
    "###Building new system prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6Yv2nyI8Wdk"
   },
   "outputs": [],
   "source": [
    "# system_prompt = \"You are an expert assistant in translation.\"\n",
    "# instruction = \"Convert the text from English to Italian:\\n\\n {text}\"\n",
    "# prompt_template = get_prompt(instruction, system_prompt)\n",
    "# print(prompt_template)\n",
    "\n",
    "# prompt = PromptTemplate(template=prompt_template, input_variable=[\"text\"])\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rObFDsZFgt-x"
   },
   "source": [
    "### Completely different system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f15ov0aYgsmx"
   },
   "outputs": [],
   "source": [
    "# diffrent system propmt\n",
    "system_prompt = \"\"\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \"\"\"\n",
    "\n",
    "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "#mxbai syetem prompt\n",
    "# system_prompt = \"\"\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\n",
    "\n",
    "# If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \"\"\"\n",
    "\n",
    "# instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "\n",
    "# Question: Represent this sentence for searching relevant passages: {question}\"\"\"\n",
    "# get_prompt(instruction, sys_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKlDR9wznrAs"
   },
   "source": [
    "### RetrievalQA\n",
    "\n",
    "Chain Type\n",
    "\n",
    "The default chain_type=\"stuff\" uses ALL of the text from the documents in the prompt. It actually doesn’t work with our example because it exceeds the token limit and causes rate-limiting errors. That’s why in this example, we had to use other chain types for example \"map_reduce\". What are the other chain types?\n",
    "\n",
    "map_reduce: It separates texts into batches (as an example, you can define batch size in llm=OpenAI(batch_size=5)), feeds each batch with the question to LLM separately, and comes up with the final answer based on the answers from each batch.\n",
    "\n",
    "refine : It separates texts into batches, feeds the first batch to LLM, and feeds the answer and the second batch to LLM. It refines the answer by going through all the batches.\n",
    "\n",
    "map-rerank: It separates texts into batches, feeds each batch to LLM, returns a score of how fully it answers the question, and comes up with the final answer based on the high-scored answers from each batch.\n",
    "\n",
    "https://towardsdatascience.com/4-ways-of-question-answering-in-langchain-188c6707cc5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4bvRKJmnVaC"
   },
   "outputs": [],
   "source": [
    "# Create the template prompt\n",
    "prompt_template = get_prompt(instruction, system_prompt)\n",
    "llm_prompt = PromptTemplate(\n",
    "    template = prompt_template, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "chain_type_kwargs = {\"prompt\": llm_prompt}\n",
    "\n",
    "# To create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = hf_llm,\n",
    "    chain_type = \"stuff\", #  uses ALL of the text from the documents in the prompt\n",
    "    retriever = retriever,\n",
    "    chain_type_kwargs = chain_type_kwargs,\n",
    "    return_source_documents = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVmX_XdRWsdb"
   },
   "source": [
    "###Format the generated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TD8aIxbRrnuL"
   },
   "outputs": [],
   "source": [
    "# to format the response and cite sources\n",
    "# textwrap: Used to wrap or fill text into a specified width. This is helpful for formatting output text to make it more readable\n",
    "\n",
    "# To trim a given string (text) at the point where a specific substring (prompt) first appears\n",
    "def trim_text(output_text, search_phrase):\n",
    "  phrase = search_phrase\n",
    "  index = output_text.find(phrase)\n",
    "  if index != -1:\n",
    "    return output_text[index:] # Trim everything from the start of text up to the phrase/symbol\n",
    "  else:\n",
    "    return output_text\n",
    "\n",
    "\n",
    "# Removes occurrences of a substring from a string, typically used here to clean up the generated text by removing predefined markers or prompts\n",
    "def remove_substring(output, substring):\n",
    "  return output.replace(substring, \"\")\n",
    "\n",
    "\n",
    "def wrap_text(text, width=150):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "\n",
    "def process_generated_response(generated_response):\n",
    "    # source_list = []\n",
    "    # print(wrap_text(generated_response['result']))\n",
    "    wrapped_response = wrap_text(generated_response['result'])\n",
    "    final_response = trim_text(wrapped_response, '[/INST]')\n",
    "    final_response = remove_substring(final_response, '[/INST]')\n",
    "    print(final_response)\n",
    "\n",
    "    print('\\n\\nSources:')\n",
    "    for source in generated_response[\"source_documents\"]:\n",
    "      # source_list.append(source.metadata['source'])\n",
    "      print(source.metadata['source'])\n",
    "\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecoGtb-6vMqE"
   },
   "outputs": [],
   "source": [
    "# qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6hX38uuMBat"
   },
   "outputs": [],
   "source": [
    "# For retrieval we need to pass this prompt.\n",
    "# query = 'Represent this sentence for searching relevant passages: A man is eating a piece of bread'\n",
    "\n",
    "# query = \"What are Large Language Models?\"\n",
    "# response = qa_chain(query)\n",
    "# # process_generated_response(response)\n",
    "# res_, sl = process_generated_response(response)\n",
    "# print(f\"\\n\\n\\n res: {res_}\\n\\n\\n sl: {sl}\")\n",
    "# for _ in sl:\n",
    "#   print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c6V0xzpMFkL"
   },
   "outputs": [],
   "source": [
    "# query = \"How many tokens was LLaMA-2 trained on?\"\n",
    "# response = qa_chain(query)\n",
    "# res_, sl = process_generated_response(response)\n",
    "# print(f\"\\n\\n\\n res: {res_}\\n\\n\\n sl: {sl}\")\n",
    "# for _ in sl:\n",
    "#   print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3m_TW256un6W"
   },
   "outputs": [],
   "source": [
    "# # For retrieval we need to pass this prompt.\n",
    "# # query = 'Represent this sentence for searching relevant passages: A man is eating a piece of bread'\n",
    "\n",
    "# query = \"What are Large Language Models?\"\n",
    "# response = qa_chain(query)\n",
    "# process_generated_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfUWg3Iv4OjA",
    "outputId": "b1f7a891-c7e0-4394-fe85-c09814f1ae6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  According to the text, LLaMA-2 was trained on 2 trillion tokens of data.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "  According to the text, LLaMA-2 was trained on 2 trillion tokens of data.\n"
     ]
    }
   ],
   "source": [
    "query = \"How many tokens was LLaMA-2 trained on?\"\n",
    "response = qa_chain(query)\n",
    "print(process_generated_response(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRfwvXgu2wo6"
   },
   "source": [
    "###retrieving questions and generating responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qq3NQsho20F_"
   },
   "outputs": [],
   "source": [
    "# %pip -q install dropbox\n",
    "\n",
    "# import pathlib\n",
    "# import pandas as pd\n",
    "# import dropbox\n",
    "# from dropbox.exceptions import AuthError\n",
    "\n",
    "# DROPBOX_ACCESS_TOKEN = ''\n",
    "\n",
    "# # Connect to the Dropbox API\n",
    "# def dropbox_connect():\n",
    "#   try:\n",
    "#     dbx = dropbox.Dropbox(DROPBOX_ACCESS_TOKEN)\n",
    "#   except AuthError as e:\n",
    "#     print(f\"Error connecting to Dropbox with access token: {str(e)}\" )\n",
    "#   return dbx\n",
    "\n",
    "\n",
    "# # Download the file\n",
    "# def dropbox_download(dbx_file_path, local_file_path):\n",
    "#   try:\n",
    "#     dbx = dropbox_connect()\n",
    "\n",
    "#     with open(local_file_path, 'wt') as f:\n",
    "#       metadata, result = dbx.files_download(path=dbx_file_path)\n",
    "#       f.write(result.content)\n",
    "#   except Exception as e:\n",
    "#       print(f\"Error downloading file from dropbox: {str(e)}\")\n",
    "\n",
    "# dbx_path_file = 'All files/Apps/LLMs-RAG/Questions.csv'\n",
    "# local_path_file = '/content/Questions'\n",
    "# Questions = dropbox_download(dbx_path_file, local_path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwLYCDl7jnw5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_question_dict(questions_file_path):\n",
    "  qfile_path = questions_file_path\n",
    "  dfQ = pd.read_csv(qfile_path)\n",
    "  # dfQ\n",
    "  qlist = [dfQ.loc[i, 'Question'] for i in range(len(dfQ)) ]\n",
    "  # print(\"These are the General Questions: \\n\")\n",
    "  # # print(f\"{dfQ.loc[:, 'Question']}\")\n",
    "  # for index in range(len(dfQ)):\n",
    "  #   print(f\"Q {index+1}: {dfQ.loc[index,'Question']}\")\n",
    "  qa_dict = {key: None for key in qlist}\n",
    "\n",
    "  return qa_dict\n",
    "\n",
    "\n",
    "def generate_qa_dict(question_dict):\n",
    "  qdict = question_dict\n",
    "  for k in qdict.keys():\n",
    "    # print(str(k))\n",
    "    query = str(k)\n",
    "    response = qa_chain(query)\n",
    "    final_res = process_generated_response(response)\n",
    "    qdict.update({k : final_res})\n",
    "\n",
    "    return qdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UnkzDSFPkYh"
   },
   "source": [
    "# Download the Questions in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfcSjCQ_PuMb",
    "outputId": "06a13f3a-8913-4130-ff7e-9ef034ba2065"
   },
   "outputs": [],
   "source": [
    "!wget -O Questionscsv.zip your_path_to_the_zip_file\n",
    "!unzip -q Questionscsv.zip -d questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JqYaxt8BMO4"
   },
   "source": [
    "###General QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPCcoSyC4XLd",
    "outputId": "1be3b768-5702-4160-95db-3b1b4ac697e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  According to the provided text, Newton's first law of motion is not explicitly mentioned.\n",
      "However, the text does mention Einstein's theory of gravity, which is different from Newton's law of gravity. Therefore, I cannot provide an answer to\n",
      "your question based on the provided text.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The force of gravity between two objects changes with\n",
      "distance according to the inverse square law. This means that the force of gravity between two objects decreases proportional to the square of the\n",
      "distance between them.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The principle of conservation of energy states that the total energy of an isolated\n",
      "system remains constant over time, meaning that energy cannot be created or destroyed, only converted from one form to another. This is a fundamental\n",
      "concept in physics and is a direct consequence of the general covariance of the theory.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure, I'd be happy to help!\n",
      "\n",
      "When white light passes through a prism, it is refracted, or bent, due to the difference in density between the air and the material of the prism. As\n",
      "a result, the light is separated into its individual colors, which we call a spectrum. This happens because each color of light has a slightly\n",
      "different wavelength, so they are refracted at slightly different angles.\n",
      "\n",
      "The most familiar example of this is the rainbow, which is formed when sunlight passes through a water droplet in the air. The sunlight is refracted\n",
      "through the droplet, causing it to split into its individual colors, which we see as a band of colors in the sky.\n",
      "\n",
      "In more technical terms, the refraction of light through a prism is caused by the change in index of refraction, which is the ratio of the speed of\n",
      "light in a vacuum to the speed of light in the material of the prism. This change in index of refraction causes the light to bend, or refract, as it\n",
      "passes through the prism.\n",
      "\n",
      "So, to summarize, a prism splits white light into a spectrum of colors by refracting the light through the prism, which separates the different colors\n",
      "based on their wavelengths.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Quantum physics is a branch of physics that deals with the behavior of matter and energy at the smallest\n",
      "scales, typically atoms and subatomic particles. It is based on the principles of wave-particle duality, uncertainty, and the probabilistic nature of\n",
      "physical phenomena. Quantum physics provides a framework for understanding the properties and interactions of matter and energy at the atomic and\n",
      "subatomic level, and has led to numerous technological innovations, including transistors, lasers, and computer chips.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  A neural network is a type of machine learning model that is designed to recognize patterns in data by\n",
      "learning from examples. It consists of multiple layers of interconnected nodes or \"neurons,\" each of which processes a portion of the input data and\n",
      "passes the output to the next layer. The final layer of neurons produces the output of the network, based on the patterns learned from the training\n",
      "data. Neural networks can be used for a wide range of tasks, including image recognition, speech recognition, natural language processing, and more.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Activation functions serve several purposes in neural networks:\n",
      "\n",
      "1. Nonlinearity: They introduce nonlinearity into the model, allowing the network to learn and represent more complex relationships between inputs and\n",
      "outputs.\n",
      "2. Input-dependent gates: In the context of selection mechanisms, activation functions can be viewed as serving as input-dependent gates, controlling\n",
      "the flow of information through the network.\n",
      "3. Activation or multiplication: They can act as either activation functions (e.g., sigmoid, tanh) or multiplication functions (e.g., ReLU, swish),\n",
      "depending on the specific type of activation function used.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Supervised learning involves training a\n",
      "machine learning model on labeled data, where the target output is known, and the goal is to learn a mapping between input data and the corresponding\n",
      "outputs. The model is trained to minimize the difference between its predictions and the actual targets, which is measured through loss functions such\n",
      "as mean squared error or cross-entropy.\n",
      "\n",
      "On the other hand, unsupervised learning involves training a model on unlabeled data, where there is no target output associated with the input data.\n",
      "The goal of unsupervised learning is to discover patterns or relationships in the data without any prior knowledge of the expected output.\n",
      "Unsupervised learning algorithms typically use distance measures or clustering techniques to group similar data points together or identify outliers.\n",
      "\n",
      "In summary, supervised learning focuses on predicting a target output based on input data, while unsupervised learning seeks to identify patterns or\n",
      "relationships in the data itself, without any prior knowledge of the expected output.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Attention.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Overfitting refers to a common\n",
      "problem in machine learning where a model becomes too complex and starts to fit the noise or random fluctuations in the training data rather than the\n",
      "underlying patterns. As a result, the model performs well on the training data but poorly on new, unseen data. This happens because the model has\n",
      "learned the training data too well and cannot generalize to new situations. To prevent overfitting, techniques such as regularization, early stopping,\n",
      "and cross-validation are commonly used to control the complexity of the model and ensure it stays focused on the important features of the data.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "  The learning rate in training neural networks refers to\n",
      "the speed at which the weights of the network are adjusted during optimization. It controls how quickly the network learns from the data and can\n",
      "significantly impact the training process. Here are some key aspects of the learning rate's significance:\n",
      "\n",
      "1. Learning Rate Schedule: The learning rate schedule determines when and how much the learning rate changes during training. A proper learning rate\n",
      "schedule can help avoid overshooting or undershooting the optimal learning rate, leading to faster convergence or better performance.\n",
      "2. Step Size: The learning rate is multiplied by a step size, which determines the amount of change in the weights at each iteration. A larger step\n",
      "size can lead to faster convergence but may cause oscillations in the optimization process.\n",
      "3. Convergence: The learning rate affects how quickly the network converges to the optimal parameters. A higher learning rate can result in faster\n",
      "convergence but may require more iterations to reach the optimal point. On the other hand, a lower learning rate may converge slower but provide\n",
      "better stability and accuracy.\n",
      "4. Overfitting: An excessively high learning rate can lead to overfitting, especially in deep neural networks. This occurs when the network adapts too\n",
      "rapidly to the training data, failing to generalize well to new examples.\n",
      "5. Hyperband Tuning: In Hyperband tuning, the learning rate is one of the critical hyperparameters to optimize. By adjusting the learning rate,\n",
      "Hyperband can find the optimal combination of hyperparameters for a given model and dataset.\n",
      "6. Adaptive Learning Rates: Some recent techniques, like Adaptive Learning Rates (ALR) (Kirkpatrick et al., 2017) or Dynamic Learning Rates (DLR)\n",
      "(Zhang et al., 2018), allow for adaptive adjustments to the learning rate during training. These methods can improve the efficiency and effectiveness\n",
      "of the training process.\n",
      "\n",
      "In summary, the learning rate plays a crucial role in controlling the optimization process of neural networks. Its careful selection and scheduling\n",
      "can significantly impact the training dynamics, convergence, and final performance of the model.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    }
   ],
   "source": [
    "# General Questions\n",
    "\n",
    "questions_file_path = '/content/questions/Questions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ka9sG8ZUMnOC",
    "outputId": "45452066-f314-4839-dc3a-40166689947e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What is Newton's first law of motion?\n",
      " response:   According to the provided text, Newton's first law of motion is not explicitly mentioned.\n",
      "However, the text does mention Einstein's theory of gravity, which is different from Newton's law of gravity. Therefore, I cannot provide an answer to\n",
      "your question based on the provided text.\n",
      "\n",
      "\n",
      "Q1: How does the force of gravity between two objects change with distance?\n",
      " response:   The force of gravity between two objects changes with\n",
      "distance according to the inverse square law. This means that the force of gravity between two objects decreases proportional to the square of the\n",
      "distance between them.\n",
      "\n",
      "\n",
      "Q2: What is the principle of conservation of energy?\n",
      " response:   The principle of conservation of energy states that the total energy of an isolated\n",
      "system remains constant over time, meaning that energy cannot be created or destroyed, only converted from one form to another. This is a fundamental\n",
      "concept in physics and is a direct consequence of the general covariance of the theory.\n",
      "\n",
      "\n",
      "Q3: Explain how a prism splits white light into a spectrum of colors.\n",
      " response:   Sure, I'd be happy to help!\n",
      "\n",
      "When white light passes through a prism, it is refracted, or bent, due to the difference in density between the air and the material of the prism. As\n",
      "a result, the light is separated into its individual colors, which we call a spectrum. This happens because each color of light has a slightly\n",
      "different wavelength, so they are refracted at slightly different angles.\n",
      "\n",
      "The most familiar example of this is the rainbow, which is formed when sunlight passes through a water droplet in the air. The sunlight is refracted\n",
      "through the droplet, causing it to split into its individual colors, which we see as a band of colors in the sky.\n",
      "\n",
      "In more technical terms, the refraction of light through a prism is caused by the change in index of refraction, which is the ratio of the speed of\n",
      "light in a vacuum to the speed of light in the material of the prism. This change in index of refraction causes the light to bend, or refract, as it\n",
      "passes through the prism.\n",
      "\n",
      "So, to summarize, a prism splits white light into a spectrum of colors by refracting the light through the prism, which separates the different colors\n",
      "based on their wavelengths.\n",
      "\n",
      "\n",
      "Q4: What is quantum physics?\n",
      " response:   Quantum physics is a branch of physics that deals with the behavior of matter and energy at the smallest\n",
      "scales, typically atoms and subatomic particles. It is based on the principles of wave-particle duality, uncertainty, and the probabilistic nature of\n",
      "physical phenomena. Quantum physics provides a framework for understanding the properties and interactions of matter and energy at the atomic and\n",
      "subatomic level, and has led to numerous technological innovations, including transistors, lasers, and computer chips.\n",
      "\n",
      "\n",
      "Q5: What is a neural network?\n",
      " response:   A neural network is a type of machine learning model that is designed to recognize patterns in data by\n",
      "learning from examples. It consists of multiple layers of interconnected nodes or \"neurons,\" each of which processes a portion of the input data and\n",
      "passes the output to the next layer. The final layer of neurons produces the output of the network, based on the patterns learned from the training\n",
      "data. Neural networks can be used for a wide range of tasks, including image recognition, speech recognition, natural language processing, and more.\n",
      "\n",
      "\n",
      "Q6: What function do activation functions serve in neural networks?\n",
      " response:   Activation functions serve several purposes in neural networks:\n",
      "\n",
      "1. Nonlinearity: They introduce nonlinearity into the model, allowing the network to learn and represent more complex relationships between inputs and\n",
      "outputs.\n",
      "2. Input-dependent gates: In the context of selection mechanisms, activation functions can be viewed as serving as input-dependent gates, controlling\n",
      "the flow of information through the network.\n",
      "3. Activation or multiplication: They can act as either activation functions (e.g., sigmoid, tanh) or multiplication functions (e.g., ReLU, swish),\n",
      "depending on the specific type of activation function used.\n",
      "\n",
      "\n",
      "Q7: What is the difference between supervised and unsupervised learning in machine learning?\n",
      " response:   Supervised learning involves training a\n",
      "machine learning model on labeled data, where the target output is known, and the goal is to learn a mapping between input data and the corresponding\n",
      "outputs. The model is trained to minimize the difference between its predictions and the actual targets, which is measured through loss functions such\n",
      "as mean squared error or cross-entropy.\n",
      "\n",
      "On the other hand, unsupervised learning involves training a model on unlabeled data, where there is no target output associated with the input data.\n",
      "The goal of unsupervised learning is to discover patterns or relationships in the data without any prior knowledge of the expected output.\n",
      "Unsupervised learning algorithms typically use distance measures or clustering techniques to group similar data points together or identify outliers.\n",
      "\n",
      "In summary, supervised learning focuses on predicting a target output based on input data, while unsupervised learning seeks to identify patterns or\n",
      "relationships in the data itself, without any prior knowledge of the expected output.\n",
      "\n",
      "\n",
      "Q8: Can you explain what overfitting means in the context of training a neural network?\n",
      " response:   Of course! Overfitting refers to a common\n",
      "problem in machine learning where a model becomes too complex and starts to fit the noise or random fluctuations in the training data rather than the\n",
      "underlying patterns. As a result, the model performs well on the training data but poorly on new, unseen data. This happens because the model has\n",
      "learned the training data too well and cannot generalize to new situations. To prevent overfitting, techniques such as regularization, early stopping,\n",
      "and cross-validation are commonly used to control the complexity of the model and ensure it stays focused on the important features of the data.\n",
      "\n",
      "\n",
      "Q9: What is the significance of the learning rate in training neural networks?\n",
      " response:   The learning rate in training neural networks refers to\n",
      "the speed at which the weights of the network are adjusted during optimization. It controls how quickly the network learns from the data and can\n",
      "significantly impact the training process. Here are some key aspects of the learning rate's significance:\n",
      "\n",
      "1. Learning Rate Schedule: The learning rate schedule determines when and how much the learning rate changes during training. A proper learning rate\n",
      "schedule can help avoid overshooting or undershooting the optimal learning rate, leading to faster convergence or better performance.\n",
      "2. Step Size: The learning rate is multiplied by a step size, which determines the amount of change in the weights at each iteration. A larger step\n",
      "size can lead to faster convergence but may cause oscillations in the optimization process.\n",
      "3. Convergence: The learning rate affects how quickly the network converges to the optimal parameters. A higher learning rate can result in faster\n",
      "convergence but may require more iterations to reach the optimal point. On the other hand, a lower learning rate may converge slower but provide\n",
      "better stability and accuracy.\n",
      "4. Overfitting: An excessively high learning rate can lead to overfitting, especially in deep neural networks. This occurs when the network adapts too\n",
      "rapidly to the training data, failing to generalize well to new examples.\n",
      "5. Hyperband Tuning: In Hyperband tuning, the learning rate is one of the critical hyperparameters to optimize. By adjusting the learning rate,\n",
      "Hyperband can find the optimal combination of hyperparameters for a given model and dataset.\n",
      "6. Adaptive Learning Rates: Some recent techniques, like Adaptive Learning Rates (ALR) (Kirkpatrick et al., 2017) or Dynamic Learning Rates (DLR)\n",
      "(Zhang et al., 2018), allow for adaptive adjustments to the learning rate during training. These methods can improve the efficiency and effectiveness\n",
      "of the training process.\n",
      "\n",
      "In summary, the learning rate plays a crucial role in controlling the optimization process of neural networks. Its careful selection and scheduling\n",
      "can significantly impact the training dynamics, convergence, and final performance of the model.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFcTjzUxM-Tp"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'generalQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PH4yrXbENATr"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'generalQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK87KAbgBPs4"
   },
   "source": [
    "###Astro Cosmology QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxE-7r7u7vTM",
    "outputId": "a49df232-bdec-4745-cb9e-2b21f3752927"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The goal of studying astrophysics and cosmology is to understand the\n",
      "origin, evolution, and structure of the universe, including the formation of galaxies, stars, and planets. By combining observations from telescopes\n",
      "and spacecraft with theoretical models, scientists can gain insights into the fundamental laws of physics that govern the behavior of matter and\n",
      "energy in the cosmos. This knowledge can also inform our understanding of the origins of life and the potential for existence of extraterrestrial life\n",
      "beyond Earth. Ultimately, the study of astrophysics and cosmology aims to provide a comprehensive understanding of the universe and its place within\n",
      "the broader context of time and space.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Big Bang theory is supported by several lines of evidence, including:\n",
      "\n",
      "1. Cosmic Microwave Background Radiation: The discovery of the cosmic microwave background radiation in 1964, which is thought to be a remnant of the\n",
      "early universe, provides strong evidence for the Big Bang theory.\n",
      "2. Abundance of Light Elements: According to the Big Bang theory, the universe was initially a hot and dense plasma, in which light elements were\n",
      "formed. The abundance of these elements, such as hydrogen, helium, and lithium, in the universe is consistent with the predictions of the Big Bang\n",
      "theory.\n",
      "3. Large-Scale Structure of the Universe: The distribution of galaxies and galaxy clusters in the universe is consistent with the predictions of the\n",
      "Big Bang theory, suggesting that the universe began in a very hot and dense state and expanded and cooled over time.\n",
      "4. Redshift of Light from Distant Galaxies: The redshift of light from distant galaxies is consistent with the idea that these galaxies are moving\n",
      "away from us, indicating that the universe is still expanding today.\n",
      "5. Observational Evidence from Supernovae: The observation of type Ia supernovae in distant galaxies suggests that the universe is expanding at a rate\n",
      "that is consistent with the predictions of the Big Bang theory.\n",
      "\n",
      "These lines of evidence, among others, provide strong support for the Big Bang theory as the most widely accepted explanation for the origins of the\n",
      "universe.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Inflationary cosmology is important because it provides a framework for understanding the\n",
      "very early universe, including the origins of structure and the homogeneity of the cosmic microwave background radiation (CMB). The inflationary\n",
      "theory, proposed by Alan Guth in the 1980s, suggests that the universe underwent a rapid expansion in its early stages, which helped to smooth out any\n",
      "irregularities and explain why the CMB appears to be so uniform. This theory has been supported by a range of observations, including the measurements\n",
      "of the CMB anisotropy and the large-scale structure of the universe. By providing a consistent explanation for these observations, inflationary\n",
      "cosmology has helped to establish the current understanding of the universe's origins and evolution.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  According to the passage, the precision era in cosmology began in the late 1920s with the\n",
      "work of the astronomer Edwin P. Hubble.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  According to the passage, the cosmic microwave background (CMB) indicates\n",
      "several things:\n",
      "\n",
      "1. Local origin: The authors suggest that the CMB may not be \"cosmic\" in origin, but rather a local phenomenon.\n",
      "2. Good agreement with plasma redshift cosmology: The authors note that the predictions of plasma redshift cosmology match well with the observed\n",
      "relations for type Ia supernovae and the intensity and black body spectrum of the CMB.\n",
      "3. Inconsistency with cosmic time dilation: The authors argue that the good observations and analyses of the relation between surface brightness and\n",
      "redshift for galaxies are well predicted by plasma redshift, but are inconsistent with cosmic time dilation and the contemporary big-bang cosmology.\n",
      "4. Expected precision measurement: The authors expect that in the near future, we will be able to determine the parameters of the standard\n",
      "cosmological model with great precision from a combination of several different experiments.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Current challenges in cosmology include understanding the nature of dark matter and dark\n",
      "energy, which together make up around 95% of the universe's mass-energy budget but are still poorly understood. Another challenge is reconciling the\n",
      "observed large-scale structure of the universe with the predictions of standard cosmological models. Additionally, there is ongoing work to improve\n",
      "the accuracy of cosmic distance measurements and to better understand the properties of the first stars and galaxies to form in the early universe.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recent developments in cosmology include the discovery of dark matter and dark\n",
      "energy, which together make up approximately 95% of the universe's mass-energy budget. Additionally, there have been significant advancements in the\n",
      "field of inflationary theory, led by figures such as Alan Guth and Andrei Linde. These theories aim to explain the very early universe, including the\n",
      "origins of structure and the uniformity of the cosmic microwave background radiation. Furthermore, observations of the cosmic microwave background and\n",
      "large-scale structure have confirmed the predictions of these theories, providing strong evidence for the inflationary model.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The observational revolution in cosmology refers to the significant\n",
      "advancements in observational techniques and technologies that have enabled scientists to gather more accurate and precise data about the universe,\n",
      "particularly in the last few decades. This has led to a better understanding of the standard Big Bang theory and its limitations, as well as the\n",
      "development of new models and frameworks to describe the evolution and structure of the universe. Some of the key areas where this observational\n",
      "revolution has had a significant impact include:\n",
      "\n",
      "1. Measurements of the cosmic microwave background radiation on angular scales of about 1 degree, which provide evidence for a flat global topology.\n",
      "2. Observations of redshift supernovae, which have helped determine the rate of expansion of the universe.\n",
      "3. Gravitational lensing measurements, which have revealed information about the large-scale structure of the universe.\n",
      "4. Studies of the distribution of galaxies and their evolution, which have placed constraints on the parameter space of cosmological models.\n",
      "5. Precision measurements of the age of the universe, which will be possible with upcoming missions such as the Laser Interferometer Space Antenna\n",
      "(LISA).\n",
      "\n",
      "Overall, these advancements have made it possible to probe the universe at earlier times than ever before, providing valuable insights into the\n",
      "origins and evolution of the cosmos.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Theoretical models that explain cosmological observations include the\n",
      "Standard Big Bang Theory, modified Friedmann models, and plasma redshift cosmology. These models incorporate various observations, such as the\n",
      "distribution of galaxies, the large-scale structure of the universe, and the magnitude-redshift relation for type Ia supernovae. However, it is\n",
      "important to recognize that all physical theories are approximations of reality and may fail if pushed too far. Therefore, cosmology continues to\n",
      "evolve as new evidence emerges, and theories are refined or replaced altogether.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "  According to the passage, the future of cosmology holds much promise and excitement,\n",
      "particularly with the incorporation of inflationary theories and large-scale structure observations. The author mentions that precision measurements\n",
      "will dominate the next millennium, providing accurate determinations of cosmic parameters and making cosmology a phenomenological science.\n",
      "Additionally, the author notes that modern cosmological models, including modified Friedmann models, are currently unsatisfactory due to discrepancies\n",
      "between the predicted and observed matter-energy content of the universe.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    }
   ],
   "source": [
    "# Astro Cosmology Questions\n",
    "\n",
    "questions_file_path = '/content/questions/AstroCosmoQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zvx-XOo9AaGW",
    "outputId": "22d0faf0-e5fa-4d18-c36c-190b89cd6657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What is the goal of studying astrophysics and cosmology?\n",
      " response:   The goal of studying astrophysics and cosmology is to understand the\n",
      "origin, evolution, and structure of the universe, including the formation of galaxies, stars, and planets. By combining observations from telescopes\n",
      "and spacecraft with theoretical models, scientists can gain insights into the fundamental laws of physics that govern the behavior of matter and\n",
      "energy in the cosmos. This knowledge can also inform our understanding of the origins of life and the potential for existence of extraterrestrial life\n",
      "beyond Earth. Ultimately, the study of astrophysics and cosmology aims to provide a comprehensive understanding of the universe and its place within\n",
      "the broader context of time and space.\n",
      "\n",
      "\n",
      "Q1: What supports the Big Bang theory?\n",
      " response:   The Big Bang theory is supported by several lines of evidence, including:\n",
      "\n",
      "1. Cosmic Microwave Background Radiation: The discovery of the cosmic microwave background radiation in 1964, which is thought to be a remnant of the\n",
      "early universe, provides strong evidence for the Big Bang theory.\n",
      "2. Abundance of Light Elements: According to the Big Bang theory, the universe was initially a hot and dense plasma, in which light elements were\n",
      "formed. The abundance of these elements, such as hydrogen, helium, and lithium, in the universe is consistent with the predictions of the Big Bang\n",
      "theory.\n",
      "3. Large-Scale Structure of the Universe: The distribution of galaxies and galaxy clusters in the universe is consistent with the predictions of the\n",
      "Big Bang theory, suggesting that the universe began in a very hot and dense state and expanded and cooled over time.\n",
      "4. Redshift of Light from Distant Galaxies: The redshift of light from distant galaxies is consistent with the idea that these galaxies are moving\n",
      "away from us, indicating that the universe is still expanding today.\n",
      "5. Observational Evidence from Supernovae: The observation of type Ia supernovae in distant galaxies suggests that the universe is expanding at a rate\n",
      "that is consistent with the predictions of the Big Bang theory.\n",
      "\n",
      "These lines of evidence, among others, provide strong support for the Big Bang theory as the most widely accepted explanation for the origins of the\n",
      "universe.\n",
      "\n",
      "\n",
      "Q2: Why is inflationary cosmology important?\n",
      " response:   Inflationary cosmology is important because it provides a framework for understanding the\n",
      "very early universe, including the origins of structure and the homogeneity of the cosmic microwave background radiation (CMB). The inflationary\n",
      "theory, proposed by Alan Guth in the 1980s, suggests that the universe underwent a rapid expansion in its early stages, which helped to smooth out any\n",
      "irregularities and explain why the CMB appears to be so uniform. This theory has been supported by a range of observations, including the measurements\n",
      "of the CMB anisotropy and the large-scale structure of the universe. By providing a consistent explanation for these observations, inflationary\n",
      "cosmology has helped to establish the current understanding of the universe's origins and evolution.\n",
      "\n",
      "\n",
      "Q3: What marks the precision era in cosmology?\n",
      " response:   According to the passage, the precision era in cosmology began in the late 1920s with the\n",
      "work of the astronomer Edwin P. Hubble.\n",
      "\n",
      "\n",
      "Q4: What does the cosmic microwave background indicate?\n",
      " response:   According to the passage, the cosmic microwave background (CMB) indicates\n",
      "several things:\n",
      "\n",
      "1. Local origin: The authors suggest that the CMB may not be \"cosmic\" in origin, but rather a local phenomenon.\n",
      "2. Good agreement with plasma redshift cosmology: The authors note that the predictions of plasma redshift cosmology match well with the observed\n",
      "relations for type Ia supernovae and the intensity and black body spectrum of the CMB.\n",
      "3. Inconsistency with cosmic time dilation: The authors argue that the good observations and analyses of the relation between surface brightness and\n",
      "redshift for galaxies are well predicted by plasma redshift, but are inconsistent with cosmic time dilation and the contemporary big-bang cosmology.\n",
      "4. Expected precision measurement: The authors expect that in the near future, we will be able to determine the parameters of the standard\n",
      "cosmological model with great precision from a combination of several different experiments.\n",
      "\n",
      "\n",
      "Q5: What are current challenges in cosmology?\n",
      " response:   Current challenges in cosmology include understanding the nature of dark matter and dark\n",
      "energy, which together make up around 95% of the universe's mass-energy budget but are still poorly understood. Another challenge is reconciling the\n",
      "observed large-scale structure of the universe with the predictions of standard cosmological models. Additionally, there is ongoing work to improve\n",
      "the accuracy of cosmic distance measurements and to better understand the properties of the first stars and galaxies to form in the early universe.\n",
      "\n",
      "\n",
      "Q6: What recent developments have occurred in cosmology?\n",
      " response:   Recent developments in cosmology include the discovery of dark matter and dark\n",
      "energy, which together make up approximately 95% of the universe's mass-energy budget. Additionally, there have been significant advancements in the\n",
      "field of inflationary theory, led by figures such as Alan Guth and Andrei Linde. These theories aim to explain the very early universe, including the\n",
      "origins of structure and the uniformity of the cosmic microwave background radiation. Furthermore, observations of the cosmic microwave background and\n",
      "large-scale structure have confirmed the predictions of these theories, providing strong evidence for the inflationary model.\n",
      "\n",
      "\n",
      "Q7: What does the observational revolution in cosmology entail?\n",
      " response:   The observational revolution in cosmology refers to the significant\n",
      "advancements in observational techniques and technologies that have enabled scientists to gather more accurate and precise data about the universe,\n",
      "particularly in the last few decades. This has led to a better understanding of the standard Big Bang theory and its limitations, as well as the\n",
      "development of new models and frameworks to describe the evolution and structure of the universe. Some of the key areas where this observational\n",
      "revolution has had a significant impact include:\n",
      "\n",
      "1. Measurements of the cosmic microwave background radiation on angular scales of about 1 degree, which provide evidence for a flat global topology.\n",
      "2. Observations of redshift supernovae, which have helped determine the rate of expansion of the universe.\n",
      "3. Gravitational lensing measurements, which have revealed information about the large-scale structure of the universe.\n",
      "4. Studies of the distribution of galaxies and their evolution, which have placed constraints on the parameter space of cosmological models.\n",
      "5. Precision measurements of the age of the universe, which will be possible with upcoming missions such as the Laser Interferometer Space Antenna\n",
      "(LISA).\n",
      "\n",
      "Overall, these advancements have made it possible to probe the universe at earlier times than ever before, providing valuable insights into the\n",
      "origins and evolution of the cosmos.\n",
      "\n",
      "\n",
      "Q8: What theoretical models explain cosmological observations?\n",
      " response:   Theoretical models that explain cosmological observations include the\n",
      "Standard Big Bang Theory, modified Friedmann models, and plasma redshift cosmology. These models incorporate various observations, such as the\n",
      "distribution of galaxies, the large-scale structure of the universe, and the magnitude-redshift relation for type Ia supernovae. However, it is\n",
      "important to recognize that all physical theories are approximations of reality and may fail if pushed too far. Therefore, cosmology continues to\n",
      "evolve as new evidence emerges, and theories are refined or replaced altogether.\n",
      "\n",
      "\n",
      "Q9: What does the future hold for cosmology?\n",
      " response:   According to the passage, the future of cosmology holds much promise and excitement,\n",
      "particularly with the incorporation of inflationary theories and large-scale structure observations. The author mentions that precision measurements\n",
      "will dominate the next millennium, providing accurate determinations of cosmic parameters and making cosmology a phenomenological science.\n",
      "Additionally, the author notes that modern cosmological models, including modified Friedmann models, are currently unsatisfactory due to discrepancies\n",
      "between the predicted and observed matter-energy content of the universe.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3leHbYjAaRT"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'AstroCosmoQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJP_s-xMAabb"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'AstroCosmoQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABHzTWuRBT6R"
   },
   "source": [
    "###Astro Physics QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mL5xk1MAao-",
    "outputId": "099bc978-5162-4fd3-fc94-2377a8cadba1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Chandrasekhar limit is a theoretical boundary beyond which\n",
      "a white dwarf (WD) cannot sustain its own gravity due to the degeneracy of its electron configuration. It is set at approximately 1.4 solar masses\n",
      "(M☉) and marks the point where a WD will collapse into a singularity, leading to a supernova explosion. The significance of the Chandrasekhar limit\n",
      "lies in its role as a critical threshold in understanding the behavior of WDs and their eventual fate.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  White dwarf stars play a crucial role in our\n",
      "understanding of stellar evolution. They are the final stage of a star's life cycle, formed when a star with a mass similar to that of the sun runs\n",
      "out of fuel and collapses under its own gravity. The dense remnant that remains is a white dwarf, characterized by a violent implosion or a gradual\n",
      "and non-violent change in the stellar structure.\n",
      "\n",
      "White dwarfs provide valuable insights into the processes that occur during the final stages of a star's evolution. For example, their extreme\n",
      "compactness allows scientists to study the behavior of matter at incredibly high densities, providing important clues about the properties of\n",
      "degenerate matter. Additionally, the limits of white dwarf diameters and masses can be used to constrain models of stellar evolution and test theories\n",
      "of gravity.\n",
      "\n",
      "Furthermore, the discovery of the Chandrasekhar limit, which marks the maximum mass of a white dwarf before it undergoes a supernova explosion, has\n",
      "had significant impacts on our understanding of the final stages of a star's life cycle. This limit has been used to predict the likelihood of a\n",
      "supernova explosion in a given star system, allowing astronomers to better understand the potential hazards posed by nearby stars.\n",
      "\n",
      "In summary, white dwarf stars offer a unique window into the final stages of a star's evolution, providing valuable insights into the behavior of\n",
      "matter at extreme densities and the processes that occur during the death throes of a star.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  There are several experimental techniques used to observe\n",
      "and study black holes, including:\n",
      "\n",
      "1. X-ray observations: Black holes can be observed through their accretion disks, which emit X-rays as they heat up due to gravitational forces.\n",
      "Telescopes like Chandra and XMM-Newton can detect these X-rays and provide information about the mass and spin of the black hole.\n",
      "2. Radio observations: Black holes can also be observed through their radio emissions, which occur when matter falls into the black hole and heats up.\n",
      "Radio telescopes like the Very Large Array (VLA) and the Event Horizon Telescope (EHT) can detect these radio emissions and provide information about\n",
      "the location and properties of the black hole.\n",
      "3. Gravitational waves: The detection of gravitational waves by LIGO and Virgo has opened up a new window for observing black holes. These waves are\n",
      "produced when two black holes collide or when a black hole merges with another object. By measuring the properties of these waves, scientists can\n",
      "learn more about the properties of the black hole itself.\n",
      "4. Gamma-ray observations: Black holes can also be observed through their gamma-ray emissions, which occur when matter is accelerated near the event\n",
      "horizon of the black hole. Gamma-ray telescopes like Fermi and Integral can detect these emissions and provide information about the properties of the\n",
      "black hole.\n",
      "5. Optical observations: Black holes can also be observed through their optical emissions, which occur when matter is illuminated by the intense\n",
      "gravity of the black hole. Optical telescopes like Hubble and the Square Kilometre Array (SKA) can detect these emissions and provide information\n",
      "about the location and properties of the black hole.\n",
      "\n",
      "Overall, these experimental techniques allow scientists to study black holes in various ways, providing valuable information about their properties\n",
      "and behavior.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Arthur Eddington played a\n",
      "crucial role in validating General Relativity through astronomical observations. As a leading astrophysicist of his time, Eddington was an early\n",
      "advocate of Einstein's theory and conducted groundbreaking experiments to test its predictions. In particular, he led the 1919 solar eclipse\n",
      "expedition that provided definitive evidence for the bending of light around massive objects, a prediction of General Relativity. Eddington's\n",
      "observations helped establish the theory as the new standard for understanding gravity and cosmic phenomena, solidifying his reputation as a\n",
      "pioneering figure in the field.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The discovery of degenerate\n",
      "matter in the 1920s by R.H. Fowler revolutionized our understanding of compact objects like neutron stars. Prior to this discovery, the existence of\n",
      "neutron stars with masses larger than approximately 1.4 solar masses (M☉) was thought to be impossible due to the collapse of the star under its own\n",
      "gravity. However, Fowler's work showed that degenerate matter, consisting of highly compressed fermions, can resist this collapse through the Pauli\n",
      "exclusion principle and the strong nuclear force between neutrons. This discovery opened up new possibilities for the formation and evolution of\n",
      "compact objects, allowing them to exist beyond the previously thought limits.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  According to the passage,\n",
      "Eddington's opposition to Chandrasekhar's theories on stellar evolution had significant implications. Firstly, it delayed the development of studies\n",
      "in stellar evolution for more than 20 years. Secondly, it hindered the acceptance of Chandrasekhar's discoveries and Nobel Prize win in 1983. Finally,\n",
      "it highlights the challenges faced by early career scientists like Chandrasekhar, who were met with resistance and skepticism from established figures\n",
      "in their field.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental advances in detecting gravitational waves have enabled scientists to directly observe these elusive phenomena, which were predicted by\n",
      "Albert Einstein's theory of general relativity in 1915. Gravitational waves are ripples in the fabric of spacetime caused by violent cosmic events,\n",
      "such as the collision of two black holes or neutron stars. The direct observation of gravitational waves has significant implications for\n",
      "astrophysics, as it provides a new window into the universe, allowing scientists to study objects and events that were previously invisible to them.\n",
      "\n",
      "One of the most significant experimental advances in detecting gravitational waves was the development of laser interferometry, which involves\n",
      "splitting a laser beam into multiple arms, sending them down long distances, and then recombining them to create an interference pattern. This\n",
      "technique was first used in the Laser Interferometer Gravitational-Wave Observatory (LIGO) in the 1980s and has since been improved upon by other\n",
      "experiments, including the Virgo detector and the LIGO-India project.\n",
      "\n",
      "On September 14, 2015, scientists detected gravitational waves for the first time, confirming a prediction made by Einstein a century earlier. These\n",
      "waves were produced by the merger of two black holes, each with a mass about 30 times that of the sun, located over 1 billion light-years away. Since\n",
      "then, several other detections have been made, including the merger of two neutron stars, which occurred in August 2017.\n",
      "\n",
      "The direct observation of gravitational waves has opened up new possibilities for studying the universe, particularly in the fields of astrophysics\n",
      "and cosmology. For example, scientists can use gravitational waves to study the properties of black holes and neutron stars, learn more about the\n",
      "origins of the universe, and gain insights into the nature of gravity itself. Additionally, the detection of gravitational waves provides strong\n",
      "evidence for the validity of Einstein's theory of general relativity, which remains one of the cornerstones of modern astrophysics.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The discovery of black holes\n",
      "challenges our understanding of physics under extreme conditions by highlighting the limitations of our current understanding of gravity and the\n",
      "behavior of matter in extremely dense environments. The existence of black holes suggests that there may be aspects of gravity and spacetime that are\n",
      "not well-understood, particularly in situations where the gravitational pull is incredibly strong. This has led to new areas of research and inquiry,\n",
      "such as the study of black hole physics and the development of new theories to describe the behavior of matter and energy under extreme conditions.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  According to the\n",
      "passage, some of the contemporary challenges in theoretical physics suggested by the study of cosmological phenomena include:\n",
      "\n",
      "1. Understanding the initial conditions of the universe: Despite the success of the Big Bang theory, there is still much uncertainty regarding the\n",
      "exact conditions at the very beginning of the universe.\n",
      "2. Explaining the observed acceleration of the universe's expansion: The observation that the universe is expanding at an accelerating rate has been\n",
      "confirmed through various observations, but the underlying physical mechanism driving this acceleration remains unclear.\n",
      "3. Resolving the \"age problem\" in cosmology: The age of the universe is estimated to be around 13.8 billion years, but this value is based on several\n",
      "assumptions and is subject to uncertainties.\n",
      "4. Addressing the discrepancy between the predicted and observed values of the density of matter in the universe: Observations suggest that the\n",
      "universe is made up of roughly 27% dark energy, 68% dark matter, and only 5% ordinary matter, while the standard cosmological model predicts a\n",
      "different distribution of these components.\n",
      "5. Developing new physical principles to explain cosmic processes at high energies: Many of the fundamental questions in cosmology remain unanswered,\n",
      "and it is believed that new physical principles may be required to explain processes occurring at energies beyond what can be reached in laboratory\n",
      "experiments or in the solar system.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "/content/papers/Selected papers-astrophysics-physics.pdf\n",
      "  Based on the given text, there are\n",
      "several future technologies that are anticipated to advance our exploration of cosmological phenomena:\n",
      "\n",
      "1. Multi-object fibrespectroscopy: This technology is expected to provide a denser coverage of the sky with higher spectral resolution, enabling the\n",
      "study of galaxy evolution and large-scale structure in unprecedented detail.\n",
      "2. Next-generation telescopes: The construction of new telescopes, such as the Giant Magellan Telescope and the Thirty Meter Telescope, is expected to\n",
      "significantly improve our ability to observe distant galaxies and cosmic structures.\n",
      "3. Space missions: Future space missions, such as the James Webb Space Telescope and the Wide Field Infrared Survey Telescope, will provide\n",
      "unparalleled observations of the universe in infrared light, enabling the study of the first stars and galaxies, the formation of galaxies, and the\n",
      "distribution of dark matter.\n",
      "4. Advanced data analysis techniques: Advances in machine learning and artificial intelligence are expected to enable more sophisticated analyses of\n",
      "large datasets, leading to new insights into the nature of dark matter and dark energy.\n",
      "5. Quantum computing: The application of quantum computing to cosmological problems may lead to breakthroughs in understanding the behavior of matter\n",
      "and energy at the smallest scales, potentially shedding light on some of the most fundamental questions in physics.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/ASTROPHYSICS AND COSMOLOGY.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n"
     ]
    }
   ],
   "source": [
    "# Astro Cosmology Questions\n",
    "\n",
    "questions_file_path = '/content/questions/AstroPhysicsQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-a3kjJnWAas7",
    "outputId": "2b35ecc6-9ff2-4c2a-866e-8d0ceecf8c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What is the Chandrasekhar limit and its significance in astrophysics?\n",
      " response:   The Chandrasekhar limit is a theoretical boundary beyond which\n",
      "a white dwarf (WD) cannot sustain its own gravity due to the degeneracy of its electron configuration. It is set at approximately 1.4 solar masses\n",
      "(M☉) and marks the point where a WD will collapse into a singularity, leading to a supernova explosion. The significance of the Chandrasekhar limit\n",
      "lies in its role as a critical threshold in understanding the behavior of WDs and their eventual fate.\n",
      "\n",
      "\n",
      "Q1: How do white dwarf stars contribute to our understanding of stellar evolution?\n",
      " response:   White dwarf stars play a crucial role in our\n",
      "understanding of stellar evolution. They are the final stage of a star's life cycle, formed when a star with a mass similar to that of the sun runs\n",
      "out of fuel and collapses under its own gravity. The dense remnant that remains is a white dwarf, characterized by a violent implosion or a gradual\n",
      "and non-violent change in the stellar structure.\n",
      "\n",
      "White dwarfs provide valuable insights into the processes that occur during the final stages of a star's evolution. For example, their extreme\n",
      "compactness allows scientists to study the behavior of matter at incredibly high densities, providing important clues about the properties of\n",
      "degenerate matter. Additionally, the limits of white dwarf diameters and masses can be used to constrain models of stellar evolution and test theories\n",
      "of gravity.\n",
      "\n",
      "Furthermore, the discovery of the Chandrasekhar limit, which marks the maximum mass of a white dwarf before it undergoes a supernova explosion, has\n",
      "had significant impacts on our understanding of the final stages of a star's life cycle. This limit has been used to predict the likelihood of a\n",
      "supernova explosion in a given star system, allowing astronomers to better understand the potential hazards posed by nearby stars.\n",
      "\n",
      "In summary, white dwarf stars offer a unique window into the final stages of a star's evolution, providing valuable insights into the behavior of\n",
      "matter at extreme densities and the processes that occur during the death throes of a star.\n",
      "\n",
      "\n",
      "Q2: What experimental techniques are used to observe and study black holes?\n",
      " response:   There are several experimental techniques used to observe\n",
      "and study black holes, including:\n",
      "\n",
      "1. X-ray observations: Black holes can be observed through their accretion disks, which emit X-rays as they heat up due to gravitational forces.\n",
      "Telescopes like Chandra and XMM-Newton can detect these X-rays and provide information about the mass and spin of the black hole.\n",
      "2. Radio observations: Black holes can also be observed through their radio emissions, which occur when matter falls into the black hole and heats up.\n",
      "Radio telescopes like the Very Large Array (VLA) and the Event Horizon Telescope (EHT) can detect these radio emissions and provide information about\n",
      "the location and properties of the black hole.\n",
      "3. Gravitational waves: The detection of gravitational waves by LIGO and Virgo has opened up a new window for observing black holes. These waves are\n",
      "produced when two black holes collide or when a black hole merges with another object. By measuring the properties of these waves, scientists can\n",
      "learn more about the properties of the black hole itself.\n",
      "4. Gamma-ray observations: Black holes can also be observed through their gamma-ray emissions, which occur when matter is accelerated near the event\n",
      "horizon of the black hole. Gamma-ray telescopes like Fermi and Integral can detect these emissions and provide information about the properties of the\n",
      "black hole.\n",
      "5. Optical observations: Black holes can also be observed through their optical emissions, which occur when matter is illuminated by the intense\n",
      "gravity of the black hole. Optical telescopes like Hubble and the Square Kilometre Array (SKA) can detect these emissions and provide information\n",
      "about the location and properties of the black hole.\n",
      "\n",
      "Overall, these experimental techniques allow scientists to study black holes in various ways, providing valuable information about their properties\n",
      "and behavior.\n",
      "\n",
      "\n",
      "Q3: What role did Arthur Eddington play in validating General Relativity through astronomical observations?\n",
      " response:   Arthur Eddington played a\n",
      "crucial role in validating General Relativity through astronomical observations. As a leading astrophysicist of his time, Eddington was an early\n",
      "advocate of Einstein's theory and conducted groundbreaking experiments to test its predictions. In particular, he led the 1919 solar eclipse\n",
      "expedition that provided definitive evidence for the bending of light around massive objects, a prediction of General Relativity. Eddington's\n",
      "observations helped establish the theory as the new standard for understanding gravity and cosmic phenomena, solidifying his reputation as a\n",
      "pioneering figure in the field.\n",
      "\n",
      "\n",
      "Q4: How has the concept of degenerate matter advanced our knowledge of compact objects like neutron stars?\n",
      " response:   The discovery of degenerate\n",
      "matter in the 1920s by R.H. Fowler revolutionized our understanding of compact objects like neutron stars. Prior to this discovery, the existence of\n",
      "neutron stars with masses larger than approximately 1.4 solar masses (M☉) was thought to be impossible due to the collapse of the star under its own\n",
      "gravity. However, Fowler's work showed that degenerate matter, consisting of highly compressed fermions, can resist this collapse through the Pauli\n",
      "exclusion principle and the strong nuclear force between neutrons. This discovery opened up new possibilities for the formation and evolution of\n",
      "compact objects, allowing them to exist beyond the previously thought limits.\n",
      "\n",
      "\n",
      "Q5: What are the implications of Eddington's opposition to Chandrasekhar's theories on stellar evolution?\n",
      " response:   According to the passage,\n",
      "Eddington's opposition to Chandrasekhar's theories on stellar evolution had significant implications. Firstly, it delayed the development of studies\n",
      "in stellar evolution for more than 20 years. Secondly, it hindered the acceptance of Chandrasekhar's discoveries and Nobel Prize win in 1983. Finally,\n",
      "it highlights the challenges faced by early career scientists like Chandrasekhar, who were met with resistance and skepticism from established figures\n",
      "in their field.\n",
      "\n",
      "\n",
      "Q6: What experimental advances have allowed for the direct observation of gravitational waves, and what do they signify for astrophysics?\n",
      " response: \n",
      "Experimental advances in detecting gravitational waves have enabled scientists to directly observe these elusive phenomena, which were predicted by\n",
      "Albert Einstein's theory of general relativity in 1915. Gravitational waves are ripples in the fabric of spacetime caused by violent cosmic events,\n",
      "such as the collision of two black holes or neutron stars. The direct observation of gravitational waves has significant implications for\n",
      "astrophysics, as it provides a new window into the universe, allowing scientists to study objects and events that were previously invisible to them.\n",
      "\n",
      "One of the most significant experimental advances in detecting gravitational waves was the development of laser interferometry, which involves\n",
      "splitting a laser beam into multiple arms, sending them down long distances, and then recombining them to create an interference pattern. This\n",
      "technique was first used in the Laser Interferometer Gravitational-Wave Observatory (LIGO) in the 1980s and has since been improved upon by other\n",
      "experiments, including the Virgo detector and the LIGO-India project.\n",
      "\n",
      "On September 14, 2015, scientists detected gravitational waves for the first time, confirming a prediction made by Einstein a century earlier. These\n",
      "waves were produced by the merger of two black holes, each with a mass about 30 times that of the sun, located over 1 billion light-years away. Since\n",
      "then, several other detections have been made, including the merger of two neutron stars, which occurred in August 2017.\n",
      "\n",
      "The direct observation of gravitational waves has opened up new possibilities for studying the universe, particularly in the fields of astrophysics\n",
      "and cosmology. For example, scientists can use gravitational waves to study the properties of black holes and neutron stars, learn more about the\n",
      "origins of the universe, and gain insights into the nature of gravity itself. Additionally, the detection of gravitational waves provides strong\n",
      "evidence for the validity of Einstein's theory of general relativity, which remains one of the cornerstones of modern astrophysics.\n",
      "\n",
      "\n",
      "Q7: How does the discovery of black holes challenge our understanding of physics under extreme conditions?\n",
      " response:   The discovery of black holes\n",
      "challenges our understanding of physics under extreme conditions by highlighting the limitations of our current understanding of gravity and the\n",
      "behavior of matter in extremely dense environments. The existence of black holes suggests that there may be aspects of gravity and spacetime that are\n",
      "not well-understood, particularly in situations where the gravitational pull is incredibly strong. This has led to new areas of research and inquiry,\n",
      "such as the study of black hole physics and the development of new theories to describe the behavior of matter and energy under extreme conditions.\n",
      "\n",
      "\n",
      "Q8: What are the contemporary challenges in theoretical physics suggested by the study of cosmological phenomena?\n",
      " response:   According to the\n",
      "passage, some of the contemporary challenges in theoretical physics suggested by the study of cosmological phenomena include:\n",
      "\n",
      "1. Understanding the initial conditions of the universe: Despite the success of the Big Bang theory, there is still much uncertainty regarding the\n",
      "exact conditions at the very beginning of the universe.\n",
      "2. Explaining the observed acceleration of the universe's expansion: The observation that the universe is expanding at an accelerating rate has been\n",
      "confirmed through various observations, but the underlying physical mechanism driving this acceleration remains unclear.\n",
      "3. Resolving the \"age problem\" in cosmology: The age of the universe is estimated to be around 13.8 billion years, but this value is based on several\n",
      "assumptions and is subject to uncertainties.\n",
      "4. Addressing the discrepancy between the predicted and observed values of the density of matter in the universe: Observations suggest that the\n",
      "universe is made up of roughly 27% dark energy, 68% dark matter, and only 5% ordinary matter, while the standard cosmological model predicts a\n",
      "different distribution of these components.\n",
      "5. Developing new physical principles to explain cosmic processes at high energies: Many of the fundamental questions in cosmology remain unanswered,\n",
      "and it is believed that new physical principles may be required to explain processes occurring at energies beyond what can be reached in laboratory\n",
      "experiments or in the solar system.\n",
      "\n",
      "\n",
      "Q9: What future technologies are anticipated to advance our exploration of cosmological phenomena?\n",
      " response:   Based on the given text, there are\n",
      "several future technologies that are anticipated to advance our exploration of cosmological phenomena:\n",
      "\n",
      "1. Multi-object fibrespectroscopy: This technology is expected to provide a denser coverage of the sky with higher spectral resolution, enabling the\n",
      "study of galaxy evolution and large-scale structure in unprecedented detail.\n",
      "2. Next-generation telescopes: The construction of new telescopes, such as the Giant Magellan Telescope and the Thirty Meter Telescope, is expected to\n",
      "significantly improve our ability to observe distant galaxies and cosmic structures.\n",
      "3. Space missions: Future space missions, such as the James Webb Space Telescope and the Wide Field Infrared Survey Telescope, will provide\n",
      "unparalleled observations of the universe in infrared light, enabling the study of the first stars and galaxies, the formation of galaxies, and the\n",
      "distribution of dark matter.\n",
      "4. Advanced data analysis techniques: Advances in machine learning and artificial intelligence are expected to enable more sophisticated analyses of\n",
      "large datasets, leading to new insights into the nature of dark matter and dark energy.\n",
      "5. Quantum computing: The application of quantum computing to cosmological problems may lead to breakthroughs in understanding the behavior of matter\n",
      "and energy at the smallest scales, potentially shedding light on some of the most fundamental questions in physics.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tUjRknDAav7"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'AstroPhysicsQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NV1OthB8Aay2"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'AstroPhysicsQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POtSGTQFCBk_"
   },
   "source": [
    "### Attention Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHRdqhM-Aa2L",
    "outputId": "e4ff4de8-f72a-4d8a-f30b-357838d4b2de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Transformer model introduces the self-attention mechanism, which allows\n",
      "the model to attend to different parts of the input sequence simultaneously and weigh their importance when computing the output. This is in contrast\n",
      "to traditional recurrent neural network (RNN) architectures, which process the input sequence sequentially and do not have a direct way to weight the\n",
      "importance of different parts of the input.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Transformer model enhances training efficiency by using an attention\n",
      "mechanism that allows it to focus on specific parts of the input sequence, rather than considering the entire sequence simultaneously. This reduces\n",
      "the computational complexity of the model and makes it faster to train. Additionally, the Transformer uses a parallelization technique called multi-\n",
      "head attention, which enables it to process multiple sequences in parallel, further increasing its training efficiency.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Transformer's encoder consists of multiple layers, each comprising of two\n",
      "sub-layers: a multi-head self-attention mechanism and a position-wise fully connected feed-forward network. The output of each sub-layer is then layer\n",
      "normalized and passed through a residual connection. Additionally, the encoder utilizes end-to-end memory networks, which rely on a recurrent\n",
      "attention mechanism rather than sequence-aligned RNNs or convolution.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In the Transformer, multi-head attention is used in three different\n",
      "ways:\n",
      "\n",
      "1. In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the\n",
      "encoder. This allows every position in the decoder to attend over all positions in the input sequence.\n",
      "2. The encoder contains self-attention layers, where each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
      "3. Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including\n",
      "that position.\n",
      "\n",
      "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions, which helps to\n",
      "improve the model's ability to capture long-range dependencies in the input sequence.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Transformer handles sequence order through the use of self-attention mechanisms.\n",
      "Self-attention allows each position in the sequence to attend to all positions in the sequence, regardless of their order. This allows the model to\n",
      "capture long-range dependencies and handle variable-length input sequences.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Attention.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Self-attention in the Transformer provides several benefits:\n",
      "\n",
      "1. Ability to model complex data: Self-attention allows the Transformer to dense within a context window, enabling it to model complex data\n",
      "effectively.\n",
      "2. Reduced computational complexity: By attending to all positions in the input sequence simultaneously, self-attention reduces the computational\n",
      "complexity of the attention mechanism compared to sequential attention.\n",
      "3. Improved parallelization: Self-attention enables better parallelization of the attention mechanism, leading to faster computation times.\n",
      "4. Better handling of long-range dependencies: Self-attention allows the Transformer to capture long-range dependencies in the input sequence more\n",
      "effectively than sequential attention.\n",
      "5. Reduced need for explicit recurrency: Self-attention eliminates the need for explicit recurrency in the Transformer, making it more efficient and\n",
      "scalable.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In Transformers, attention refers to a mechanism that maps a query and a set of key-value pairs\n",
      "to an output. The query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values based on the similarity\n",
      "between the query and the keys. This allows the model to selectively focus on specific parts of the input when generating the output.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Transformer uses residual dropout as a regularization technique.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Transformer model improved machine translation accuracy by\n",
      "relying solely on attention mechanisms, rather than recurrent or convolutional layers. This allowed for faster training times and improved\n",
      "parallelizability, resulting in higher quality translations. Specifically, the Transformer model achieved a BLEU score of 28.4 on the WMT 2014\n",
      "English-to-German translation task, surpassing previous state-of-the-art models, including ensembles. Additionally, the Transformer model established\n",
      "a new single-model state-of-the-art BLEU score of 41.8 on the WMT 2014 English-to-French translation task, outperforming all previously published\n",
      "single models at less than 1/4 the training cost of the previous state-of-the-art model.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "  Yes, the Transformer model can be applied beyond machine\n",
      "translation. In fact, the authors of the paper propose applying it to other tasks such as English constituency parsing, and they mention plans to\n",
      "extend the Transformer to problems involving input and output modalities other than text. They also mention investigating local, restricted attention\n",
      "mechanisms to efficiently handle large inputs and outputs such as images, audio, and video.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n",
      "/content/papers/Attention.pdf\n"
     ]
    }
   ],
   "source": [
    "# Attention Questions\n",
    "\n",
    "questions_file_path = '/content/questions/AttQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWlOMKZNAa48",
    "outputId": "6954da78-7387-49bf-9971-4492fc10fc94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What innovation does the Transformer model introduce?\n",
      " response:   The Transformer model introduces the self-attention mechanism, which allows\n",
      "the model to attend to different parts of the input sequence simultaneously and weigh their importance when computing the output. This is in contrast\n",
      "to traditional recurrent neural network (RNN) architectures, which process the input sequence sequentially and do not have a direct way to weight the\n",
      "importance of different parts of the input.\n",
      "\n",
      "\n",
      "Q1: How does the Transformer model enhance training efficiency?\n",
      " response:   The Transformer model enhances training efficiency by using an attention\n",
      "mechanism that allows it to focus on specific parts of the input sequence, rather than considering the entire sequence simultaneously. This reduces\n",
      "the computational complexity of the model and makes it faster to train. Additionally, the Transformer uses a parallelization technique called multi-\n",
      "head attention, which enables it to process multiple sequences in parallel, further increasing its training efficiency.\n",
      "\n",
      "\n",
      "Q2: What are key components of the Transformer’s encoder?\n",
      " response:   The Transformer's encoder consists of multiple layers, each comprising of two\n",
      "sub-layers: a multi-head self-attention mechanism and a position-wise fully connected feed-forward network. The output of each sub-layer is then layer\n",
      "normalized and passed through a residual connection. Additionally, the encoder utilizes end-to-end memory networks, which rely on a recurrent\n",
      "attention mechanism rather than sequence-aligned RNNs or convolution.\n",
      "\n",
      "\n",
      "Q3: What is the function of multi-head attention in the Transformer?\n",
      " response:   In the Transformer, multi-head attention is used in three different\n",
      "ways:\n",
      "\n",
      "1. In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the\n",
      "encoder. This allows every position in the decoder to attend over all positions in the input sequence.\n",
      "2. The encoder contains self-attention layers, where each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
      "3. Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including\n",
      "that position.\n",
      "\n",
      "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions, which helps to\n",
      "improve the model's ability to capture long-range dependencies in the input sequence.\n",
      "\n",
      "\n",
      "Q4: How does the Transformer handle sequence order?\n",
      " response:   The Transformer handles sequence order through the use of self-attention mechanisms.\n",
      "Self-attention allows each position in the sequence to attend to all positions in the sequence, regardless of their order. This allows the model to\n",
      "capture long-range dependencies and handle variable-length input sequences.\n",
      "\n",
      "\n",
      "Q5: What are the benefits of self-attention in the Transformer?\n",
      " response:   Self-attention in the Transformer provides several benefits:\n",
      "\n",
      "1. Ability to model complex data: Self-attention allows the Transformer to dense within a context window, enabling it to model complex data\n",
      "effectively.\n",
      "2. Reduced computational complexity: By attending to all positions in the input sequence simultaneously, self-attention reduces the computational\n",
      "complexity of the attention mechanism compared to sequential attention.\n",
      "3. Improved parallelization: Self-attention enables better parallelization of the attention mechanism, leading to faster computation times.\n",
      "4. Better handling of long-range dependencies: Self-attention allows the Transformer to capture long-range dependencies in the input sequence more\n",
      "effectively than sequential attention.\n",
      "5. Reduced need for explicit recurrency: Self-attention eliminates the need for explicit recurrency in the Transformer, making it more efficient and\n",
      "scalable.\n",
      "\n",
      "\n",
      "Q6: What is attention in Transformers?\n",
      " response:   In Transformers, attention refers to a mechanism that maps a query and a set of key-value pairs\n",
      "to an output. The query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values based on the similarity\n",
      "between the query and the keys. This allows the model to selectively focus on specific parts of the input when generating the output.\n",
      "\n",
      "\n",
      "Q7: What regularization techniques are used in the Transformer?\n",
      " response:   The Transformer uses residual dropout as a regularization technique.\n",
      "\n",
      "\n",
      "Q8: How did the Transformer model improve machine translation accuracy?\n",
      " response:   The Transformer model improved machine translation accuracy by\n",
      "relying solely on attention mechanisms, rather than recurrent or convolutional layers. This allowed for faster training times and improved\n",
      "parallelizability, resulting in higher quality translations. Specifically, the Transformer model achieved a BLEU score of 28.4 on the WMT 2014\n",
      "English-to-German translation task, surpassing previous state-of-the-art models, including ensembles. Additionally, the Transformer model established\n",
      "a new single-model state-of-the-art BLEU score of 41.8 on the WMT 2014 English-to-French translation task, outperforming all previously published\n",
      "single models at less than 1/4 the training cost of the previous state-of-the-art model.\n",
      "\n",
      "\n",
      "Q9: Can the Transformer model be applied beyond machine translation?\n",
      " response:   Yes, the Transformer model can be applied beyond machine\n",
      "translation. In fact, the authors of the paper propose applying it to other tasks such as English constituency parsing, and they mention plans to\n",
      "extend the Transformer to problems involving input and output modalities other than text. They also mention investigating local, restricted attention\n",
      "mechanisms to efficiently handle large inputs and outputs such as images, audio, and video.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnmw05WDCRbt"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'AttQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9Zjmnb0CTyb"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'AttQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5BK_Q6FCZJm"
   },
   "source": [
    "###Coherent Spin Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePOCH8wECb92",
    "outputId": "7e4726ad-d767-4523-c99d-257976d3a6d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The objective of using Heisenberg exchange in quantum\n",
      "computing is to transmit the spin state of an electron back and forth along an array of electrons in a quadruple quantum dot, thereby transferring\n",
      "single-spin eigenstates and entangled states via coherent SW AP gates between all neighboring pairs of spins in a four-qubit array. This method allows\n",
      "for the transmission of information without moving the objects themselves, providing a means of storing and manipulating information in a resource-\n",
      "efficient manner.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  External factors that can\n",
      "influence the Heisenberg exchange interaction during quantum spin-state transfer include:\n",
      "\n",
      "1. Magnetic field gradients: A change in the magnetic field gradient between the dots can cause the Heisenberg exchange interaction to drive\n",
      "transitions to the singlet or unpolarized triplet configurations of the two spins.\n",
      "2. Nuclear spin noise: Fluctuations in the nuclear spin environment can affect the Heisenberg exchange interaction and limit the fidelity of spin-\n",
      "state transfer.\n",
      "3. Temporal fluctuations in the magnetic gradient: Random changes in the magnetic field gradient over time can impact the Heisenberg exchange\n",
      "interaction and reduce the fidelity of spin-state transfer.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Coherent spin-state transfer via Heisenberg\n",
      "exchange has the potential to significantly advance quantum technology by providing a means of efficiently transferring the quantum state of a system\n",
      "without physically moving the system itself. This can be particularly useful in spin-based quantum computing, where multi-qubit gates and quantum\n",
      "error correction rely heavily on the ability to manipulate the state of individual spins within a larger array. By demonstrating the successful\n",
      "transfer of single-spin eigenstates and entangled states between neighboring spins in a four-qubit array, Yadav et al.'s experiment paves the way for\n",
      "more complex quantum computations and robust quantum information processing. Additionally, the compatibility of this method with arbitrary single- and\n",
      "multi-qubit states and its scalability to large arrays of qubits makes it an attractive option for future research and development in the field.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  A quantum system is prepared for spin-state transfer through the\n",
      "application of specific operations, such as S 23 operations, which manipulate the nuclear magnetic fields experienced by the spins in the system.\n",
      "These operations are used to initialize the system in a desired state, such as the ∣⟩ ∣⟩ ∣⟩ ↑⊗ ↑↓−↓↑ ()1 state, and then evolve the system under the\n",
      "influence of the magnetic fields for a variable time before applying a final S 23 operation and projecting the resulting state onto a particular\n",
      "subspace of interest.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Heisenberg exchange interaction\n",
      "facilitates quantum computing operations by enabling the transfer of spin states between neighboring electrons in an array of spin qubits. Through\n",
      "coherent SW AP operations, the Heisenberg exchange interaction allows for the transmission of single-spin and entangled states back and forth in the\n",
      "array without moving any electrons. This scalable method enables high connectivity between qubits, which is essential for quantum error correction in\n",
      "large spin-qubit arrays.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Electric fields do not directly influence quantum\n",
      "state dynamics in spin-state transfers. The dynamics of the quantum state are primarily determined by the nuclear magnetic fields and the exchange\n",
      "interaction between the spins. The electric fields are used to control the orientation of the magnetic fields and to apply the necessary pulses for\n",
      "the spin-state transfer. However, the electric fields do not directly affect the quantum state dynamics.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Quantum scalability refers to the ability to\n",
      "scale up the size of a quantum system while maintaining its quantum properties and functionality. In the context of coherent spin-state transfer,\n",
      "quantum scalability is crucial for the development of large-scale spin-based quantum computers.\n",
      "\n",
      "In the article, the authors discuss the potential of using spin qubits based on electrons in quantum dots as a leading platform for quantum\n",
      "information processing. They highlight that single-qubit gate fidelities exceeding 99.9% and two-qubit gate fidelities surpassing 98% have been\n",
      "achieved in small-scale arrays of electrons in quantum dots. However, as the number of qubits is increased, maintaining sufficient connectivity for\n",
      "efficient and fault-tolerant quantum computing becomes challenging.\n",
      "\n",
      "To address this issue, the authors propose the use of coherent spin-state transfer via Heisenberg exchange, which allows for the transfer of single-\n",
      "spin eigenstates and entangled states between neighboring pairs of spins in a four-qubit array. This process is scalable to large numbers of qubits\n",
      "and can be used for multi-qubit gates and quantum error correction in spin-based quantum computers.\n",
      "\n",
      "Overall, the discussion of quantum scalability in the article emphasizes the need for developing techniques that enable the efficient and reliable\n",
      "transfer of quantum states in large-scale spin-based quantum systems.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Heisenberg exchange plays a crucial role in\n",
      "quantum computing applications, particularly in spin-based quantum computers. It enables coherent spin-state transfer between neighboring electrons in\n",
      "an array of spin qubits, which is essential for multi-qubit gates and quantum error correction in large spin-qubit arrays. The Heisenberg exchange\n",
      "interaction tends to swap the spin states of adjacent electrons, allowing for the transfer of single-spin and entangled states back and forth in the\n",
      "array without moving any electrons. This property makes it useful for scaling up spin-based quantum processors, as it allows for efficient and fault-\n",
      "tolerant quantum computing.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In the given passage, the following metaphors are used to\n",
      "explain the initialization of quantum systems:\n",
      "\n",
      "* \"left-side gradient\" (line 10) - This metaphor is used to describe the process of initializing a quantum system with a specific spin orientation.\n",
      "* \"pair of quantum dots\" (lines 11-12) - This metaphor is used to describe the process of initializing two quantum systems with different spin\n",
      "orientations.\n",
      "* \"electron exchange with the reservoirs\" (line 13) - This metaphor is used to describe the process of transferring electrons between the quantum\n",
      "systems and the surrounding environment.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "  According to the article, future developments in quantum\n",
      "mechanics research are expected to include:\n",
      "\n",
      "1. Further advances in the physical meaning of puzzling phenomena, such as quantum measurement, quantum randomness, non-locality, particle\n",
      "indistinguishability, causality, and the nature of time.\n",
      "2. Exploration of the interplay between quantum mechanics and black-hole physics, as well as with thermodynamics.\n",
      "3. Investigation of the emergence of the familiar classical world via quantum principles.\n",
      "4. Progress on topological quantum computing and prospects of a quantum internet.\n",
      "5. Experimental advances in satellite-based quantum communication and verification of basic laws of quantum theory.\n",
      "6. Continued multi-disciplinary community of quantum scientists and engineers progressing in the quest for delivering innovative technologies of\n",
      "global impact.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    }
   ],
   "source": [
    "# Coherent Spin Questions\n",
    "\n",
    "questions_file_path = '/content/questions/CoSpinQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHeW0aTkC7Qe",
    "outputId": "79a43211-0ecc-450d-ab45-e621eb7157d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What is the objective of using Heisenberg exchange in quantum computing?\n",
      " response:   The objective of using Heisenberg exchange in quantum\n",
      "computing is to transmit the spin state of an electron back and forth along an array of electrons in a quadruple quantum dot, thereby transferring\n",
      "single-spin eigenstates and entangled states via coherent SW AP gates between all neighboring pairs of spins in a four-qubit array. This method allows\n",
      "for the transmission of information without moving the objects themselves, providing a means of storing and manipulating information in a resource-\n",
      "efficient manner.\n",
      "\n",
      "\n",
      "Q1: What external factors influence the Heisenberg exchange interaction during quantum spin-state transfer?\n",
      " response:   External factors that can\n",
      "influence the Heisenberg exchange interaction during quantum spin-state transfer include:\n",
      "\n",
      "1. Magnetic field gradients: A change in the magnetic field gradient between the dots can cause the Heisenberg exchange interaction to drive\n",
      "transitions to the singlet or unpolarized triplet configurations of the two spins.\n",
      "2. Nuclear spin noise: Fluctuations in the nuclear spin environment can affect the Heisenberg exchange interaction and limit the fidelity of spin-\n",
      "state transfer.\n",
      "3. Temporal fluctuations in the magnetic gradient: Random changes in the magnetic field gradient over time can impact the Heisenberg exchange\n",
      "interaction and reduce the fidelity of spin-state transfer.\n",
      "\n",
      "\n",
      "Q2: How does coherent spin-state transfer contribute to advancements in quantum technology?\n",
      " response:   Coherent spin-state transfer via Heisenberg\n",
      "exchange has the potential to significantly advance quantum technology by providing a means of efficiently transferring the quantum state of a system\n",
      "without physically moving the system itself. This can be particularly useful in spin-based quantum computing, where multi-qubit gates and quantum\n",
      "error correction rely heavily on the ability to manipulate the state of individual spins within a larger array. By demonstrating the successful\n",
      "transfer of single-spin eigenstates and entangled states between neighboring spins in a four-qubit array, Yadav et al.'s experiment paves the way for\n",
      "more complex quantum computations and robust quantum information processing. Additionally, the compatibility of this method with arbitrary single- and\n",
      "multi-qubit states and its scalability to large arrays of qubits makes it an attractive option for future research and development in the field.\n",
      "\n",
      "\n",
      "Q3: How is a quantum system prepared for spin-state transfer?\n",
      " response:   A quantum system is prepared for spin-state transfer through the\n",
      "application of specific operations, such as S 23 operations, which manipulate the nuclear magnetic fields experienced by the spins in the system.\n",
      "These operations are used to initialize the system in a desired state, such as the ∣⟩ ∣⟩ ∣⟩ ↑⊗ ↑↓−↓↑ ()1 state, and then evolve the system under the\n",
      "influence of the magnetic fields for a variable time before applying a final S 23 operation and projecting the resulting state onto a particular\n",
      "subspace of interest.\n",
      "\n",
      "\n",
      "Q4: How does the Heisenberg exchange interaction facilitate quantum computing operations?\n",
      " response:   The Heisenberg exchange interaction\n",
      "facilitates quantum computing operations by enabling the transfer of spin states between neighboring electrons in an array of spin qubits. Through\n",
      "coherent SW AP operations, the Heisenberg exchange interaction allows for the transmission of single-spin and entangled states back and forth in the\n",
      "array without moving any electrons. This scalable method enables high connectivity between qubits, which is essential for quantum error correction in\n",
      "large spin-qubit arrays.\n",
      "\n",
      "\n",
      "Q5: How do electric fields influence quantum state dynamics in spin-state transfers?\n",
      " response:   Electric fields do not directly influence quantum\n",
      "state dynamics in spin-state transfers. The dynamics of the quantum state are primarily determined by the nuclear magnetic fields and the exchange\n",
      "interaction between the spins. The electric fields are used to control the orientation of the magnetic fields and to apply the necessary pulses for\n",
      "the spin-state transfer. However, the electric fields do not directly affect the quantum state dynamics.\n",
      "\n",
      "\n",
      "Q6: How is quantum scalability addressed in discussions of coherent spin-state transfer?\n",
      " response:   Quantum scalability refers to the ability to\n",
      "scale up the size of a quantum system while maintaining its quantum properties and functionality. In the context of coherent spin-state transfer,\n",
      "quantum scalability is crucial for the development of large-scale spin-based quantum computers.\n",
      "\n",
      "In the article, the authors discuss the potential of using spin qubits based on electrons in quantum dots as a leading platform for quantum\n",
      "information processing. They highlight that single-qubit gate fidelities exceeding 99.9% and two-qubit gate fidelities surpassing 98% have been\n",
      "achieved in small-scale arrays of electrons in quantum dots. However, as the number of qubits is increased, maintaining sufficient connectivity for\n",
      "efficient and fault-tolerant quantum computing becomes challenging.\n",
      "\n",
      "To address this issue, the authors propose the use of coherent spin-state transfer via Heisenberg exchange, which allows for the transfer of single-\n",
      "spin eigenstates and entangled states between neighboring pairs of spins in a four-qubit array. This process is scalable to large numbers of qubits\n",
      "and can be used for multi-qubit gates and quantum error correction in spin-based quantum computers.\n",
      "\n",
      "Overall, the discussion of quantum scalability in the article emphasizes the need for developing techniques that enable the efficient and reliable\n",
      "transfer of quantum states in large-scale spin-based quantum systems.\n",
      "\n",
      "\n",
      "Q7: What role does the Heisenberg exchange play in quantum computing applications?\n",
      " response:   The Heisenberg exchange plays a crucial role in\n",
      "quantum computing applications, particularly in spin-based quantum computers. It enables coherent spin-state transfer between neighboring electrons in\n",
      "an array of spin qubits, which is essential for multi-qubit gates and quantum error correction in large spin-qubit arrays. The Heisenberg exchange\n",
      "interaction tends to swap the spin states of adjacent electrons, allowing for the transfer of single-spin and entangled states back and forth in the\n",
      "array without moving any electrons. This property makes it useful for scaling up spin-based quantum processors, as it allows for efficient and fault-\n",
      "tolerant quantum computing.\n",
      "\n",
      "\n",
      "Q8: What metaphors are used to explain the initialization of quantum systems?\n",
      " response:   In the given passage, the following metaphors are used to\n",
      "explain the initialization of quantum systems:\n",
      "\n",
      "* \"left-side gradient\" (line 10) - This metaphor is used to describe the process of initializing a quantum system with a specific spin orientation.\n",
      "* \"pair of quantum dots\" (lines 11-12) - This metaphor is used to describe the process of initializing two quantum systems with different spin\n",
      "orientations.\n",
      "* \"electron exchange with the reservoirs\" (line 13) - This metaphor is used to describe the process of transferring electrons between the quantum\n",
      "systems and the surrounding environment.\n",
      "\n",
      "\n",
      "Q9: What future developments are expected in quantum mechanics research?\n",
      " response:   According to the article, future developments in quantum\n",
      "mechanics research are expected to include:\n",
      "\n",
      "1. Further advances in the physical meaning of puzzling phenomena, such as quantum measurement, quantum randomness, non-locality, particle\n",
      "indistinguishability, causality, and the nature of time.\n",
      "2. Exploration of the interplay between quantum mechanics and black-hole physics, as well as with thermodynamics.\n",
      "3. Investigation of the emergence of the familiar classical world via quantum principles.\n",
      "4. Progress on topological quantum computing and prospects of a quantum internet.\n",
      "5. Experimental advances in satellite-based quantum communication and verification of basic laws of quantum theory.\n",
      "6. Continued multi-disciplinary community of quantum scientists and engineers progressing in the quest for delivering innovative technologies of\n",
      "global impact.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFoJ5VRiC8Bh"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'CoSpinQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23pmj4wMDDBK"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'CoSpinQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFX0IazTDT2U"
   },
   "source": [
    "###Mamba Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zq9gIgZ7DVVm",
    "outputId": "dc1463da-dcf6-4362-dfdd-6f52e2122bac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mamba achieves computational efficiency\n",
      "without specialized hardware optimizations through several design choices and techniques:\n",
      "\n",
      "1. Simplified architecture: Mamba has a simplified architecture compared to other state-of-the-art transformer models, with fewer layers and less\n",
      "complex computations. This reduces the computational requirements and allows for faster training and inference times.\n",
      "2. Efficient attention mechanism: Mamba uses a novel attention mechanism called SSM (Self-Attention Multi-Head) that is more efficient than\n",
      "traditional attention mechanisms. SSM uses a selective layer to focus on specific parts of the input sequence, reducing the computational complexity\n",
      "of the attention mechanism.\n",
      "3. Optimized batching: Mamba uses a larger batch size than traditional transformer models, allowing for faster training and inference times. The\n",
      "authors claim that Mamba can use batch sizes of up to 128K, which is significantly larger than the batch sizes used in other transformer models.\n",
      "4. Linear projection: Mamba uses a linear projection layer instead of a multi-layer perceptron (MLP) projection layer, which reduces the computational\n",
      "complexity of the model.\n",
      "5. Non-linearity: Mamba uses a simple non-linearity function (SiLU or Swish) instead of more complex activation functions like ReLU or tanh. This\n",
      "reduces the computational complexity of the model and allows for faster training and inference times.\n",
      "\n",
      "Overall, Mamba's computational efficiency is achieved through a combination of simplification, optimization, and careful choice of components. While\n",
      "specialized hardware optimizations can provide additional speedups, Mamba's design choices allow it to achieve competitive performance without relying\n",
      "on them.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mamba introduces several innovations to manage long\n",
      "sequence data processing:\n",
      "\n",
      "1. Selective State Space Models (SSMs): Mamba uses a novel approach called SSMs, which allows the model to perform context-dependent reasoning while\n",
      "scaling linearly in sequence length. This enables the model to handle long sequences efficiently without sacrificing performance.\n",
      "2. Fast Training and Inference: Mamba's design enables fast training and inference, as the computational complexity of the model grows linearly with\n",
      "the sequence length during training and the model can autoregressively generate output sequences without storing previous elements.\n",
      "3. Long Context: Mamba's architecture and training strategy enable it to capture long-range dependencies effectively, resulting in improved\n",
      "performance on real-data tasks up to sequence lengths of 1 million.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The\n",
      "selective state space model in Mamba differs from traditional attention mechanisms in handling sequence data by introducing a novel mechanism called\n",
      "\"selection\" that enables the model to selectively focus on specific parts of the input sequence. Unlike traditional attention mechanisms that\n",
      "weightedly combine the entire input sequence, the selective state space model in Mamba selects a subset of tokens based on their relevance to the\n",
      "current task, allowing it to efficiently process long sequences while ignoring irrelevant information. This selective focus enables the model to\n",
      "achieve better performance on various tasks, including language modeling, copy generation, and machine translation, among others.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  According to the text, one limitation of Mamba's approach to\n",
      "sequence modeling is the potential need for further engineering challenges and adjustments to the model when scaling SSMs for larger sequence lengths.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mamba's architecture simplifies the\n",
      "integration of RNN-like and CNN-like layers by combining them into a single block. The block consists of a repeated sequence of the H3 block, which is\n",
      "the basis of most SSM architectures, followed by an MLP block, which is a common component of neural networks. Instead of interleaving these two\n",
      "blocks, Mamba repeats the Mamba block homogeneously. This allows for a simplified integration of both types of layers, as they are combined into a\n",
      "single block.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  There are several potential challenges that\n",
      "could restrict the open-sourcing and wider adoption of Mamba:\n",
      "\n",
      "1. Technical complexity: Mamba is a complex model that requires significant technical expertise to implement and maintain. Open-sourcing the model may\n",
      "not be feasible if the developers do not have the necessary resources or infrastructure to support it.\n",
      "2. Intellectual property protection: Some companies may be hesitant to open-source their models due to concerns about protecting their intellectual\n",
      "property. They may fear that opening up their models could lead to unauthorized use or exploitation.\n",
      "3. Regulatory compliance: Depending on the jurisdiction, there may be legal or regulatory restrictions on the use and distribution of AI models.\n",
      "Companies may need to navigate these regulations before they can open-source their models.\n",
      "4. Quality control: When open-sourcing a model, the quality of the code and the model itself becomes a concern. Companies may need to invest time and\n",
      "resources into ensuring that the model is reliable and performs well before making it available to others.\n",
      "5. Community engagement: Building a community around an open-sourced model requires effort and dedication. Companies may need to invest in community\n",
      "outreach and engagement to generate interest and participation in the development and maintenance of the model.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Based on the performance\n",
      "evaluation of Mamba in the paper, there are several areas that could benefit from further research and development:\n",
      "\n",
      "1. Scalability: While Mamba shows promising results in smaller sequence lengths, there is a need to explore how well it will scale to even longer\n",
      "sequences. Future work could focus on developing techniques to improve the efficiency of Mamba when dealing with very long sequences.\n",
      "2. Domain adaptability: While Mamba performs well across various domains, there is a possibility that it may not generalize as well to new, unseen\n",
      "domains. Research could investigate methods to improve the adaptability of Mamba to different domains.\n",
      "3. Improving the selection mechanism: The selection mechanism in Mamba is a key component that enables it to perform context-dependent reasoning.\n",
      "However, there is room for improvement in terms of refining the selection process to enhance its performance.\n",
      "4. Multimodal applications: Mamba has shown promise in various modalities, including language and genomics. Future research could explore the\n",
      "application of Mamba to other modalities, such as image and video processing, to leverage its strengths in context-dependent reasoning.\n",
      "5. Combining with other techniques: There is potential to combine Mamba with other techniques, such as attention mechanisms or graph neural networks,\n",
      "to further improve its performance. Investigating the effectiveness of such combinations could lead to novel approaches in natural language processing\n",
      "and related fields.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dynamic parameter adjustment plays a\n",
      "crucial role in Mamba's selective state space models. The mechanism can be viewed as a particular hard-coded instance of a selection mechanism, where\n",
      "$A$ is manually set to 0, instead of a learnable mechanism that depends on the input. By introducing a selection mechanism, Mamba allows the model to\n",
      "perform context-dependent reasoning while scaling linearly in sequence length. This enables the model to adaptively adjust its parameters based on the\n",
      "input, resulting in improved performance compared to traditional state space models.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mamba addresses the\n",
      "inefficiencies of Transformers in moderate to long sequence processing by introducing a novel selective state spaces (SSM) layer, which enables the\n",
      "model to selectively remember relevant tokens while ignoring irrelevant ones. This allows Mamba to efficiently process long sequences without\n",
      "sacrificing performance. Additionally, Mamba uses a global convolution parameterized by an MLP, which helps improve the model's ability to perform\n",
      "content-based reasoning. These improvements enable Mamba to achieve better performance than previous models, including Transformers, on tasks such as\n",
      "language modeling and audio waveform modeling.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "  The design of Mamba has\n",
      "significant implications for its applicability across various data modalities. Here are some key takeaways:\n",
      "\n",
      "1. Scalability: Mamba's selective state space model (SSM) layer allows it to scale linearly in sequence length, making it suitable for handling long\n",
      "sequences common in many data modalities like genomics, audio, and video. This scalability is particularly important for tasks that require processing\n",
      "vast amounts of data.\n",
      "2. Context-dependent reasoning: Mamba's ability to perform context-dependent reasoning through its selective SSM layer makes it well-suited for tasks\n",
      "that benefit from considering the broader context, such as natural language processing (NLP) and machine translation. By selectively focusing on\n",
      "specific parts of the input sequence, Mamba can capture subtle contextual relationships that might otherwise be overlooked.\n",
      "3. Domain adaptability: Mamba's modular architecture enables it to adapt to new domains without requiring extensive retraining. This property makes it\n",
      "an attractive choice for applying the same model to multiple related tasks or datasets, as the selective SSM layer can be fine-tuned for each domain\n",
      "without altering the rest of the architecture.\n",
      "4. Attention efficiency: Mamba's use of a selective SSM layer reduces the computational complexity of attention mechanisms, leading to faster training\n",
      "and inference times. This efficiency advantage becomes particularly valuable when dealing with long sequences or large models, as it enables the use\n",
      "of more powerful hardware without sacrificing performance.\n",
      "5. Versatility: The combination of Mamba's scalability, context-dependent reasoning capabilities, domain adaptability, and attention efficiency makes\n",
      "it a versatile model that can excel in a wide range of data modalities. Its potential applications include NLP, machine learning, computer vision, and\n",
      "more, depending on the specific requirements of the task at hand.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    }
   ],
   "source": [
    "# Mamba Questions\n",
    "\n",
    "questions_file_path = '/content/questions/MambaQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtCHuDu1De8w",
    "outputId": "6249632d-6dca-4084-bd5a-86ee894f2ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: How does Mamba achieve computational efficiency without specialized hardware optimizations?\n",
      " response:   Mamba achieves computational efficiency\n",
      "without specialized hardware optimizations through several design choices and techniques:\n",
      "\n",
      "1. Simplified architecture: Mamba has a simplified architecture compared to other state-of-the-art transformer models, with fewer layers and less\n",
      "complex computations. This reduces the computational requirements and allows for faster training and inference times.\n",
      "2. Efficient attention mechanism: Mamba uses a novel attention mechanism called SSM (Self-Attention Multi-Head) that is more efficient than\n",
      "traditional attention mechanisms. SSM uses a selective layer to focus on specific parts of the input sequence, reducing the computational complexity\n",
      "of the attention mechanism.\n",
      "3. Optimized batching: Mamba uses a larger batch size than traditional transformer models, allowing for faster training and inference times. The\n",
      "authors claim that Mamba can use batch sizes of up to 128K, which is significantly larger than the batch sizes used in other transformer models.\n",
      "4. Linear projection: Mamba uses a linear projection layer instead of a multi-layer perceptron (MLP) projection layer, which reduces the computational\n",
      "complexity of the model.\n",
      "5. Non-linearity: Mamba uses a simple non-linearity function (SiLU or Swish) instead of more complex activation functions like ReLU or tanh. This\n",
      "reduces the computational complexity of the model and allows for faster training and inference times.\n",
      "\n",
      "Overall, Mamba's computational efficiency is achieved through a combination of simplification, optimization, and careful choice of components. While\n",
      "specialized hardware optimizations can provide additional speedups, Mamba's design choices allow it to achieve competitive performance without relying\n",
      "on them.\n",
      "\n",
      "\n",
      "Q1: What innovations does Mamba introduce to manage long sequence data processing?\n",
      " response:   Mamba introduces several innovations to manage long\n",
      "sequence data processing:\n",
      "\n",
      "1. Selective State Space Models (SSMs): Mamba uses a novel approach called SSMs, which allows the model to perform context-dependent reasoning while\n",
      "scaling linearly in sequence length. This enables the model to handle long sequences efficiently without sacrificing performance.\n",
      "2. Fast Training and Inference: Mamba's design enables fast training and inference, as the computational complexity of the model grows linearly with\n",
      "the sequence length during training and the model can autoregressively generate output sequences without storing previous elements.\n",
      "3. Long Context: Mamba's architecture and training strategy enable it to capture long-range dependencies effectively, resulting in improved\n",
      "performance on real-data tasks up to sequence lengths of 1 million.\n",
      "\n",
      "\n",
      "Q2: How does the selective state space model in Mamba differ from traditional attention mechanisms in handling sequence data?\n",
      " response:   The\n",
      "selective state space model in Mamba differs from traditional attention mechanisms in handling sequence data by introducing a novel mechanism called\n",
      "\"selection\" that enables the model to selectively focus on specific parts of the input sequence. Unlike traditional attention mechanisms that\n",
      "weightedly combine the entire input sequence, the selective state space model in Mamba selects a subset of tokens based on their relevance to the\n",
      "current task, allowing it to efficiently process long sequences while ignoring irrelevant information. This selective focus enables the model to\n",
      "achieve better performance on various tasks, including language modeling, copy generation, and machine translation, among others.\n",
      "\n",
      "\n",
      "Q3: What are the limitations of Mamba’s approach to sequence modeling?\n",
      " response:   According to the text, one limitation of Mamba's approach to\n",
      "sequence modeling is the potential need for further engineering challenges and adjustments to the model when scaling SSMs for larger sequence lengths.\n",
      "\n",
      "\n",
      "Q4: How does Mamba’s architecture simplify the integration of RNN-like and CNN-like layers?\n",
      " response:   Mamba's architecture simplifies the\n",
      "integration of RNN-like and CNN-like layers by combining them into a single block. The block consists of a repeated sequence of the H3 block, which is\n",
      "the basis of most SSM architectures, followed by an MLP block, which is a common component of neural networks. Instead of interleaving these two\n",
      "blocks, Mamba repeats the Mamba block homogeneously. This allows for a simplified integration of both types of layers, as they are combined into a\n",
      "single block.\n",
      "\n",
      "\n",
      "Q5: What potential challenges might restrict the open-sourcing and wider adoption of Mamba?\n",
      " response:   There are several potential challenges that\n",
      "could restrict the open-sourcing and wider adoption of Mamba:\n",
      "\n",
      "1. Technical complexity: Mamba is a complex model that requires significant technical expertise to implement and maintain. Open-sourcing the model may\n",
      "not be feasible if the developers do not have the necessary resources or infrastructure to support it.\n",
      "2. Intellectual property protection: Some companies may be hesitant to open-source their models due to concerns about protecting their intellectual\n",
      "property. They may fear that opening up their models could lead to unauthorized use or exploitation.\n",
      "3. Regulatory compliance: Depending on the jurisdiction, there may be legal or regulatory restrictions on the use and distribution of AI models.\n",
      "Companies may need to navigate these regulations before they can open-source their models.\n",
      "4. Quality control: When open-sourcing a model, the quality of the code and the model itself becomes a concern. Companies may need to invest time and\n",
      "resources into ensuring that the model is reliable and performs well before making it available to others.\n",
      "5. Community engagement: Building a community around an open-sourced model requires effort and dedication. Companies may need to invest in community\n",
      "outreach and engagement to generate interest and participation in the development and maintenance of the model.\n",
      "\n",
      "\n",
      "Q6: In what ways does Mamba's performance evaluation suggest areas for future research and development?\n",
      " response:   Based on the performance\n",
      "evaluation of Mamba in the paper, there are several areas that could benefit from further research and development:\n",
      "\n",
      "1. Scalability: While Mamba shows promising results in smaller sequence lengths, there is a need to explore how well it will scale to even longer\n",
      "sequences. Future work could focus on developing techniques to improve the efficiency of Mamba when dealing with very long sequences.\n",
      "2. Domain adaptability: While Mamba performs well across various domains, there is a possibility that it may not generalize as well to new, unseen\n",
      "domains. Research could investigate methods to improve the adaptability of Mamba to different domains.\n",
      "3. Improving the selection mechanism: The selection mechanism in Mamba is a key component that enables it to perform context-dependent reasoning.\n",
      "However, there is room for improvement in terms of refining the selection process to enhance its performance.\n",
      "4. Multimodal applications: Mamba has shown promise in various modalities, including language and genomics. Future research could explore the\n",
      "application of Mamba to other modalities, such as image and video processing, to leverage its strengths in context-dependent reasoning.\n",
      "5. Combining with other techniques: There is potential to combine Mamba with other techniques, such as attention mechanisms or graph neural networks,\n",
      "to further improve its performance. Investigating the effectiveness of such combinations could lead to novel approaches in natural language processing\n",
      "and related fields.\n",
      "\n",
      "\n",
      "Q7: What role does dynamic parameter adjustment play in Mamba’s selective state space models?\n",
      " response:   Dynamic parameter adjustment plays a\n",
      "crucial role in Mamba's selective state space models. The mechanism can be viewed as a particular hard-coded instance of a selection mechanism, where\n",
      "$A$ is manually set to 0, instead of a learnable mechanism that depends on the input. By introducing a selection mechanism, Mamba allows the model to\n",
      "perform context-dependent reasoning while scaling linearly in sequence length. This enables the model to adaptively adjust its parameters based on the\n",
      "input, resulting in improved performance compared to traditional state space models.\n",
      "\n",
      "\n",
      "Q8: How does Mamba address the inefficiencies of Transformers in moderate to long sequence processing?\n",
      " response:   Mamba addresses the\n",
      "inefficiencies of Transformers in moderate to long sequence processing by introducing a novel selective state spaces (SSM) layer, which enables the\n",
      "model to selectively remember relevant tokens while ignoring irrelevant ones. This allows Mamba to efficiently process long sequences without\n",
      "sacrificing performance. Additionally, Mamba uses a global convolution parameterized by an MLP, which helps improve the model's ability to perform\n",
      "content-based reasoning. These improvements enable Mamba to achieve better performance than previous models, including Transformers, on tasks such as\n",
      "language modeling and audio waveform modeling.\n",
      "\n",
      "\n",
      "Q9: What implications does the design of Mamba have for its applicability across different data modalities?\n",
      " response:   The design of Mamba has\n",
      "significant implications for its applicability across various data modalities. Here are some key takeaways:\n",
      "\n",
      "1. Scalability: Mamba's selective state space model (SSM) layer allows it to scale linearly in sequence length, making it suitable for handling long\n",
      "sequences common in many data modalities like genomics, audio, and video. This scalability is particularly important for tasks that require processing\n",
      "vast amounts of data.\n",
      "2. Context-dependent reasoning: Mamba's ability to perform context-dependent reasoning through its selective SSM layer makes it well-suited for tasks\n",
      "that benefit from considering the broader context, such as natural language processing (NLP) and machine translation. By selectively focusing on\n",
      "specific parts of the input sequence, Mamba can capture subtle contextual relationships that might otherwise be overlooked.\n",
      "3. Domain adaptability: Mamba's modular architecture enables it to adapt to new domains without requiring extensive retraining. This property makes it\n",
      "an attractive choice for applying the same model to multiple related tasks or datasets, as the selective SSM layer can be fine-tuned for each domain\n",
      "without altering the rest of the architecture.\n",
      "4. Attention efficiency: Mamba's use of a selective SSM layer reduces the computational complexity of attention mechanisms, leading to faster training\n",
      "and inference times. This efficiency advantage becomes particularly valuable when dealing with long sequences or large models, as it enables the use\n",
      "of more powerful hardware without sacrificing performance.\n",
      "5. Versatility: The combination of Mamba's scalability, context-dependent reasoning capabilities, domain adaptability, and attention efficiency makes\n",
      "it a versatile model that can excel in a wide range of data modalities. Its potential applications include NLP, machine learning, computer vision, and\n",
      "more, depending on the specific requirements of the task at hand.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FM3u9a1DgXN"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'MambaQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_vuJeSUDhnN"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'MambaQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOBp2sMoDmC5"
   },
   "source": [
    "###Parametric Magnon Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIE3Or1yDqez",
    "outputId": "ad635c4b-7ee7-4fff-d3a8-790184b6a509"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Based on the given text, the materials\n",
      "typically used to construct quantum transducers in hybrid quantum systems are:\n",
      "\n",
      "1. Yttrium iron garnet (YIG)\n",
      "2. Diamond\n",
      "3. Silicon carbide (SiC)\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Magnon nonlinearities enhance quantum transduction by allowing for\n",
      "selective tuning of the spin-magnon coupling \"on\" and \"off.\" This control over the coupling enables protection of the spin centers against any\n",
      "resonant magnon noise-induced decoherence, leading to improved transduction behavior.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  To minimize the microwave footprint\n",
      "in quantum computing transducers, several techniques are employed:\n",
      "\n",
      "1. Parametric magnon effects: By downconverting the microwave driving frequency using parametrically generated magnon modes, the footprint can be\n",
      "significantly reduced.\n",
      "2. Highly confined magnon stray fields: Using highly confined magnon stray fields to drive the spin qubits at room temperature helps minimize the\n",
      "microwave footprint.\n",
      "3. Indirect scheme: Employing an indirect scheme to mediate the microwave interaction with spin qubits in silicon carbide reduces the microwave\n",
      "footprint by utilizing highly confined magnon stray fields.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Silicon carbide (SiC) is favored in some quantum computing\n",
      "applications due to its unique properties, which make it an ideal platform for certain types of quantum devices. Here are some reasons why SiC is\n",
      "preferred in some cases:\n",
      "\n",
      "1. High thermal conductivity: SiC has a high thermal conductivity, which is essential for cooling quantum bits (qubits) and reducing their heating\n",
      "effects. Qubits can easily get heated during quantum computations, and if they are not properly cooled, their performance can be compromised. SiC's\n",
      "high thermal conductivity makes it an excellent material for dissipating heat away from the qubits.\n",
      "2. Low noise: SiC has a low noise figure, which means it can reduce unwanted electromagnetic interference (EMI) that can affect the performance of\n",
      "quantum devices. Noise can cause errors in quantum computations, so minimizing EMI is crucial for reliable quantum operations.\n",
      "3. High radiation resistance: SiC is highly resistant to radiation damage, which is critical for quantum devices operating in harsh environments.\n",
      "Radiation can cause qubits to lose their quantum states, leading to errors in calculations. By using SiC, researchers can build more robust quantum\n",
      "devices that can withstand radiation exposure better than other materials.\n",
      "4. Large bandgap: The large bandgap of SiC allows it to be used in both electronic and photonic applications. This versatility makes it an attractive\n",
      "material for developing hybrid quantum devices that combine different physical systems. For example, SiC can be used to create quantum wells or\n",
      "quantum wires that can be integrated with superconducting circuits or other materials to develop more complex quantum systems.\n",
      "5. Availability of fabrication techniques: SiC is relatively easy to fabricate using established semiconductor manufacturing techniques. This makes it\n",
      "easier to integrate SiC with other materials and develop complex quantum devices.\n",
      "\n",
      "In summary, SiC is favored in some quantum computing applications due to its unique combination of high thermal conductivity, low noise, high\n",
      "radiation resistance, large bandgap, and availability of fabrication techniques. These properties make it an ideal platform for developing hybrid\n",
      "quantum devices that can take advantage of the strengths of multiple physical systems.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Experimental methods crucial for\n",
      "validating the functionality of quantum transducers include:\n",
      "\n",
      "1. Characterization of the magnon-photon interface: This involves measuring the transfer efficiency of magnons to photons and vice versa, as well as\n",
      "the quality factor of the magnon mode.\n",
      "2. Quantification of the spin-magnon coupling: This can be achieved through measurements of the precession frequency of the spin qubits in response to\n",
      "applied magnetic fields, which will reveal the strength of the spin-magnon coupling.\n",
      "3. Demonstration of quantum gates: To validate the functionality of the quantum transducer, it is essential to demonstrate the ability to perform\n",
      "quantum gates, such as the controlled-NOT gate, using the magnon-photon interface.\n",
      "4. Measurement of the memory capacity: The ability to store and retrieve quantum information over long distances requires the demonstration of a large\n",
      "memory capacity. This can be measured through the implementation of quantum error correction codes.\n",
      "5. Verification of nonlinear magnonics: The unique functionalities provided by nonlinear magnonics, such as the ability to manipulate the magnon\n",
      "wavefunction, must be demonstrated experimentally to validate the effectiveness of the quantum transducer.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Frequency tuning plays a crucial role\n",
      "in quantum transducers utilizing magnon interactions. By precisely controlling the frequency of the external driving field, the magnon population can\n",
      "be tailored, allowing for efficient transfer of energy and information between the quantum system and the magnon bath. This enables the manipulation\n",
      "of the magnon-mediated couplings and decoherence rates, which are essential for achieving high-quality quantum gates and robust quantum computation.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Parametric magnonics introduces an innovative\n",
      "approach in quantum transducers by utilizing nonlinear magnon dynamics to enhance microwave transduction to spin qubits. Unlike traditional hybrid\n",
      "systems that rely on linearly-excited magnons, the proposed hybrid transducer exploits parametrically generated magnons to selectively tune the spin-\n",
      "magnon coupling \"on\" and \"off.\" This provides a new means of controlling the coupling between the spin centers and the magnons, which could\n",
      "potentially protect the spin centers against any resonant magnon noise-induced errors.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Introducing nonlinear magnonics into quantum computing\n",
      "systems can significantly impact their functionality and capabilities. Nonlinear magnonics refers to the study of how magnon interactions can be used\n",
      "to manipulate and control quantum systems beyond the simple linear couplings typically observed in these systems. By incorporating nonlinear magnonics\n",
      "into quantum computing architectures, it becomes possible to achieve stronger coupling strengths and cooperativities between quantum systems, leading\n",
      "to more efficient and robust quantum computing operations. Additionally, nonlinear magnonics can enable new functionalities such as the generation of\n",
      "nonclassical magnon states, which can be used to enhance the performance of quantum algorithms and applications. Overall, the introduction of\n",
      "nonlinear magnonics offers a promising avenue for advancing the development of quantum computing technologies.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Future applications that could benefit from\n",
      "magnon nonlinearities in quantum systems include:\n",
      "\n",
      "1. Enhanced quantum computing: Nonlinear magnonics could be used to create more powerful and efficient quantum computers by leveraging the unique\n",
      "properties of magnon nonlinearities.\n",
      "2. Quantum communication: Magnon nonlinearities could be used to improve the performance of quantum communication systems, such as quantum key\n",
      "distribution and quantum teleportation.\n",
      "3. Quantum metrology: Nonlinear magnonics could be used to enhance the precision of quantum metrology techniques, such as magnetometry and\n",
      "gravitational wave detection.\n",
      "4. Quantum simulation: Magnon nonlinearities could be used to simulate complex quantum systems that are difficult to study using traditional methods.\n",
      "5. Quantum control: Nonlinear magnonics could be used to develop new methods for controlling and manipulating quantum systems, which could lead to\n",
      "breakthroughs in fields such as chemistry and materials science.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "  Recent research in quantum magnonics has\n",
      "expanded the scope of designing quantum interfaces beyond traditional linear magnon dynamics. Nonlinear magnonics offers unique functionalities,\n",
      "including tunable transduction between physical components, which can significantly improve the performance of quantum interfaces. The ability to\n",
      "manipulate magnon interactions through nonlinear processes enables the engineering of hybrid transducers that leverage magnon nonlinearities to\n",
      "enhance microwave transduction to spin qubits. This approach provides a novel perspective for engineering quantum interfaces, offering improved\n",
      "control over the spin-magnon coupling and the potential for enhanced coupling strengths and cooperativities in hybrid quantum systems.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    }
   ],
   "source": [
    "# Parametric Magnon Questions\n",
    "\n",
    "questions_file_path = '/content/questions/ParametricMagnonQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnUQW8FOD_xi",
    "outputId": "1f8b820b-adea-4117-aa10-ebbc5e3ea8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What materials are typically used to construct quantum transducers in hybrid quantum systems?\n",
      " response:   Based on the given text, the materials\n",
      "typically used to construct quantum transducers in hybrid quantum systems are:\n",
      "\n",
      "1. Yttrium iron garnet (YIG)\n",
      "2. Diamond\n",
      "3. Silicon carbide (SiC)\n",
      "\n",
      "\n",
      "Q1: How do magnon nonlinearities enhance quantum transduction?\n",
      " response:   Magnon nonlinearities enhance quantum transduction by allowing for\n",
      "selective tuning of the spin-magnon coupling \"on\" and \"off.\" This control over the coupling enables protection of the spin centers against any\n",
      "resonant magnon noise-induced decoherence, leading to improved transduction behavior.\n",
      "\n",
      "\n",
      "Q2: What techniques are used to minimize the microwave footprint in quantum computing transducers?\n",
      " response:   To minimize the microwave footprint\n",
      "in quantum computing transducers, several techniques are employed:\n",
      "\n",
      "1. Parametric magnon effects: By downconverting the microwave driving frequency using parametrically generated magnon modes, the footprint can be\n",
      "significantly reduced.\n",
      "2. Highly confined magnon stray fields: Using highly confined magnon stray fields to drive the spin qubits at room temperature helps minimize the\n",
      "microwave footprint.\n",
      "3. Indirect scheme: Employing an indirect scheme to mediate the microwave interaction with spin qubits in silicon carbide reduces the microwave\n",
      "footprint by utilizing highly confined magnon stray fields.\n",
      "\n",
      "\n",
      "Q3: Why is silicon carbide favored in some quantum computing applications?\n",
      " response:   Silicon carbide (SiC) is favored in some quantum computing\n",
      "applications due to its unique properties, which make it an ideal platform for certain types of quantum devices. Here are some reasons why SiC is\n",
      "preferred in some cases:\n",
      "\n",
      "1. High thermal conductivity: SiC has a high thermal conductivity, which is essential for cooling quantum bits (qubits) and reducing their heating\n",
      "effects. Qubits can easily get heated during quantum computations, and if they are not properly cooled, their performance can be compromised. SiC's\n",
      "high thermal conductivity makes it an excellent material for dissipating heat away from the qubits.\n",
      "2. Low noise: SiC has a low noise figure, which means it can reduce unwanted electromagnetic interference (EMI) that can affect the performance of\n",
      "quantum devices. Noise can cause errors in quantum computations, so minimizing EMI is crucial for reliable quantum operations.\n",
      "3. High radiation resistance: SiC is highly resistant to radiation damage, which is critical for quantum devices operating in harsh environments.\n",
      "Radiation can cause qubits to lose their quantum states, leading to errors in calculations. By using SiC, researchers can build more robust quantum\n",
      "devices that can withstand radiation exposure better than other materials.\n",
      "4. Large bandgap: The large bandgap of SiC allows it to be used in both electronic and photonic applications. This versatility makes it an attractive\n",
      "material for developing hybrid quantum devices that combine different physical systems. For example, SiC can be used to create quantum wells or\n",
      "quantum wires that can be integrated with superconducting circuits or other materials to develop more complex quantum systems.\n",
      "5. Availability of fabrication techniques: SiC is relatively easy to fabricate using established semiconductor manufacturing techniques. This makes it\n",
      "easier to integrate SiC with other materials and develop complex quantum devices.\n",
      "\n",
      "In summary, SiC is favored in some quantum computing applications due to its unique combination of high thermal conductivity, low noise, high\n",
      "radiation resistance, large bandgap, and availability of fabrication techniques. These properties make it an ideal platform for developing hybrid\n",
      "quantum devices that can take advantage of the strengths of multiple physical systems.\n",
      "\n",
      "\n",
      "Q4: What experimental methods are crucial for validating the functionality of quantum transducers?\n",
      " response:   Experimental methods crucial for\n",
      "validating the functionality of quantum transducers include:\n",
      "\n",
      "1. Characterization of the magnon-photon interface: This involves measuring the transfer efficiency of magnons to photons and vice versa, as well as\n",
      "the quality factor of the magnon mode.\n",
      "2. Quantification of the spin-magnon coupling: This can be achieved through measurements of the precession frequency of the spin qubits in response to\n",
      "applied magnetic fields, which will reveal the strength of the spin-magnon coupling.\n",
      "3. Demonstration of quantum gates: To validate the functionality of the quantum transducer, it is essential to demonstrate the ability to perform\n",
      "quantum gates, such as the controlled-NOT gate, using the magnon-photon interface.\n",
      "4. Measurement of the memory capacity: The ability to store and retrieve quantum information over long distances requires the demonstration of a large\n",
      "memory capacity. This can be measured through the implementation of quantum error correction codes.\n",
      "5. Verification of nonlinear magnonics: The unique functionalities provided by nonlinear magnonics, such as the ability to manipulate the magnon\n",
      "wavefunction, must be demonstrated experimentally to validate the effectiveness of the quantum transducer.\n",
      "\n",
      "\n",
      "Q5: What is the importance of frequency tuning in quantum transducers using magnon interactions?\n",
      " response:   Frequency tuning plays a crucial role\n",
      "in quantum transducers utilizing magnon interactions. By precisely controlling the frequency of the external driving field, the magnon population can\n",
      "be tailored, allowing for efficient transfer of energy and information between the quantum system and the magnon bath. This enables the manipulation\n",
      "of the magnon-mediated couplings and decoherence rates, which are essential for achieving high-quality quantum gates and robust quantum computation.\n",
      "\n",
      "\n",
      "Q6: What innovative approach does parametric magnonics introduce in quantum transducers?\n",
      " response:   Parametric magnonics introduces an innovative\n",
      "approach in quantum transducers by utilizing nonlinear magnon dynamics to enhance microwave transduction to spin qubits. Unlike traditional hybrid\n",
      "systems that rely on linearly-excited magnons, the proposed hybrid transducer exploits parametrically generated magnons to selectively tune the spin-\n",
      "magnon coupling \"on\" and \"off.\" This provides a new means of controlling the coupling between the spin centers and the magnons, which could\n",
      "potentially protect the spin centers against any resonant magnon noise-induced errors.\n",
      "\n",
      "\n",
      "Q7: How does introducing nonlinear magnonics impact quantum computing systems?\n",
      " response:   Introducing nonlinear magnonics into quantum computing\n",
      "systems can significantly impact their functionality and capabilities. Nonlinear magnonics refers to the study of how magnon interactions can be used\n",
      "to manipulate and control quantum systems beyond the simple linear couplings typically observed in these systems. By incorporating nonlinear magnonics\n",
      "into quantum computing architectures, it becomes possible to achieve stronger coupling strengths and cooperativities between quantum systems, leading\n",
      "to more efficient and robust quantum computing operations. Additionally, nonlinear magnonics can enable new functionalities such as the generation of\n",
      "nonclassical magnon states, which can be used to enhance the performance of quantum algorithms and applications. Overall, the introduction of\n",
      "nonlinear magnonics offers a promising avenue for advancing the development of quantum computing technologies.\n",
      "\n",
      "\n",
      "Q8: What future applications could benefit from magnon nonlinearities in quantum systems?\n",
      " response:   Future applications that could benefit from\n",
      "magnon nonlinearities in quantum systems include:\n",
      "\n",
      "1. Enhanced quantum computing: Nonlinear magnonics could be used to create more powerful and efficient quantum computers by leveraging the unique\n",
      "properties of magnon nonlinearities.\n",
      "2. Quantum communication: Magnon nonlinearities could be used to improve the performance of quantum communication systems, such as quantum key\n",
      "distribution and quantum teleportation.\n",
      "3. Quantum metrology: Nonlinear magnonics could be used to enhance the precision of quantum metrology techniques, such as magnetometry and\n",
      "gravitational wave detection.\n",
      "4. Quantum simulation: Magnon nonlinearities could be used to simulate complex quantum systems that are difficult to study using traditional methods.\n",
      "5. Quantum control: Nonlinear magnonics could be used to develop new methods for controlling and manipulating quantum systems, which could lead to\n",
      "breakthroughs in fields such as chemistry and materials science.\n",
      "\n",
      "\n",
      "Q9: How does recent research in quantum magnonics influence the design of quantum interfaces?\n",
      " response:   Recent research in quantum magnonics has\n",
      "expanded the scope of designing quantum interfaces beyond traditional linear magnon dynamics. Nonlinear magnonics offers unique functionalities,\n",
      "including tunable transduction between physical components, which can significantly improve the performance of quantum interfaces. The ability to\n",
      "manipulate magnon interactions through nonlinear processes enables the engineering of hybrid transducers that leverage magnon nonlinearities to\n",
      "enhance microwave transduction to spin qubits. This approach provides a novel perspective for engineering quantum interfaces, offering improved\n",
      "control over the spin-magnon coupling and the potential for enhanced coupling strengths and cooperativities in hybrid quantum systems.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNKuB30JEBWi"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'ParametricMagnonQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ns4l3PKbEC_G"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'ParametricMagnonQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQD1a_eoEKsM"
   },
   "source": [
    "###Quantum Mechanics Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6z4CERedEPiX",
    "outputId": "b5c9f76f-98b5-43a5-a76b-47c3390536af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Quantum mechanics has had a profound impact on modern\n",
      "technology, particularly in the fields of computing, cryptography, and sensing. Here are some key ways in which quantum mechanics has influenced\n",
      "technology:\n",
      "\n",
      "1. Superfast quantum computers: Quantum computers have the potential to solve complex problems much faster than classical computers. This is because\n",
      "quantum bits (qubits) can exist in multiple states simultaneously, allowing them to process vast amounts of data quickly.\n",
      "2. Unbreakable quantum cryptography: Quantum cryptography provides secure communication channels that are resistant to eavesdropping. This is because\n",
      "any attempt to measure a quantum system will disturb its state, making it detectable if someone is trying to intercept the communication.\n",
      "3. Ultrasensitive quantum sensors: Quantum sensors can measure incredibly small changes in physical quantities, such as magnetic fields or\n",
      "temperature. This makes them ideal for applications such as medical imaging, navigation, and materials science.\n",
      "4. Topological quantum computing: Topological quantum computing is a new approach to quantum computing that uses non-Abelian anyons, which are exotic\n",
      "particles that can store and manipulate quantum information. This could lead to the development of fault-tolerant quantum computers that are more\n",
      "robust against errors.\n",
      "5. Quantum internet: The idea of a quantum internet refers to the use of quantum entanglement to create a secure and fast network for transmitting\n",
      "information. This could potentially revolutionize the way we communicate and transfer data.\n",
      "\n",
      "Overall, the significance of quantum mechanics in modern technology lies in its ability to provide new and innovative solutions to old problems. By\n",
      "harnessing the strange properties of quantum systems, researchers and engineers are developing new technologies that could change the way we live and\n",
      "work.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Quantum mechanics has greatly influenced the creation of new fields of\n",
      "study, particularly in the areas of quantum information theory and quantum thermodynamics. These fields have emerged as a result of the improved\n",
      "understanding of the resource power of quantum phenomena, which has triggered technological developments rivaling the three major industrial\n",
      "revolutions of the past century. Quantum mechanics has also led to the development of novel mathematical and computational tools applicable to various\n",
      "domains, including condensed matter physics, statistical mechanics, and cosmology.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Quantum science research has led to significant\n",
      "advancements in various scientific domains, including:\n",
      "\n",
      "1. Condensed matter physics: Quantum mechanics has helped understand the behavior of materials at the atomic scale, leading to improvements in\n",
      "electronic devices, energy storage, and optical materials.\n",
      "2. Statistical mechanics: Quantum statistics have enabled the study of complex systems, such as biological molecules, and have revealed new insights\n",
      "into phase transitions and critical phenomena.\n",
      "3. Cosmology: Quantum mechanics has played a crucial role in understanding the origins of the universe, particularly in the early stages of cosmic\n",
      "evolution.\n",
      "4. Computational methods: Quantum algorithms and simulations have been developed, providing faster solutions to certain problems in chemistry,\n",
      "materials science, and optimization.\n",
      "5. Cryptography: Quantum cryptography has emerged as a secure means of communication, thanks to the principles of quantum mechanics, offering\n",
      "protection against eavesdropping and hacking.\n",
      "6. Sensors: Quantum sensors have shown great promise in detecting and measuring tiny changes in magnetic fields, electric fields, and temperature,\n",
      "opening up new possibilities in fields like medicine, geophysics, and environmental monitoring.\n",
      "7. Materials science: Quantum effects have contributed to the development of advanced materials with unique properties, such as superconductors,\n",
      "nanomaterials, and metamaterials.\n",
      "8. Optics: Quantum optics has expanded our understanding of light-matter interactions, enabling the design of new lasers, optical fibers, and imaging\n",
      "techniques.\n",
      "9. Chemistry: Quantum mechanics has facilitated the development of new chemical reactions, catalysts, and drug discovery methods.\n",
      "10. Biology: Quantum mechanics has shed light on the behavior of biological systems, including photosynthesis, protein folding, and the structure of\n",
      "DNA.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Advancements in quantum technologies have the\n",
      "potential to greatly impact society in various ways, including but not limited to:\n",
      "\n",
      "1. Healthcare: Quantum computing and sensing technologies could lead to breakthroughs in drug discovery, personalized medicine, and medical imaging.\n",
      "2. Energy: Quantum computing could optimize energy consumption and production, leading to more efficient use of resources and reduced carbon\n",
      "footprint.\n",
      "3. Communication: Quantum cryptography could provide unbreakable security for communication networks, protecting sensitive information from hacking\n",
      "and cyber attacks.\n",
      "4. Finance: Quantum computing could accelerate financial modeling and risk analysis, enabling more accurate investment decisions and reducing economic\n",
      "risks.\n",
      "5. Materials Science: Quantum computing could simulate the behavior of materials at the atomic level, leading to the discovery of new materials with\n",
      "unique properties.\n",
      "6. Environmental Monitoring: Quantum sensors could monitor environmental changes at the molecular level, enabling more effective conservation and\n",
      "management of natural resources.\n",
      "7. Food Security: Quantum sensors could detect contaminants in food supplies, ensuring safer and more reliable food distribution.\n",
      "8. Cybersecurity: Quantum computing could solve complex cybersecurity problems, protecting against cyber threats and maintaining confidentiality of\n",
      "sensitive information.\n",
      "9. Education: Quantum computing could revolutionize education by providing interactive and immersive learning experiences, making learning more\n",
      "engaging and accessible.\n",
      "10. Manufacturing: Quantum computing could optimize manufacturing processes, leading to increased efficiency, reduced costs, and faster production\n",
      "times.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Quantum phenomena underpin emerging technological innovations\n",
      "in several ways:\n",
      "\n",
      "1. Quantum Computing: Quantum computers have the potential to solve complex problems that are currently unsolvable with traditional computers. This is\n",
      "because quantum bits (qubits) can exist in multiple states simultaneously, allowing for faster processing times and more efficient problem-solving.\n",
      "2. Quantum Cryptography: Quantum cryptography provides unbreakable encryption methods, ensuring secure communication over long distances. This is\n",
      "achieved through the use of entangled particles, which cannot be replicated or hacked.\n",
      "3. Ultrasensitive Quantum Sensors: Quantum sensors have the ability to detect extremely small changes in magnetic fields, electric fields, and\n",
      "temperature. These sensors have numerous applications in fields such as medicine, navigation, and materials science.\n",
      "4. Black Hole Physics: The study of the interplay between quantum mechanics and black hole physics has led to a deeper understanding of the behavior\n",
      "of matter and energy under extreme conditions. This research has potential applications in areas such as astrophysics and cosmology.\n",
      "5. Thermodynamics: The study of the interplay between quantum mechanics and thermodynamics has led to a better understanding of the behavior of\n",
      "systems at the nanoscale. This research has potential applications in areas such as energy storage and conversion.\n",
      "\n",
      "Overall, the study of quantum phenomena continues to lead to breakthroughs in various fields, and the potential applications of these phenomena are\n",
      "vast and varied.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Technology giants such as Google, IBM, and Microsoft\n",
      "are playing a significant role in the advancement of quantum technologies. They are actively involved in embracing the challenge of making quantum\n",
      "technology a household commodity in the near future. These companies are investing heavily in research and development, and their involvement has\n",
      "helped to accelerate the pace of innovation in the field of quantum computing, quantum cryptography, and quantum sensors.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  According to the text, some of the fundamental\n",
      "questions about quantum mechanics that remain open include:\n",
      "\n",
      "* The interpretation of quantum mechanics' elusive foundations\n",
      "* The nature of time\n",
      "* Causality\n",
      "* Quantum measurement\n",
      "* Quantum randomness\n",
      "* Non-locality\n",
      "* Particle indistinguishability\n",
      "\n",
      "These questions are still being debated and researched by the international community of quantum scientists and engineers, who are working to shed\n",
      "light on the physical meaning of fundamental quantum principles and to push the boundaries of the quantum description of the world.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Exploring quantum mechanics contributes to theoretical\n",
      "physics by providing insights into the fundamental nature of matter and energy, leading to a deeper understanding of the behavior of particles at the\n",
      "atomic and subatomic level. Quantum mechanics is a crucial tool for developing new technologies, such as transistors, lasers, and computer chips,\n",
      "which have transformed modern society. By pushing the boundaries of knowledge in this field, researchers can discover novel phenomena and develop new\n",
      "ideas that can lead to breakthroughs in various areas of science and engineering. Additionally, studying quantum mechanics helps refine mathematical\n",
      "models and computational techniques, which are essential tools for solving complex problems across multiple disciplines. Ultimately, the pursuit of\n",
      "knowledge in quantum mechanics has far-reaching implications beyond the laboratory walls, fostering innovation and driving technological advancements\n",
      "that benefit humanity as a whole.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Experimental advances in verifying quantum theory include:\n",
      "\n",
      "1. Quantum computing: Developments in building functional quantum computers have demonstrated the ability to perform certain calculations\n",
      "exponentially faster than classical computers.\n",
      "2. Quantum simulation: Experiments have shown the potential to simulate complex quantum systems, such as many-body localized systems, using small-\n",
      "scale quantum devices.\n",
      "3. Quantum metrology: Advances in precision measurement techniques have demonstrated the ability to make precise measurements of quantum systems, such\n",
      "as phase and frequency, using quantum sensors.\n",
      "4. Quantum communication: Development of secure quantum communication protocols, such as quantum key distribution, have shown the potential to provide\n",
      "unbreakable encryption methods.\n",
      "5. Quantum optics: Studies of quantum optical systems, such as cavity quantum electrodynamics, have revealed new insights into quantum behavior and\n",
      "have led to the development of new quantum technologies.\n",
      "6. Quantum gravity: Investigations into the intersection of quantum mechanics and general relativity have shed light on the nature of spacetime at the\n",
      "smallest scales and have implications for our understanding of the universe.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "  According to the article, future developments in quantum technology\n",
      "include:\n",
      "\n",
      "* Superfast quantum computers\n",
      "* Unbreakable quantum cryptography\n",
      "* Ultrasensitive quantum sensors\n",
      "* Topological quantum computing\n",
      "* Quantum internet\n",
      "* Experimental advances in satellite-based quantum communication and verification of basic laws of quantum theory.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    }
   ],
   "source": [
    "# Quantum Mechanics Questions\n",
    "\n",
    "questions_file_path = '/content/questions/QuantumMechanicsQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbmQY-poEX05",
    "outputId": "c3398e20-53e9-4117-bff8-e580deb31daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What is the significance of quantum mechanics in modern technology?\n",
      " response:   Quantum mechanics has had a profound impact on modern\n",
      "technology, particularly in the fields of computing, cryptography, and sensing. Here are some key ways in which quantum mechanics has influenced\n",
      "technology:\n",
      "\n",
      "1. Superfast quantum computers: Quantum computers have the potential to solve complex problems much faster than classical computers. This is because\n",
      "quantum bits (qubits) can exist in multiple states simultaneously, allowing them to process vast amounts of data quickly.\n",
      "2. Unbreakable quantum cryptography: Quantum cryptography provides secure communication channels that are resistant to eavesdropping. This is because\n",
      "any attempt to measure a quantum system will disturb its state, making it detectable if someone is trying to intercept the communication.\n",
      "3. Ultrasensitive quantum sensors: Quantum sensors can measure incredibly small changes in physical quantities, such as magnetic fields or\n",
      "temperature. This makes them ideal for applications such as medical imaging, navigation, and materials science.\n",
      "4. Topological quantum computing: Topological quantum computing is a new approach to quantum computing that uses non-Abelian anyons, which are exotic\n",
      "particles that can store and manipulate quantum information. This could lead to the development of fault-tolerant quantum computers that are more\n",
      "robust against errors.\n",
      "5. Quantum internet: The idea of a quantum internet refers to the use of quantum entanglement to create a secure and fast network for transmitting\n",
      "information. This could potentially revolutionize the way we communicate and transfer data.\n",
      "\n",
      "Overall, the significance of quantum mechanics in modern technology lies in its ability to provide new and innovative solutions to old problems. By\n",
      "harnessing the strange properties of quantum systems, researchers and engineers are developing new technologies that could change the way we live and\n",
      "work.\n",
      "\n",
      "\n",
      "Q1: How has quantum mechanics influenced new fields of study?\n",
      " response:   Quantum mechanics has greatly influenced the creation of new fields of\n",
      "study, particularly in the areas of quantum information theory and quantum thermodynamics. These fields have emerged as a result of the improved\n",
      "understanding of the resource power of quantum phenomena, which has triggered technological developments rivaling the three major industrial\n",
      "revolutions of the past century. Quantum mechanics has also led to the development of novel mathematical and computational tools applicable to various\n",
      "domains, including condensed matter physics, statistical mechanics, and cosmology.\n",
      "\n",
      "\n",
      "Q2: What advancements have quantum science research brought to other scientific domains?\n",
      " response:   Quantum science research has led to significant\n",
      "advancements in various scientific domains, including:\n",
      "\n",
      "1. Condensed matter physics: Quantum mechanics has helped understand the behavior of materials at the atomic scale, leading to improvements in\n",
      "electronic devices, energy storage, and optical materials.\n",
      "2. Statistical mechanics: Quantum statistics have enabled the study of complex systems, such as biological molecules, and have revealed new insights\n",
      "into phase transitions and critical phenomena.\n",
      "3. Cosmology: Quantum mechanics has played a crucial role in understanding the origins of the universe, particularly in the early stages of cosmic\n",
      "evolution.\n",
      "4. Computational methods: Quantum algorithms and simulations have been developed, providing faster solutions to certain problems in chemistry,\n",
      "materials science, and optimization.\n",
      "5. Cryptography: Quantum cryptography has emerged as a secure means of communication, thanks to the principles of quantum mechanics, offering\n",
      "protection against eavesdropping and hacking.\n",
      "6. Sensors: Quantum sensors have shown great promise in detecting and measuring tiny changes in magnetic fields, electric fields, and temperature,\n",
      "opening up new possibilities in fields like medicine, geophysics, and environmental monitoring.\n",
      "7. Materials science: Quantum effects have contributed to the development of advanced materials with unique properties, such as superconductors,\n",
      "nanomaterials, and metamaterials.\n",
      "8. Optics: Quantum optics has expanded our understanding of light-matter interactions, enabling the design of new lasers, optical fibers, and imaging\n",
      "techniques.\n",
      "9. Chemistry: Quantum mechanics has facilitated the development of new chemical reactions, catalysts, and drug discovery methods.\n",
      "10. Biology: Quantum mechanics has shed light on the behavior of biological systems, including photosynthesis, protein folding, and the structure of\n",
      "DNA.\n",
      "\n",
      "\n",
      "Q3: What are the potential societal impacts of advancements in quantum technologies?\n",
      " response:   Advancements in quantum technologies have the\n",
      "potential to greatly impact society in various ways, including but not limited to:\n",
      "\n",
      "1. Healthcare: Quantum computing and sensing technologies could lead to breakthroughs in drug discovery, personalized medicine, and medical imaging.\n",
      "2. Energy: Quantum computing could optimize energy consumption and production, leading to more efficient use of resources and reduced carbon\n",
      "footprint.\n",
      "3. Communication: Quantum cryptography could provide unbreakable security for communication networks, protecting sensitive information from hacking\n",
      "and cyber attacks.\n",
      "4. Finance: Quantum computing could accelerate financial modeling and risk analysis, enabling more accurate investment decisions and reducing economic\n",
      "risks.\n",
      "5. Materials Science: Quantum computing could simulate the behavior of materials at the atomic level, leading to the discovery of new materials with\n",
      "unique properties.\n",
      "6. Environmental Monitoring: Quantum sensors could monitor environmental changes at the molecular level, enabling more effective conservation and\n",
      "management of natural resources.\n",
      "7. Food Security: Quantum sensors could detect contaminants in food supplies, ensuring safer and more reliable food distribution.\n",
      "8. Cybersecurity: Quantum computing could solve complex cybersecurity problems, protecting against cyber threats and maintaining confidentiality of\n",
      "sensitive information.\n",
      "9. Education: Quantum computing could revolutionize education by providing interactive and immersive learning experiences, making learning more\n",
      "engaging and accessible.\n",
      "10. Manufacturing: Quantum computing could optimize manufacturing processes, leading to increased efficiency, reduced costs, and faster production\n",
      "times.\n",
      "\n",
      "\n",
      "Q4: How do quantum phenomena underpin emerging technological innovations?\n",
      " response:   Quantum phenomena underpin emerging technological innovations\n",
      "in several ways:\n",
      "\n",
      "1. Quantum Computing: Quantum computers have the potential to solve complex problems that are currently unsolvable with traditional computers. This is\n",
      "because quantum bits (qubits) can exist in multiple states simultaneously, allowing for faster processing times and more efficient problem-solving.\n",
      "2. Quantum Cryptography: Quantum cryptography provides unbreakable encryption methods, ensuring secure communication over long distances. This is\n",
      "achieved through the use of entangled particles, which cannot be replicated or hacked.\n",
      "3. Ultrasensitive Quantum Sensors: Quantum sensors have the ability to detect extremely small changes in magnetic fields, electric fields, and\n",
      "temperature. These sensors have numerous applications in fields such as medicine, navigation, and materials science.\n",
      "4. Black Hole Physics: The study of the interplay between quantum mechanics and black hole physics has led to a deeper understanding of the behavior\n",
      "of matter and energy under extreme conditions. This research has potential applications in areas such as astrophysics and cosmology.\n",
      "5. Thermodynamics: The study of the interplay between quantum mechanics and thermodynamics has led to a better understanding of the behavior of\n",
      "systems at the nanoscale. This research has potential applications in areas such as energy storage and conversion.\n",
      "\n",
      "Overall, the study of quantum phenomena continues to lead to breakthroughs in various fields, and the potential applications of these phenomena are\n",
      "vast and varied.\n",
      "\n",
      "\n",
      "Q5: What role do technology giants play in the advancement of quantum technologies?\n",
      " response:   Technology giants such as Google, IBM, and Microsoft\n",
      "are playing a significant role in the advancement of quantum technologies. They are actively involved in embracing the challenge of making quantum\n",
      "technology a household commodity in the near future. These companies are investing heavily in research and development, and their involvement has\n",
      "helped to accelerate the pace of innovation in the field of quantum computing, quantum cryptography, and quantum sensors.\n",
      "\n",
      "\n",
      "Q6: What are the fundamental questions about quantum mechanics that remain open?\n",
      " response:   According to the text, some of the fundamental\n",
      "questions about quantum mechanics that remain open include:\n",
      "\n",
      "* The interpretation of quantum mechanics' elusive foundations\n",
      "* The nature of time\n",
      "* Causality\n",
      "* Quantum measurement\n",
      "* Quantum randomness\n",
      "* Non-locality\n",
      "* Particle indistinguishability\n",
      "\n",
      "These questions are still being debated and researched by the international community of quantum scientists and engineers, who are working to shed\n",
      "light on the physical meaning of fundamental quantum principles and to push the boundaries of the quantum description of the world.\n",
      "\n",
      "\n",
      "Q7: How does exploring quantum mechanics contribute to theoretical physics?\n",
      " response:   Exploring quantum mechanics contributes to theoretical\n",
      "physics by providing insights into the fundamental nature of matter and energy, leading to a deeper understanding of the behavior of particles at the\n",
      "atomic and subatomic level. Quantum mechanics is a crucial tool for developing new technologies, such as transistors, lasers, and computer chips,\n",
      "which have transformed modern society. By pushing the boundaries of knowledge in this field, researchers can discover novel phenomena and develop new\n",
      "ideas that can lead to breakthroughs in various areas of science and engineering. Additionally, studying quantum mechanics helps refine mathematical\n",
      "models and computational techniques, which are essential tools for solving complex problems across multiple disciplines. Ultimately, the pursuit of\n",
      "knowledge in quantum mechanics has far-reaching implications beyond the laboratory walls, fostering innovation and driving technological advancements\n",
      "that benefit humanity as a whole.\n",
      "\n",
      "\n",
      "Q8: What experimental advances have been made in verifying quantum theory?\n",
      " response:   Experimental advances in verifying quantum theory include:\n",
      "\n",
      "1. Quantum computing: Developments in building functional quantum computers have demonstrated the ability to perform certain calculations\n",
      "exponentially faster than classical computers.\n",
      "2. Quantum simulation: Experiments have shown the potential to simulate complex quantum systems, such as many-body localized systems, using small-\n",
      "scale quantum devices.\n",
      "3. Quantum metrology: Advances in precision measurement techniques have demonstrated the ability to make precise measurements of quantum systems, such\n",
      "as phase and frequency, using quantum sensors.\n",
      "4. Quantum communication: Development of secure quantum communication protocols, such as quantum key distribution, have shown the potential to provide\n",
      "unbreakable encryption methods.\n",
      "5. Quantum optics: Studies of quantum optical systems, such as cavity quantum electrodynamics, have revealed new insights into quantum behavior and\n",
      "have led to the development of new quantum technologies.\n",
      "6. Quantum gravity: Investigations into the intersection of quantum mechanics and general relativity have shed light on the nature of spacetime at the\n",
      "smallest scales and have implications for our understanding of the universe.\n",
      "\n",
      "\n",
      "Q9: What future developments are anticipated in quantum technology?\n",
      " response:   According to the article, future developments in quantum technology\n",
      "include:\n",
      "\n",
      "* Superfast quantum computers\n",
      "* Unbreakable quantum cryptography\n",
      "* Ultrasensitive quantum sensors\n",
      "* Topological quantum computing\n",
      "* Quantum internet\n",
      "* Experimental advances in satellite-based quantum communication and verification of basic laws of quantum theory.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyXwnHL1EZKl"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'QuantumMechanicsQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwcTgfULEcY4"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'Quantum MechanicsQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyyA_gUfEiDt"
   },
   "source": [
    "###Qubit Teleportation Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8y3tvjmEEmmW",
    "outputId": "3f895d0d-3122-45d7-8372-0070a5f05f48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Based on the given context, the main components used in\n",
      "quantum networks for teleportation are:\n",
      "\n",
      "1. NV centres (in diamond): Used as communication qubits for teleportation.\n",
      "2. Nearby 13C nuclear spins: Used as memory qubits for storing information.\n",
      "3. Optical connections: Used to connect the nodes in the quantum network.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Entanglement is established between distant nodes in a\n",
      "quantum network through a process called entanglement swapping. This involves using a middle node, which is already entangled with one of the distant\n",
      "nodes, to create a shared entangled state between the other two distant nodes.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Bell-state measurement (BSM) plays a crucial role\n",
      "in quantum teleportation. In the protocol described in the article, the BSM is used to perform a joint measurement on the sender's part of the\n",
      "entangled state and the qubit state to be teleported. The outcome of the BSM is then fed back to the receiver, who applies a gate operation\n",
      "conditioned on the BSM outcome to recover the teleported state. The BSM allows for the transfer of quantum information across a lossy network link,\n",
      "making it possible to reliably send qubits across long distances.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Quantum\n",
      "teleportation is considered advantageous over traditional communication methods in quantum networks because it allows for the reliable transfer of\n",
      "quantum information across lossy network connections without requiring physical transport of the information. This is particularly useful in large-\n",
      "scale quantum networks where the number of nodes and connections can be vast, making it impractical to physically transmit the information between all\n",
      "nodes. By using quantum teleportation, the information can be transferred through a series of joint Bell-state measurements, allowing for efficient\n",
      "and reliable communication across the network.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The innovations that have improved the\n",
      "fidelity and reliability of quantum teleportation include:\n",
      "\n",
      "* Memory qubit readout and protection during entanglement generation\n",
      "* Real-time rejection of false heralding signals\n",
      "\n",
      "These innovations have enabled the successful preparation of the teleporter and the ability to perform unconditional qubit teleportation between non-\n",
      "neighboring nodes in a quantum network.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The main challenge associated\n",
      "with extending quantum teleportation beyond directly connected nodes is the requirement for pre-shared remote entanglement, which is difficult to\n",
      "achieve due to the high resource demands and limited scalability of existing protocols. Additionally, joint qubit readout and coherence times become\n",
      "increasingly limiting factors as the distance between nodes grows, leading to reduced fidelity and reliability in the teleportation process.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Memory qubits play a crucial role in the\n",
      "process of quantum teleportation in a network. They are used to store the quantum state of the qubit being teleported, allowing it to be transmitted\n",
      "accurately across non-neighboring nodes in the network. The memory qubits are entangled with the communication qubit, which is used to generate remote\n",
      "entanglement between the neighboring nodes. This entanglement is then used to perform the teleportation protocol, which involves swapping the state of\n",
      "the memory qubit with the state of the qubit being teleported. By doing so, the quantum state of the qubit is transferred accurately to the\n",
      "destination node, allowing for the successful teleportation of the qubit.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Future applications of quantum teleportation in\n",
      "quantum networks include:\n",
      "\n",
      "1. Multi-node protocols: Teleportation-based protocols can be used to transmit quantum information between multiple nodes in a quantum network,\n",
      "enabling secure communication over long distances.\n",
      "2. Distributed quantum computing: Quantum teleportation can be used to distribute quantum information among multiple nodes in a quantum network,\n",
      "allowing for distributed quantum computing applications.\n",
      "3. Quantum cryptography: Quantum teleportation can be used to enhance the security of quantum cryptographic systems by allowing for the reliable\n",
      "transmission of encrypted quantum information between distant nodes.\n",
      "4. Quantum metrology: Quantum teleportation can be used to improve the precision of quantum measurements by allowing for the reliable transmission of\n",
      "quantum information between distant nodes.\n",
      "5. Quantum communication networks: Quantum teleportation can be used to enable secure communication over long distances in quantum communication\n",
      "networks, which are essential for various applications such as quantum cryptography and quantum metrology.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Real-time feed-forward significantly improves the\n",
      "process of quantum teleportation by enabling unconditional teleportation. In the absence of feed-forward operations, the teleportation fidelity is\n",
      "limited due to errors in the Bell state measurements and other noise sources. However, by applying feed-forward gates in real-time based on the BSM\n",
      "outcomes, the errors can be corrected, leading to improved fidelity.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "  Technical\n",
      "advancements needed to realize efficient quantum teleportation between non-neighboring nodes include:\n",
      "\n",
      "1. Establishing remote entanglement on the two links between non-neighboring nodes.\n",
      "2. Entanglement swapping on the middle node to generate shared entanglement between all three nodes.\n",
      "3. Storage of the entangled state in a memory qubit to protect it during the teleportation process.\n",
      "4. Key innovations in the qubit readout procedure, including the use of a deterministic BSM, to enable unconditional teleportation.\n",
      "5. Active memory qubit protection during entanglement generation to reduce remote entanglement infidelities.\n",
      "6. Tailored heralding that reduces remote entanglement infidelities.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    }
   ],
   "source": [
    "# Qubit Teleportation Questions\n",
    "\n",
    "questions_file_path = '/content/questions/QubitTeleportationQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KK06Y1woEm62",
    "outputId": "78c91e13-bea0-4127-bf69-9be4c1579756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What are the main components used in quantum networks for teleportation?\n",
      " response:   Based on the given context, the main components used in\n",
      "quantum networks for teleportation are:\n",
      "\n",
      "1. NV centres (in diamond): Used as communication qubits for teleportation.\n",
      "2. Nearby 13C nuclear spins: Used as memory qubits for storing information.\n",
      "3. Optical connections: Used to connect the nodes in the quantum network.\n",
      "\n",
      "\n",
      "Q1: How is entanglement established between distant nodes in a quantum network?\n",
      " response:   Entanglement is established between distant nodes in a\n",
      "quantum network through a process called entanglement swapping. This involves using a middle node, which is already entangled with one of the distant\n",
      "nodes, to create a shared entangled state between the other two distant nodes.\n",
      "\n",
      "\n",
      "Q2: What role does the Bell-state measurement (BSM) play in quantum teleportation?\n",
      " response:   The Bell-state measurement (BSM) plays a crucial role\n",
      "in quantum teleportation. In the protocol described in the article, the BSM is used to perform a joint measurement on the sender's part of the\n",
      "entangled state and the qubit state to be teleported. The outcome of the BSM is then fed back to the receiver, who applies a gate operation\n",
      "conditioned on the BSM outcome to recover the teleported state. The BSM allows for the transfer of quantum information across a lossy network link,\n",
      "making it possible to reliably send qubits across long distances.\n",
      "\n",
      "\n",
      "Q3: Why is quantum teleportation considered advantageous over traditional communication methods in quantum networks?\n",
      " response:   Quantum\n",
      "teleportation is considered advantageous over traditional communication methods in quantum networks because it allows for the reliable transfer of\n",
      "quantum information across lossy network connections without requiring physical transport of the information. This is particularly useful in large-\n",
      "scale quantum networks where the number of nodes and connections can be vast, making it impractical to physically transmit the information between all\n",
      "nodes. By using quantum teleportation, the information can be transferred through a series of joint Bell-state measurements, allowing for efficient\n",
      "and reliable communication across the network.\n",
      "\n",
      "\n",
      "Q4: What innovations have improved the fidelity and reliability of quantum teleportation?\n",
      " response:   The innovations that have improved the\n",
      "fidelity and reliability of quantum teleportation include:\n",
      "\n",
      "* Memory qubit readout and protection during entanglement generation\n",
      "* Real-time rejection of false heralding signals\n",
      "\n",
      "These innovations have enabled the successful preparation of the teleporter and the ability to perform unconditional qubit teleportation between non-\n",
      "neighboring nodes in a quantum network.\n",
      "\n",
      "\n",
      "Q5: What challenges are associated with extending quantum teleportation beyond directly connected nodes?\n",
      " response:   The main challenge associated\n",
      "with extending quantum teleportation beyond directly connected nodes is the requirement for pre-shared remote entanglement, which is difficult to\n",
      "achieve due to the high resource demands and limited scalability of existing protocols. Additionally, joint qubit readout and coherence times become\n",
      "increasingly limiting factors as the distance between nodes grows, leading to reduced fidelity and reliability in the teleportation process.\n",
      "\n",
      "\n",
      "Q6: How do memory qubits contribute to the process of quantum teleportation in a network?\n",
      " response:   Memory qubits play a crucial role in the\n",
      "process of quantum teleportation in a network. They are used to store the quantum state of the qubit being teleported, allowing it to be transmitted\n",
      "accurately across non-neighboring nodes in the network. The memory qubits are entangled with the communication qubit, which is used to generate remote\n",
      "entanglement between the neighboring nodes. This entanglement is then used to perform the teleportation protocol, which involves swapping the state of\n",
      "the memory qubit with the state of the qubit being teleported. By doing so, the quantum state of the qubit is transferred accurately to the\n",
      "destination node, allowing for the successful teleportation of the qubit.\n",
      "\n",
      "\n",
      "Q7: What are potential future applications of quantum teleportation in quantum networks?\n",
      " response:   Future applications of quantum teleportation in\n",
      "quantum networks include:\n",
      "\n",
      "1. Multi-node protocols: Teleportation-based protocols can be used to transmit quantum information between multiple nodes in a quantum network,\n",
      "enabling secure communication over long distances.\n",
      "2. Distributed quantum computing: Quantum teleportation can be used to distribute quantum information among multiple nodes in a quantum network,\n",
      "allowing for distributed quantum computing applications.\n",
      "3. Quantum cryptography: Quantum teleportation can be used to enhance the security of quantum cryptographic systems by allowing for the reliable\n",
      "transmission of encrypted quantum information between distant nodes.\n",
      "4. Quantum metrology: Quantum teleportation can be used to improve the precision of quantum measurements by allowing for the reliable transmission of\n",
      "quantum information between distant nodes.\n",
      "5. Quantum communication networks: Quantum teleportation can be used to enable secure communication over long distances in quantum communication\n",
      "networks, which are essential for various applications such as quantum cryptography and quantum metrology.\n",
      "\n",
      "\n",
      "Q8: How does real-time feed-forward impact the process of quantum teleportation?\n",
      " response:   Real-time feed-forward significantly improves the\n",
      "process of quantum teleportation by enabling unconditional teleportation. In the absence of feed-forward operations, the teleportation fidelity is\n",
      "limited due to errors in the Bell state measurements and other noise sources. However, by applying feed-forward gates in real-time based on the BSM\n",
      "outcomes, the errors can be corrected, leading to improved fidelity.\n",
      "\n",
      "\n",
      "Q9: What technical advancements are needed to realize efficient quantum teleportation between non-neighbouring nodes?\n",
      " response:   Technical\n",
      "advancements needed to realize efficient quantum teleportation between non-neighboring nodes include:\n",
      "\n",
      "1. Establishing remote entanglement on the two links between non-neighboring nodes.\n",
      "2. Entanglement swapping on the middle node to generate shared entanglement between all three nodes.\n",
      "3. Storage of the entangled state in a memory qubit to protect it during the teleportation process.\n",
      "4. Key innovations in the qubit readout procedure, including the use of a deterministic BSM, to enable unconditional teleportation.\n",
      "5. Active memory qubit protection during entanglement generation to reduce remote entanglement infidelities.\n",
      "6. Tailored heralding that reduces remote entanglement infidelities.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKJiJ4xMEnKG"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'QubitTeleportationQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ljd8D_p-EnYa"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'QubitTeleportationQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gGG_6CtE3H9"
   },
   "source": [
    "###Variance Based Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiO0mcg-E3ly",
    "outputId": "fb4d4a0a-446b-4e55-ed5f-d0a1c7e781ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The focus of variance-based sensitivity analysis in\n",
      "quantum memory is todetermine the sensitivity of a quantum memory implementation toexperimental fluctuations and drift, particularly in the context\n",
      "ofresonant /Lambda1-type quantum memory protocols.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In the context of the paper \" Variance-based sensitivity analysis of /Lambda1-type quantum\n",
      "memory,\" /Lambda1-type quantum memory refers to a specific type of optical quantum memory that utilizes the /Lambda1 configuration of laser beams to\n",
      "store and retrieve photonic quantum states.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Control field parameters are crucial in Λ-type quantum\n",
      "memory systems because they directly affect the quality of the stored quantum state. The control fields are used to manipulate the quantum states of\n",
      "the atoms in the memory, and any fluctuations or drift in these fields can lead to degradation of the memory efficiency. The sensitivity of the memory\n",
      "to control field parameters is determined by the Sobol' variances and sensitivity indices, which provide a complete picture of the system performance\n",
      "landscape around a central point of input parameters. By analyzing these variances and indices, researchers can identify which input parameters are\n",
      "most sensitive globally and determine the region of control field phase space where acceptable memory performance is achievable. Additionally, the\n",
      "collapse of the N-dimensional parameter space in the case of full Sobol' variances allows for the identification of the most important input\n",
      "parameters that dominate the overall variability of the system.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shot-to-shot fluctuations significantly impact quantum\n",
      "memoryperformance. According to the study, shot-to-shot variations in thecontrol field parameters result in fluctuations in the memoryefficiency, with\n",
      "the degree of sensitivity depending on theparticular quantum memory protocol used. For instance, inthe absorb-then-transfer (ATT) protocol, the shot-\n",
      "to-shot vari-ance in memory efficiency is approximately linearly related to theepsilon (epsilon) parameter, with a coefficient of around0.38.\n",
      "Similarly, in the averaged-then-transfer (ATS) protocol,the relationship between shot-to-shot variation and epsilon isapproximately linear with a\n",
      "coefficient of around 0.13. Thesevalues indicate that a smaller value of epsilon corresponds to lesstransients in memory efficiency due to shot-to-\n",
      "shot fluctuations.Similarly, in the echo-state (EIT) protocol, the relationship betweenshot-to-shot variation and epsilon is approximately linear\n",
      "witha coefficient of around 0.09. These findings demonstrate that reduc-ing shot-to-shot fluctuations in quantum memory performance is crucialfor\n",
      "achieving higher average efficiency and stability in quantumapplications.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The optical control field plays a crucial role in the\n",
      "memory interaction. It determines the shape of the control ﬁeld pulse area, delay relative to the signal ﬁeld, and duration, which affect the memory\n",
      "efﬁciency. The control ﬁeld shape is assumed to be intrinsic and fixed properties of the memory, while the remaining extrinsic, more readily tunable\n",
      "parameters are grouped into G, which parametrize the optical control ﬁeld used in the memory interaction. Optimizing these parameters allows for\n",
      "maximum memory efﬁciency.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Longer timescale drifts in control field parameters can significantlyaffect\n",
      "the performance of quantum memory. In the context of /Lambda1-typequantum memory, longer timescale drifts can lead to a decrease in memoryefficiency\n",
      "due to the accumulation of errors over time. Specifically,if the control ﬁeld parameters drift over a longer timescale, thememory parameters may\n",
      "become less stable, leading to a decrease infidelity and efﬁciency.\n",
      "\n",
      "The sensitivity of quantum memory to longer timescale driftsdepends on the specific protocol being used and the parametersof the memory. For example,\n",
      "in the absorbtion-then-transfer(ATS) protocol, longer timescale drifts in the control ﬁeld parameters canlead to a larger reduction in memory\n",
      "efﬁciency compared to theabsorb-then-transfer (AT) protocol. Similarly, in the echo state(ES) protocol, longer timescale drifts can result in a\n",
      "smallerreduction in memory efﬁciency compared to the ATS protocol.\n",
      "\n",
      "Overall, the impact of longer timescale drifts on quantum memorydepends on the specific experimental conditions and theresulting ﬂuctuations in the\n",
      "control ﬁeld parameters. To minimizethese effects, it is important to carefully control and monitor theexperimental parameters and to implement\n",
      "appropriate errorcorrection techniques.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Memory sensitivity analysis is significant because it helps to identify\n",
      "which input parameters are most critical to achieving good memory performance. By analyzing the sensitivity of the system to fluctuations in these\n",
      "parameters, researchers can gain insights into how to optimize the system's design and operation to achieve better performance. Additionally, by\n",
      "understanding which parameters are most sensitive, researchers can develop strategies to mitigate the impact of experimental drift or other sources of\n",
      "variability on the system's performance. Overall, memory sensitivity analysis is an essential tool for optimizing quantum memory systems and ensuring\n",
      "their reliability and robustness.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Experimental techniques used to analyze memory sensitivity\n",
      "include:\n",
      "\n",
      "1. Variance-based sensitivity analysis: This involves measuring the variance in memory performance due to changes in control field parameters, and\n",
      "calculating the sensitivity of the memory to these changes.\n",
      "2. Single-parameter sensitivity calculations: This involves analyzing the sensitivity of the memory to changes in a single parameter at a time, such\n",
      "as pulse area, delay, or pulse duration.\n",
      "3. Two- and three-parameter sensitivity calculations: These involve analyzing the sensitivity of the memory to correlations between multiple\n",
      "parameters, such as delays and pulse areas.\n",
      "4. Upper bound calculations: These involve calculating an upper bound on memory fidelity or a lower bound on sensitivity in the presence of\n",
      "experimental fluctuations and drift.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Gaussian control field has a direct impact on the memory\n",
      "performance. When the control field parameters, such as the pulse area, delay, and duration, deviate from their optimal values, it leads to\n",
      "fluctuations in the memory efficiency. These fluctuations can result in a decrease in the overall memory performance.\n",
      "\n",
      "To quantify the sensitivity of the memory performance to these fluctuations, we can use the concept of \"overlap fidelity.\" This measure calculates the\n",
      "similarity between the optimal control fields at nearby points in the memory parameter space. The regions with the lowest overlap fidelity are those\n",
      "that are most sensitive to fluctuations in the memory parameters.\n",
      "\n",
      "By analyzing the overlap fidelity and the dependence of memory efficiency fluctuations on memory parameter fluctuations, we can gain insights into the\n",
      "behavior of the memory system under different conditions. This knowledge can be used to optimize the control field parameters for improved memory\n",
      "performance.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "  The findings on quantum memory sensitivity have\n",
      "several practical implications for experimenting with quantum memories:\n",
      "\n",
      "1. Device optimization: By understanding which parameters are most sensitive to fluctuations and drift, researchers can optimize their devices to\n",
      "minimize the impact of these factors, leading to improved memory efficiency and fidelity.\n",
      "2. Experimental design: The study highlights the importance of considering both short-term and long-term fluctuations in experimental parameters.\n",
      "Researchers can design their experiments accordingly, taking into account both immediate and longer-term variations in the system.\n",
      "3. Noise reduction: The sensitivity analysis provides insights into how to reduce noise in quantum memories, which is crucial for achieving high-\n",
      "quality quantum states. By optimizing device parameters and controlling experimental conditions, researchers can mitigate the impact of noise and\n",
      "improve memory performance.\n",
      "4. Robustness: The findings demonstrate that certain quantum memory protocols are more robust against experimental fluctuations than others. By\n",
      "selecting appropriate protocols based on their sensitivity to fluctuations, researchers can develop more reliable and resilient quantum memories.\n",
      "5. Multi-parameter optimization: The variance-based sensitivity analysis presented in the paper can be applied to other figures of merit beyond memory\n",
      "efﬁciency. This opens up opportunities for multi-parameter optimization, where researchers can simultaneously optimize multiple parameters to achieve\n",
      "optimal performance across various metrics.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    }
   ],
   "source": [
    "# Variance Based Questions\n",
    "\n",
    "questions_file_path = '/content/questions/VarianceQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czXJQDQGE313",
    "outputId": "5f5871fe-eda9-4eb1-9f48-8eb2de8396a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What is the focus of variance-based sensitivity analysis in quantum memory?\n",
      " response:   The focus of variance-based sensitivity analysis in\n",
      "quantum memory is todetermine the sensitivity of a quantum memory implementation toexperimental fluctuations and drift, particularly in the context\n",
      "ofresonant /Lambda1-type quantum memory protocols.\n",
      "\n",
      "\n",
      "Q1: What does Λ-type quantum memory refer to?\n",
      " response:   In the context of the paper \" Variance-based sensitivity analysis of /Lambda1-type quantum\n",
      "memory,\" /Lambda1-type quantum memory refers to a specific type of optical quantum memory that utilizes the /Lambda1 configuration of laser beams to\n",
      "store and retrieve photonic quantum states.\n",
      "\n",
      "\n",
      "Q2: Why are control field parameters crucial in Λ-type quantum memory systems?\n",
      " response:   Control field parameters are crucial in Λ-type quantum\n",
      "memory systems because they directly affect the quality of the stored quantum state. The control fields are used to manipulate the quantum states of\n",
      "the atoms in the memory, and any fluctuations or drift in these fields can lead to degradation of the memory efficiency. The sensitivity of the memory\n",
      "to control field parameters is determined by the Sobol' variances and sensitivity indices, which provide a complete picture of the system performance\n",
      "landscape around a central point of input parameters. By analyzing these variances and indices, researchers can identify which input parameters are\n",
      "most sensitive globally and determine the region of control field phase space where acceptable memory performance is achievable. Additionally, the\n",
      "collapse of the N-dimensional parameter space in the case of full Sobol' variances allows for the identification of the most important input\n",
      "parameters that dominate the overall variability of the system.\n",
      "\n",
      "\n",
      "Q3: How does shot-to-shot fluctuation impact quantum memory performance?\n",
      " response:   Shot-to-shot fluctuations significantly impact quantum\n",
      "memoryperformance. According to the study, shot-to-shot variations in thecontrol field parameters result in fluctuations in the memoryefficiency, with\n",
      "the degree of sensitivity depending on theparticular quantum memory protocol used. For instance, inthe absorb-then-transfer (ATT) protocol, the shot-\n",
      "to-shot vari-ance in memory efficiency is approximately linearly related to theepsilon (epsilon) parameter, with a coefficient of around0.38.\n",
      "Similarly, in the averaged-then-transfer (ATS) protocol,the relationship between shot-to-shot variation and epsilon isapproximately linear with a\n",
      "coefficient of around 0.13. Thesevalues indicate that a smaller value of epsilon corresponds to lesstransients in memory efficiency due to shot-to-\n",
      "shot fluctuations.Similarly, in the echo-state (EIT) protocol, the relationship betweenshot-to-shot variation and epsilon is approximately linear\n",
      "witha coefficient of around 0.09. These findings demonstrate that reduc-ing shot-to-shot fluctuations in quantum memory performance is crucialfor\n",
      "achieving higher average efficiency and stability in quantumapplications.\n",
      "\n",
      "\n",
      "Q4: What role does the optical control field play in the memory interaction?\n",
      " response:   The optical control field plays a crucial role in the\n",
      "memory interaction. It determines the shape of the control ﬁeld pulse area, delay relative to the signal ﬁeld, and duration, which affect the memory\n",
      "efﬁciency. The control ﬁeld shape is assumed to be intrinsic and fixed properties of the memory, while the remaining extrinsic, more readily tunable\n",
      "parameters are grouped into G, which parametrize the optical control ﬁeld used in the memory interaction. Optimizing these parameters allows for\n",
      "maximum memory efﬁciency.\n",
      "\n",
      "\n",
      "Q5: How do longer timescale drifts affect quantum memory?\n",
      " response:   Longer timescale drifts in control field parameters can significantlyaffect\n",
      "the performance of quantum memory. In the context of /Lambda1-typequantum memory, longer timescale drifts can lead to a decrease in memoryefficiency\n",
      "due to the accumulation of errors over time. Specifically,if the control ﬁeld parameters drift over a longer timescale, thememory parameters may\n",
      "become less stable, leading to a decrease infidelity and efﬁciency.\n",
      "\n",
      "The sensitivity of quantum memory to longer timescale driftsdepends on the specific protocol being used and the parametersof the memory. For example,\n",
      "in the absorbtion-then-transfer(ATS) protocol, longer timescale drifts in the control ﬁeld parameters canlead to a larger reduction in memory\n",
      "efﬁciency compared to theabsorb-then-transfer (AT) protocol. Similarly, in the echo state(ES) protocol, longer timescale drifts can result in a\n",
      "smallerreduction in memory efﬁciency compared to the ATS protocol.\n",
      "\n",
      "Overall, the impact of longer timescale drifts on quantum memorydepends on the specific experimental conditions and theresulting ﬂuctuations in the\n",
      "control ﬁeld parameters. To minimizethese effects, it is important to carefully control and monitor theexperimental parameters and to implement\n",
      "appropriate errorcorrection techniques.\n",
      "\n",
      "\n",
      "Q6: What is the significance of memory sensitivity analysis?\n",
      " response:   Memory sensitivity analysis is significant because it helps to identify\n",
      "which input parameters are most critical to achieving good memory performance. By analyzing the sensitivity of the system to fluctuations in these\n",
      "parameters, researchers can gain insights into how to optimize the system's design and operation to achieve better performance. Additionally, by\n",
      "understanding which parameters are most sensitive, researchers can develop strategies to mitigate the impact of experimental drift or other sources of\n",
      "variability on the system's performance. Overall, memory sensitivity analysis is an essential tool for optimizing quantum memory systems and ensuring\n",
      "their reliability and robustness.\n",
      "\n",
      "\n",
      "Q7: What experimental techniques are used to analyze memory sensitivity?\n",
      " response:   Experimental techniques used to analyze memory sensitivity\n",
      "include:\n",
      "\n",
      "1. Variance-based sensitivity analysis: This involves measuring the variance in memory performance due to changes in control field parameters, and\n",
      "calculating the sensitivity of the memory to these changes.\n",
      "2. Single-parameter sensitivity calculations: This involves analyzing the sensitivity of the memory to changes in a single parameter at a time, such\n",
      "as pulse area, delay, or pulse duration.\n",
      "3. Two- and three-parameter sensitivity calculations: These involve analyzing the sensitivity of the memory to correlations between multiple\n",
      "parameters, such as delays and pulse areas.\n",
      "4. Upper bound calculations: These involve calculating an upper bound on memory fidelity or a lower bound on sensitivity in the presence of\n",
      "experimental fluctuations and drift.\n",
      "\n",
      "\n",
      "Q8: How does the Gaussian control field relate to memory performance?\n",
      " response:   The Gaussian control field has a direct impact on the memory\n",
      "performance. When the control field parameters, such as the pulse area, delay, and duration, deviate from their optimal values, it leads to\n",
      "fluctuations in the memory efficiency. These fluctuations can result in a decrease in the overall memory performance.\n",
      "\n",
      "To quantify the sensitivity of the memory performance to these fluctuations, we can use the concept of \"overlap fidelity.\" This measure calculates the\n",
      "similarity between the optimal control fields at nearby points in the memory parameter space. The regions with the lowest overlap fidelity are those\n",
      "that are most sensitive to fluctuations in the memory parameters.\n",
      "\n",
      "By analyzing the overlap fidelity and the dependence of memory efficiency fluctuations on memory parameter fluctuations, we can gain insights into the\n",
      "behavior of the memory system under different conditions. This knowledge can be used to optimize the control field parameters for improved memory\n",
      "performance.\n",
      "\n",
      "\n",
      "Q9: What practical ramifications do the findings on quantum memory sensitivity have?\n",
      " response:   The findings on quantum memory sensitivity have\n",
      "several practical implications for experimenting with quantum memories:\n",
      "\n",
      "1. Device optimization: By understanding which parameters are most sensitive to fluctuations and drift, researchers can optimize their devices to\n",
      "minimize the impact of these factors, leading to improved memory efficiency and fidelity.\n",
      "2. Experimental design: The study highlights the importance of considering both short-term and long-term fluctuations in experimental parameters.\n",
      "Researchers can design their experiments accordingly, taking into account both immediate and longer-term variations in the system.\n",
      "3. Noise reduction: The sensitivity analysis provides insights into how to reduce noise in quantum memories, which is crucial for achieving high-\n",
      "quality quantum states. By optimizing device parameters and controlling experimental conditions, researchers can mitigate the impact of noise and\n",
      "improve memory performance.\n",
      "4. Robustness: The findings demonstrate that certain quantum memory protocols are more robust against experimental fluctuations than others. By\n",
      "selecting appropriate protocols based on their sensitivity to fluctuations, researchers can develop more reliable and resilient quantum memories.\n",
      "5. Multi-parameter optimization: The variance-based sensitivity analysis presented in the paper can be applied to other figures of merit beyond memory\n",
      "efﬁciency. This opens up opportunities for multi-parameter optimization, where researchers can simultaneously optimize multiple parameters to achieve\n",
      "optimal performance across various metrics.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWVjvnyoE4Np"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'VarianceQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGuOvCPHE4hy"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'VarianceQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNWPoFZa_grw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00396f00747042ba9350b4b41d7c07fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "017bb7d3258246079f68316952bba230": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "024afc1c7c53444f98952a1d0567ba99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "028a560b68fd4280b496c67c326cdb78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02ded56529414887976dc2918cd1d2b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_316f9af751f5477ea2e85c56c663c744",
      "placeholder": "​",
      "style": "IPY_MODEL_566c5b7bafae4cb39d247f67551f4110",
      "value": " 188/188 [00:00&lt;00:00, 17.6kB/s]"
     }
    },
    "041318f4654c4c579efedf268bbeeaa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "047e8d7819df44449e57fbb9acb1ba35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04a30812666b4d25ba52bb95e65ebe01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04a4f0d443774918a2ba915663004b77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0cb700041e3470da5e1ddd95fc5494d",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8c42fb0384a46be9ed48fcbe91d129b",
      "value": 125
     }
    },
    "04dcbfb8de6e4f1195d4d587bbb38443": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0563b9909b4d4797ab569bbdbb1f6aec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de2a0d0c35d94351a56596c1dea14f40",
      "placeholder": "​",
      "style": "IPY_MODEL_2addadb89a18443192b0180cadea75ed",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "0574f6037616413aac5fb6c22739c698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "06c4ab34c67c459b84374bb13d756074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "081b16fce37e41248e8cbc51a31730ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_536dbff8b134445493df81fded6b2b3e",
      "placeholder": "​",
      "style": "IPY_MODEL_c8e798fe3d184ff2b0c574c70855ce76",
      "value": "Your token has been saved in your configured git credential helpers (store)."
     }
    },
    "094f451bbf004e919828ad6f39e8581e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0995b5a53dd84efb8e53ac231263de84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09d6014f8d8d4fffb0bbd45fa771170c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c08c1261a59472a9bd387472957b4ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d74258894604e68a6d21a5ecce32eac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6100da1428c4bc29f0908e24edd8f8c",
      "max": 349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd1c7dac9cc24abaa31de91fe5410b0f",
      "value": 349
     }
    },
    "0ff1273410d54c1f9f9e50f240926a37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "104c15b3b1a647e5b1bf0bb4ac1e10ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11f75d3716834548b5fbac29ab25f9f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1300784b96984a8eb7a1cca571a5f023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1398733b0952408c8fcb09de6ff41724": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_713a931b441247cab0a93f22c372fade",
      "placeholder": "​",
      "style": "IPY_MODEL_1ee42d7544814f5687eb05728b9f702b",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "15706616ea504bc29cec1bf1d8419a30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17e141486ff04047a4d6e82bec957fad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb304a587fda46c88b90fec6f4a9fd11",
      "placeholder": "​",
      "style": "IPY_MODEL_b78b5a28ba4c4e71a966fbf370a019cf",
      "value": " 232k/232k [00:00&lt;00:00, 636kB/s]"
     }
    },
    "1891b63efdde45f29740958e8f801a09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1398733b0952408c8fcb09de6ff41724",
       "IPY_MODEL_3ee788552f644a01967d338c0b3c35d7",
       "IPY_MODEL_eff596c781cb49b18eb06e549dd0e5f6"
      ],
      "layout": "IPY_MODEL_7cd91e4219c74049a584efa937acf701"
     }
    },
    "199012c0c40f477d934f54efe3ad3357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a8cb29fee164ef994e237418df09ef0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1afb25af643142f488387bdd7789288a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bdb58a2c30b4ba9a52a84ad222c91ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c78b061ba144f98bb6cce1bde3fb474": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d890c0163374ea4bd37efe69f918f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ee42d7544814f5687eb05728b9f702b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ef1eec0dd5e47bea1bcea6f9034f021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f0821e07ddc41e2adb07c5323b169e2",
      "placeholder": "​",
      "style": "IPY_MODEL_e244474294cc486fa649eb90b4cd633b",
      "value": "config.json: 100%"
     }
    },
    "1f5675ca438d4175b637cdcdebca663c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f8ee0b81a764ad8a5bf267dbb46c666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6938566ba694345acca363cafc140b1",
      "placeholder": "​",
      "style": "IPY_MODEL_e0320b96d838421fbfc081ee96a5c1c3",
      "value": "Token is valid (permission: write)."
     }
    },
    "1fc0c62d93bf4f768988a9b8ec838dc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "204e67ceec9448158221d98db20ccc61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2079914d78a449b9b0d4763f7074f2c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21658bf2e96d4691878b9c192cbde886": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a01589c766734d0594c23f32f7002f8c",
      "placeholder": "​",
      "style": "IPY_MODEL_9959187cad5740c69c84c3e9a699e716",
      "value": " 349/349 [00:00&lt;00:00, 21.2kB/s]"
     }
    },
    "229456cdfceb4042b305579a31c26704": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "25f6af5cceca42d799000a518ea770f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "26074db82ccf4914ba45bc07f95aab38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26c32b8194954325ae28a9ebc0cabc39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "275cec8b3ec6431b85c15cd21902a924": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28a51f46fff747bebc7941fe1a651cd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15706616ea504bc29cec1bf1d8419a30",
      "max": 1842767,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7eac30f901bb4df9ae83d2c4f8ae9fca",
      "value": 1842767
     }
    },
    "2902e3edc0054b6e8ed58a7a10a9755b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2addadb89a18443192b0180cadea75ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b6071112897414da7b667cb0b8538c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7d2bdf65a094186b9672f725b5768c3",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3546f16388b041bfbeaf164e52a71c22",
      "value": 2
     }
    },
    "2c582191ffb34870a9f1a4347dd788b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fe07a2bb16246849b3dcf0c537586ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fe39a5d59d54d5b9a18ba0d36f32fd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ffc7aa76fcd4603a00392cfd033ae42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30c14055d966408a8aa9e1ba2e4e645f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "316f9af751f5477ea2e85c56c663c744": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "323c44b996254a84a7015bbe2f108b11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3453e03816494f6db5613e144b1eb69a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_379c5bb2822d4f658e367e88e8f76646",
      "placeholder": "​",
      "style": "IPY_MODEL_204e67ceec9448158221d98db20ccc61",
      "value": "1_Pooling/config.json: 100%"
     }
    },
    "3546f16388b041bfbeaf164e52a71c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3627208748d84690b7142140e97f92d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "379c5bb2822d4f658e367e88e8f76646": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3876b135bd1647feb2a18c024051cb10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_955dba34b0b64377b250d3dd5e4a0b5d",
      "placeholder": "​",
      "style": "IPY_MODEL_a33796f57e8642f1a994dd4b35162850",
      "value": " 2/2 [01:00&lt;00:00, 26.67s/it]"
     }
    },
    "3a12ca6ac76641529c4714ca1901a57b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f8ee0b81a764ad8a5bf267dbb46c666",
       "IPY_MODEL_081b16fce37e41248e8cbc51a31730ad",
       "IPY_MODEL_bbdbfccc2e8b4168b8f87fff78f508cc",
       "IPY_MODEL_fcf5ac563be64dba8271f6ca855db1a6"
      ],
      "layout": "IPY_MODEL_8bc776651d29481197c859a440dd14d7"
     }
    },
    "3a403557189c4d65ac9cea26cac1e5fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ae25353d9214ca8a94748eb27f677a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d434a71b4d6467dba2802590f7d32ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9868ffcced842acb57be30b202649d8",
      "max": 9976576152,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_25f6af5cceca42d799000a518ea770f9",
      "value": 9976576152
     }
    },
    "3df56cdeca9345d9b2ed0f664f0c975c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90564ec207f6426786fcc429378d4959",
      "placeholder": "​",
      "style": "IPY_MODEL_5d2a287a27eb45698b01e22d58c8b6af",
      "value": "Connecting..."
     }
    },
    "3e43256b6e334e3fad60f19af2be048d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1300784b96984a8eb7a1cca571a5f023",
      "max": 3500296424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8e2fcbc6e9e4fd5ae9c7eb4a636c662",
      "value": 3500296424
     }
    },
    "3ee788552f644a01967d338c0b3c35d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d47276c296bd470b856ba6fb3a9d9c11",
      "max": 414,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5bceb4289844c71bcaaa6b21f0b59c4",
      "value": 414
     }
    },
    "3f4adba8484947ce9aff751b33a42b71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "408933246daa421ea85229be88220356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40896aab4d49469ba8ad6d63ecc4658c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6f24e8061dd44cd90e8e954147ab2fa",
      "max": 188,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89aa0186f88e450b934ca809adf54658",
      "value": 188
     }
    },
    "40e8c1f82d58459b97951a604deb1b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc0c62d93bf4f768988a9b8ec838dc1",
      "placeholder": "​",
      "style": "IPY_MODEL_5bdb5c1e0b1d49f78b0f929206840507",
      "value": " 190/190 [00:00&lt;00:00, 16.6kB/s]"
     }
    },
    "430638a4dbf14252b9a4ee94a9e7d4a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce38825a1c4540af933f4e5ef1bc16e5",
      "placeholder": "​",
      "style": "IPY_MODEL_8e0ea91c80ca466d880b8af03b0f170e",
      "value": " 614/614 [00:00&lt;00:00, 59.0kB/s]"
     }
    },
    "43f6ba43bff5476582698472f9555f24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44d1156fc633432091a7722270359118": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1afb25af643142f488387bdd7789288a",
      "max": 437955512,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0625bf7cc4543c7bee080289d5a0e87",
      "value": 437955512
     }
    },
    "457d65bc00bd466eab43816f8439e320": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49d91597fe6044da9d3642cc8930f93c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a1542f333a34a9bb83454776efc98e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b71f7b7efb746c1be638b957cb33b6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fe07a2bb16246849b3dcf0c537586ac",
      "placeholder": "​",
      "style": "IPY_MODEL_dc6a9cf83af5406a825639c8d05d604b",
      "value": "tokenizer.json: 100%"
     }
    },
    "4ce912186d4b4bffbb6174eaeecaba32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0995b5a53dd84efb8e53ac231263de84",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3627208748d84690b7142140e97f92d9",
      "value": 52
     }
    },
    "52a7771f24e0414b9ac58ded3e1422b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a403557189c4d65ac9cea26cac1e5fe",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c493c03ae67043ad951854ea0a01b50d",
      "value": 190
     }
    },
    "5305e31c5cf6443da5762cddb03f0c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5332663318864679b969e094197871e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_028a560b68fd4280b496c67c326cdb78",
      "max": 26788,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98cd1bfbb7254fae9404ac870ab9d324",
      "value": 26788
     }
    },
    "535ffec7938e4ff3ac941768b4dff1ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "536dbff8b134445493df81fded6b2b3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54d73b9390a2472b8ed6e090c6c95378": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "566c5b7bafae4cb39d247f67551f4110": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57693568ba184a0eaed1eb4d2ed0d96a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "583e6d1fd990468c8331dbdfa7557b63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9acfac341cc14cbcb88bf6a62546b026",
       "IPY_MODEL_3d434a71b4d6467dba2802590f7d32ef",
       "IPY_MODEL_d9cc02ef0d8a48a8be1abbd89242f3c2"
      ],
      "layout": "IPY_MODEL_1c78b061ba144f98bb6cce1bde3fb474"
     }
    },
    "587fc849341f4d2f99050093257bbc1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58d47803029b47d6b0822036c73d1f37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59c3bc2628a34e3e91e40dfe7557a021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a58cf536fba456aae42644cece78ba7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff02416027c746e7931c9239f9279380",
      "placeholder": "​",
      "style": "IPY_MODEL_8a12845b17fe420d9f2ea33561049b5a",
      "value": " 3.50G/3.50G [00:10&lt;00:00, 336MB/s]"
     }
    },
    "5b7dedbfcb2841c7926c57c2e5b5174a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_650141acc22647a8b6ad394c05a212a9",
      "placeholder": "​",
      "style": "IPY_MODEL_61f05a1aa1e54bbfbf5d8ec268d77ce0",
      "value": "modules.json: 100%"
     }
    },
    "5bdb5c1e0b1d49f78b0f929206840507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d2a287a27eb45698b01e22d58c8b6af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5dfb5b675e034cfcb231d207b026a0df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a986a055d1664274ac43c069d3757668",
      "placeholder": "​",
      "style": "IPY_MODEL_e973a97654574cdc86775d2c05606a7a",
      "value": " 366/366 [00:00&lt;00:00, 33.6kB/s]"
     }
    },
    "5e6e2dbcbf16475392bfbd7dd57f8355": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d5f9c3e6ad164c6397ca4fd4f9828ccd",
       "IPY_MODEL_04a4f0d443774918a2ba915663004b77",
       "IPY_MODEL_e7c032e40eb943deb36466ee88625ff6"
      ],
      "layout": "IPY_MODEL_b87b6e19a89143748acfa70cd863a393"
     }
    },
    "5e73e93098a4421b8fff39259803d298": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_323c44b996254a84a7015bbe2f108b11",
      "placeholder": "​",
      "style": "IPY_MODEL_65c001a48fb04568b03e4fc30156b391",
      "value": " 124/124 [00:00&lt;00:00, 8.20kB/s]"
     }
    },
    "5f0821e07ddc41e2adb07c5323b169e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61f05a1aa1e54bbfbf5d8ec268d77ce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62713568ffb74392bb83cbe2bc4ddfa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b04c1b4e1a24478281e8ca22b4cf6e8a",
      "placeholder": "​",
      "style": "IPY_MODEL_535ffec7938e4ff3ac941768b4dff1ac",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "63ee9264c3b3423bb0c79efc838f5726": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a775e22e1aa4432b9ed08ad890ffe1dd",
       "IPY_MODEL_4ce912186d4b4bffbb6174eaeecaba32",
       "IPY_MODEL_bf418252dc514941872cabfe8e732fee"
      ],
      "layout": "IPY_MODEL_97ca9351170f4544b9921cf898b580a6"
     }
    },
    "64705649180d4acda86085244015039e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be2225e503b5464eb2b3f891ac1fcff1",
      "placeholder": "​",
      "style": "IPY_MODEL_2ffc7aa76fcd4603a00392cfd033ae42",
      "value": "model.safetensors: 100%"
     }
    },
    "64e5de311a6e43c88ab06a54568a2d95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11f75d3716834548b5fbac29ab25f9f6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fe39a5d59d54d5b9a18ba0d36f32fd0",
      "value": 231508
     }
    },
    "650141acc22647a8b6ad394c05a212a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65c001a48fb04568b03e4fc30156b391": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65d61c3f5bbd41a0869ef8eacdf13c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54d73b9390a2472b8ed6e090c6c95378",
      "placeholder": "​",
      "style": "IPY_MODEL_684fff7856234d89b931fe5188b3e308",
      "value": " 711k/711k [00:00&lt;00:00, 3.07MB/s]"
     }
    },
    "684fff7856234d89b931fe5188b3e308": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "696139dd70e14effb09beed25b6c9dce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b24ae0f59034c2bb81613ff52e92dbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_104c15b3b1a647e5b1bf0bb4ac1e10ab",
      "placeholder": "​",
      "style": "IPY_MODEL_a48f9a9b539045409f4663ff43f154eb",
      "value": "config.json: 100%"
     }
    },
    "6b4c285be66f4a9f8e03d01792a09a35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_998cab80696e4e7bbc35049bd6931e1c",
       "IPY_MODEL_8c20a97c631b42dbac18c09d2ee45e4b",
       "IPY_MODEL_5e73e93098a4421b8fff39259803d298"
      ],
      "layout": "IPY_MODEL_7ef0d53cb2d64a6a9a232c64de32c9d5"
     }
    },
    "713a931b441247cab0a93f22c372fade": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7575bf01755b4b31bc7725a98d7bc2c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77f3feea020e4f8bbb08acbeb5a6c8cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b06fe1665654870ab643866ebec1462": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_973ad6ee8b924412878fde6a43c5514e",
       "IPY_MODEL_2b6071112897414da7b667cb0b8538c4",
       "IPY_MODEL_a78851c1f45549658ac83b084bf7ab2e"
      ],
      "layout": "IPY_MODEL_9d51117f768c41e5b96e51fb484cb34d"
     }
    },
    "7c1c692d316c4074bb2d67630a5379b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c81b9edaa3d461a98dc4a020bad85f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cc272dd43a34b159d9c6efd2d12a12d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cd91e4219c74049a584efa937acf701": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d071cd36a414a1fb3d9155abf353a03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce4dd338da2b4aa2b7ce431ddace57ca",
       "IPY_MODEL_d5d96a4f796e4afc918a5209506389c8",
       "IPY_MODEL_5dfb5b675e034cfcb231d207b026a0df"
      ],
      "layout": "IPY_MODEL_00396f00747042ba9350b4b41d7c07fa"
     }
    },
    "7eac30f901bb4df9ae83d2c4f8ae9fca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ef0d53cb2d64a6a9a232c64de32c9d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f8f479c531e433885159f64a7aedbb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "807f426a895f4ad0ad5bc2f62a51d98b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8190f1e57e2549e79acbcdd3473ebd7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ff1273410d54c1f9f9e50f240926a37",
      "max": 711396,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0574f6037616413aac5fb6c22739c698",
      "value": 711396
     }
    },
    "81b50221a50c4fe085dd04b93da05a5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b7dedbfcb2841c7926c57c2e5b5174a",
       "IPY_MODEL_0d74258894604e68a6d21a5ecce32eac",
       "IPY_MODEL_21658bf2e96d4691878b9c192cbde886"
      ],
      "layout": "IPY_MODEL_b404237a418a40c8ac93ba53b899a087"
     }
    },
    "82a0638fd3444de0a06ee00456177c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83d83c03818841a1a50ec54f7967ec8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88404c84874a42e8841d9a3464e147ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c654149e39cd430cab0425513704c924",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a1542f333a34a9bb83454776efc98e3",
      "value": 2
     }
    },
    "89aa0186f88e450b934ca809adf54658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a12845b17fe420d9f2ea33561049b5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ac5af7924b04565893a7470c66f27c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0563b9909b4d4797ab569bbdbb1f6aec",
       "IPY_MODEL_5332663318864679b969e094197871e8",
       "IPY_MODEL_c5701ec915e147f895f7dc1ffe385e4e"
      ],
      "layout": "IPY_MODEL_c7058fe0829a4c928072e6516c3184c6"
     }
    },
    "8af4cbdbc16740ff9141f7409beabf91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_807f426a895f4ad0ad5bc2f62a51d98b",
      "placeholder": "​",
      "style": "IPY_MODEL_2c582191ffb34870a9f1a4347dd788b0",
      "value": " 777/777 [00:00&lt;00:00, 51.3kB/s]"
     }
    },
    "8bc776651d29481197c859a440dd14d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "8c20a97c631b42dbac18c09d2ee45e4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_932b1f0d5e414796bd10346ebf6be046",
      "max": 124,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2079914d78a449b9b0d4763f7074f2c9",
      "value": 124
     }
    },
    "8cc9b8739aed455886d6bdd5af6def66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddc3835c87c406a949101259fe238e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e0ea91c80ca466d880b8af03b0f170e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90564ec207f6426786fcc429378d4959": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92ae919c407c435e827f3259f1b2556b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "932b1f0d5e414796bd10346ebf6be046": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93fe193d320049ef8b64e7b544c97f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9402ac70d917481cb33ca9cd950a80dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fca86ad563634cc9992724cc868528d7",
      "placeholder": "​",
      "style": "IPY_MODEL_d022ce6ae972406aaacd0a5fd8677769",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "9425428d01404514b06b354f8d2bec97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b857360b00484bffacbbf6068f2dcbdd",
      "max": 777,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd9eb13addbe45aba24adfb20bd88880",
      "value": 777
     }
    },
    "955dba34b0b64377b250d3dd5e4a0b5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97053e3ff42b44cc8534382b3b13206e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ef1eec0dd5e47bea1bcea6f9034f021",
       "IPY_MODEL_aae60e3e71e2435fae1025fae4c18288",
       "IPY_MODEL_430638a4dbf14252b9a4ee94a9e7d4a4"
      ],
      "layout": "IPY_MODEL_c58770fb5b6547aea8c863d9f5295ccd"
     }
    },
    "973ad6ee8b924412878fde6a43c5514e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2938e4401144d7d9ae41210f506a85b",
      "placeholder": "​",
      "style": "IPY_MODEL_58d47803029b47d6b0822036c73d1f37",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "97ca9351170f4544b9921cf898b580a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98cd1bfbb7254fae9404ac870ab9d324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9959187cad5740c69c84c3e9a699e716": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "998cab80696e4e7bbc35049bd6931e1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f8f479c531e433885159f64a7aedbb0",
      "placeholder": "​",
      "style": "IPY_MODEL_094f451bbf004e919828ad6f39e8581e",
      "value": "config_sentence_transformers.json: 100%"
     }
    },
    "9acfac341cc14cbcb88bf6a62546b026": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57693568ba184a0eaed1eb4d2ed0d96a",
      "placeholder": "​",
      "style": "IPY_MODEL_cd059062b89140dfb99771bf52c4e66f",
      "value": "model-00001-of-00002.safetensors: 100%"
     }
    },
    "9acfccf60cf94029bbc9f95061a6048a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bd9b57a3524432eabe32c7515aae8c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9be3709eb608458aa895aaf56485e3e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ca18a67e97a4263a299f14f0b5b35b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b3a76956729a40d78f9453e5ed426f19",
       "IPY_MODEL_3e43256b6e334e3fad60f19af2be048d",
       "IPY_MODEL_5a58cf536fba456aae42644cece78ba7"
      ],
      "layout": "IPY_MODEL_c0be785eca7c42a6863bb45f91bd0cce"
     }
    },
    "9d51117f768c41e5b96e51fb484cb34d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ee5bc663a214ed5a3e94a80b05c0600": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64705649180d4acda86085244015039e",
       "IPY_MODEL_44d1156fc633432091a7722270359118",
       "IPY_MODEL_bb7824a817d64b2d9aa8580d74f1ba8e"
      ],
      "layout": "IPY_MODEL_1a8cb29fee164ef994e237418df09ef0"
     }
    },
    "a01589c766734d0594c23f32f7002f8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a206c0c91d5e4dcdaf1e946257f58325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a33796f57e8642f1a994dd4b35162850": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3a41b2fab7f4a40a6e79de61ea79ea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab6abf9284a04a2c87894b11bc316c41",
      "placeholder": "​",
      "style": "IPY_MODEL_7c1c692d316c4074bb2d67630a5379b0",
      "value": " 1.62k/1.62k [00:00&lt;00:00, 150kB/s]"
     }
    },
    "a48f9a9b539045409f4663ff43f154eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a492166ba2c648c5be891055f1b53d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8c5ae851f394ca490f04cf96e48992b",
      "placeholder": "​",
      "style": "IPY_MODEL_dfd88b60d7d840f59c837173191a32e6",
      "value": "README.md: 100%"
     }
    },
    "a775e22e1aa4432b9ed08ad890ffe1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_587fc849341f4d2f99050093257bbc1c",
      "placeholder": "​",
      "style": "IPY_MODEL_041318f4654c4c579efedf268bbeeaa4",
      "value": "sentence_bert_config.json: 100%"
     }
    },
    "a78851c1f45549658ac83b084bf7ab2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bdb58a2c30b4ba9a52a84ad222c91ef",
      "placeholder": "​",
      "style": "IPY_MODEL_e46a2af177c14f6ea0f2c7142c078cb6",
      "value": " 2/2 [00:04&lt;00:00,  2.17s/it]"
     }
    },
    "a94cda1ce28a48218f7f416e40db76d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a986a055d1664274ac43c069d3757668": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaacb878704c47d8930d8fafda03eb4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43f6ba43bff5476582698472f9555f24",
      "placeholder": "​",
      "style": "IPY_MODEL_0c08c1261a59472a9bd387472957b4ea",
      "value": "Downloading shards: 100%"
     }
    },
    "aae60e3e71e2435fae1025fae4c18288": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ddc3835c87c406a949101259fe238e7",
      "max": 614,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5c5e484dae7433bb36acdbb2ca807e6",
      "value": 614
     }
    },
    "ab6abf9284a04a2c87894b11bc316c41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abf211c42aa8430b839473fcfe6f2fe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad752c901a5f4b709ac380127311a907": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cc9b8739aed455886d6bdd5af6def66",
      "placeholder": "​",
      "style": "IPY_MODEL_7cc272dd43a34b159d9c6efd2d12a12d",
      "value": "tokenizer.model: 100%"
     }
    },
    "aff52811af324aa883e99ba00d6b2093": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04dcbfb8de6e4f1195d4d587bbb38443",
      "placeholder": "​",
      "style": "IPY_MODEL_7575bf01755b4b31bc7725a98d7bc2c9",
      "value": "tokenizer.json: 100%"
     }
    },
    "b04c1b4e1a24478281e8ca22b4cf6e8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0dc6ea045e347f297e183bbd0b6cb17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b16af085e17e46c994a640eec94e7f66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3a76956729a40d78f9453e5ed426f19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebc2bcb28dd24d3abf69cbf0445e0cd9",
      "placeholder": "​",
      "style": "IPY_MODEL_d63f7c5715f4466ea2faac8469e1b9d3",
      "value": "model-00002-of-00002.safetensors: 100%"
     }
    },
    "b404237a418a40c8ac93ba53b899a087": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b42611fd7b1d4235a0192e638a01bd70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad752c901a5f4b709ac380127311a907",
       "IPY_MODEL_e96f1cf63a5c43a29f8e4070e4d2c981",
       "IPY_MODEL_b71457d5c7b847c5928a47c331db3f6c"
      ],
      "layout": "IPY_MODEL_b16af085e17e46c994a640eec94e7f66"
     }
    },
    "b54ac008e9614dfb88b27ee3ed42bf33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b71457d5c7b847c5928a47c331db3f6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcc3118e85254be7aa0348af5407e1de",
      "placeholder": "​",
      "style": "IPY_MODEL_408933246daa421ea85229be88220356",
      "value": " 500k/500k [00:00&lt;00:00, 20.4MB/s]"
     }
    },
    "b72530813cf142c290aceac5bb198838": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b78b5a28ba4c4e71a966fbf370a019cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b857360b00484bffacbbf6068f2dcbdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b87b6e19a89143748acfa70cd863a393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8c42fb0384a46be9ed48fcbe91d129b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b963713bb0c54eeb89c4bae07f69dc69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aaacb878704c47d8930d8fafda03eb4a",
       "IPY_MODEL_88404c84874a42e8841d9a3464e147ad",
       "IPY_MODEL_3876b135bd1647feb2a18c024051cb10"
      ],
      "layout": "IPY_MODEL_f73de0e914214591b1eec8c79dea6b61"
     }
    },
    "baaa6229a0a94544bcee0592538655bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb304a587fda46c88b90fec6f4a9fd11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb3d302958ce405d8579c2c8dd98b02d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a492166ba2c648c5be891055f1b53d24",
       "IPY_MODEL_f711a33c1f664453a8e7514f04a52fe7",
       "IPY_MODEL_e73a5fe07a5148f0867465fadf38c13e"
      ],
      "layout": "IPY_MODEL_dc011ffbf6b24150b80fc19f599dc0a1"
     }
    },
    "bb6d3d12e9a04c5f8c2c4ff724bb8a2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb7824a817d64b2d9aa8580d74f1ba8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e434edef7a1645339c214a039b0f8dff",
      "placeholder": "​",
      "style": "IPY_MODEL_26074db82ccf4914ba45bc07f95aab38",
      "value": " 438M/438M [00:01&lt;00:00, 427MB/s]"
     }
    },
    "bbdbdbe755d84088b13500a35a5b41ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbdbfccc2e8b4168b8f87fff78f508cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d24a0469f3a440c6b4f8c0bea159543f",
      "placeholder": "​",
      "style": "IPY_MODEL_1d890c0163374ea4bd37efe69f918f7e",
      "value": "Your token has been saved to /root/.cache/huggingface/token"
     }
    },
    "bcc3118e85254be7aa0348af5407e1de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bce334785f9449d782120bd30c876b1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5bdde31aee5438ca41786fc312e9e55",
       "IPY_MODEL_40896aab4d49469ba8ad6d63ecc4658c",
       "IPY_MODEL_02ded56529414887976dc2918cd1d2b3"
      ],
      "layout": "IPY_MODEL_047e8d7819df44449e57fbb9acb1ba35"
     }
    },
    "bd4fdc792ab544679f89b3377c20fdbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be202f12608542dbb59110e48e8ed7f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_f9f1f9de43f34bebbd9e56007fef48b4",
      "style": "IPY_MODEL_26c32b8194954325ae28a9ebc0cabc39",
      "value": true
     }
    },
    "be2225e503b5464eb2b3f891ac1fcff1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf418252dc514941872cabfe8e732fee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a94cda1ce28a48218f7f416e40db76d6",
      "placeholder": "​",
      "style": "IPY_MODEL_59c3bc2628a34e3e91e40dfe7557a021",
      "value": " 52.0/52.0 [00:00&lt;00:00, 3.37kB/s]"
     }
    },
    "c0625bf7cc4543c7bee080289d5a0e87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0be785eca7c42a6863bb45f91bd0cce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c24e721fc5174221bfe55cd2edaa5458": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c493c03ae67043ad951854ea0a01b50d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c5701ec915e147f895f7dc1ffe385e4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49d91597fe6044da9d3642cc8930f93c",
      "placeholder": "​",
      "style": "IPY_MODEL_83d83c03818841a1a50ec54f7967ec8a",
      "value": " 26.8k/26.8k [00:00&lt;00:00, 2.44MB/s]"
     }
    },
    "c58770fb5b6547aea8c863d9f5295ccd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5bceb4289844c71bcaaa6b21f0b59c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c654149e39cd430cab0425513704c924": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6f24e8061dd44cd90e8e954147ab2fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7058fe0829a4c928072e6516c3184c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c81d23e2511a4a619a3b55c3037e5c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3453e03816494f6db5613e144b1eb69a",
       "IPY_MODEL_52a7771f24e0414b9ac58ded3e1422b8",
       "IPY_MODEL_40e8c1f82d58459b97951a604deb1b30"
      ],
      "layout": "IPY_MODEL_b54ac008e9614dfb88b27ee3ed42bf33"
     }
    },
    "c8e798fe3d184ff2b0c574c70855ce76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9033eae67f64950ad66210e21d38f06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df187b6ffef94d8dbf6eff59c6664ac8",
      "placeholder": "​",
      "style": "IPY_MODEL_696139dd70e14effb09beed25b6c9dce",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "cd059062b89140dfb99771bf52c4e66f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd9eb13addbe45aba24adfb20bd88880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ce38825a1c4540af933f4e5ef1bc16e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce4dd338da2b4aa2b7ce431ddace57ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c81b9edaa3d461a98dc4a020bad85f1",
      "placeholder": "​",
      "style": "IPY_MODEL_92ae919c407c435e827f3259f1b2556b",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "ce7fde73103f4db0ac8e457478e460be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ae25353d9214ca8a94748eb27f677a1",
      "placeholder": "​",
      "style": "IPY_MODEL_bb6d3d12e9a04c5f8c2c4ff724bb8a2f",
      "value": " 1.84M/1.84M [00:00&lt;00:00, 45.7MB/s]"
     }
    },
    "d022ce6ae972406aaacd0a5fd8677769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0cb700041e3470da5e1ddd95fc5494d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d24a0469f3a440c6b4f8c0bea159543f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2938e4401144d7d9ae41210f506a85b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d47276c296bd470b856ba6fb3a9d9c11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5141402fb2545abaf8ef162a62a7972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5d96a4f796e4afc918a5209506389c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bd9b57a3524432eabe32c7515aae8c5",
      "max": 366,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a206c0c91d5e4dcdaf1e946257f58325",
      "value": 366
     }
    },
    "d5f9c3e6ad164c6397ca4fd4f9828ccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f4adba8484947ce9aff751b33a42b71",
      "placeholder": "​",
      "style": "IPY_MODEL_b0dc6ea045e347f297e183bbd0b6cb17",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "d60780bd3c0e45658d9fa9918cf67495": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_024afc1c7c53444f98952a1d0567ba99",
      "max": 1618,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fe05473196f54d6d893f81190cb03106",
      "value": 1618
     }
    },
    "d63f7c5715f4466ea2faac8469e1b9d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d79f7edb958841b98b18978b9351eaed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b24ae0f59034c2bb81613ff52e92dbf",
       "IPY_MODEL_9425428d01404514b06b354f8d2bec97",
       "IPY_MODEL_8af4cbdbc16740ff9141f7409beabf91"
      ],
      "layout": "IPY_MODEL_1f5675ca438d4175b637cdcdebca663c"
     }
    },
    "d8c5ae851f394ca490f04cf96e48992b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8e2fcbc6e9e4fd5ae9c7eb4a636c662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d924801ca37e4790abffec0451509824": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_09d6014f8d8d4fffb0bbd45fa771170c",
      "style": "IPY_MODEL_229456cdfceb4042b305579a31c26704",
      "tooltip": ""
     }
    },
    "d9cc02ef0d8a48a8be1abbd89242f3c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_199012c0c40f477d934f54efe3ad3357",
      "placeholder": "​",
      "style": "IPY_MODEL_93fe193d320049ef8b64e7b544c97f63",
      "value": " 9.98G/9.98G [00:49&lt;00:00, 298MB/s]"
     }
    },
    "dc011ffbf6b24150b80fc19f599dc0a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc6a9cf83af5406a825639c8d05d604b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd0fc1e9c5c640c3b2baae39636a4e0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de2a0d0c35d94351a56596c1dea14f40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df187b6ffef94d8dbf6eff59c6664ac8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfd88b60d7d840f59c837173191a32e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0320b96d838421fbfc081ee96a5c1c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e244474294cc486fa649eb90b4cd633b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2531668afb04b7abdc89a0e271a46d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aff52811af324aa883e99ba00d6b2093",
       "IPY_MODEL_28a51f46fff747bebc7941fe1a651cd3",
       "IPY_MODEL_ce7fde73103f4db0ac8e457478e460be"
      ],
      "layout": "IPY_MODEL_baaa6229a0a94544bcee0592538655bb"
     }
    },
    "e27cbf7564aa48c2af3009405c207c36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbdbdbe755d84088b13500a35a5b41ae",
      "placeholder": "​",
      "style": "IPY_MODEL_dd0fc1e9c5c640c3b2baae39636a4e0f",
      "value": "vocab.txt: 100%"
     }
    },
    "e434edef7a1645339c214a039b0f8dff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e46a2af177c14f6ea0f2c7142c078cb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5bdde31aee5438ca41786fc312e9e55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77f3feea020e4f8bbb08acbeb5a6c8cf",
      "placeholder": "​",
      "style": "IPY_MODEL_2902e3edc0054b6e8ed58a7a10a9755b",
      "value": "generation_config.json: 100%"
     }
    },
    "e5c5e484dae7433bb36acdbb2ca807e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6938566ba694345acca363cafc140b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e73a5fe07a5148f0867465fadf38c13e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30c14055d966408a8aa9e1ba2e4e645f",
      "placeholder": "​",
      "style": "IPY_MODEL_5305e31c5cf6443da5762cddb03f0c64",
      "value": " 94.6k/94.6k [00:00&lt;00:00, 5.79MB/s]"
     }
    },
    "e7c032e40eb943deb36466ee88625ff6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c24e721fc5174221bfe55cd2edaa5458",
      "placeholder": "​",
      "style": "IPY_MODEL_06c4ab34c67c459b84374bb13d756074",
      "value": " 125/125 [00:00&lt;00:00, 12.2kB/s]"
     }
    },
    "e96f1cf63a5c43a29f8e4070e4d2c981": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_275cec8b3ec6431b85c15cd21902a924",
      "max": 499723,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5141402fb2545abaf8ef162a62a7972",
      "value": 499723
     }
    },
    "e973a97654574cdc86775d2c05606a7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea1264d4dfd04c92aa49963bd45f4657": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9033eae67f64950ad66210e21d38f06",
       "IPY_MODEL_d60780bd3c0e45658d9fa9918cf67495",
       "IPY_MODEL_a3a41b2fab7f4a40a6e79de61ea79ea7"
      ],
      "layout": "IPY_MODEL_04a30812666b4d25ba52bb95e65ebe01"
     }
    },
    "eb2ec9bb35bd43d492b20bf1234db4bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ebc2bcb28dd24d3abf69cbf0445e0cd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eff596c781cb49b18eb06e549dd0e5f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_457d65bc00bd466eab43816f8439e320",
      "placeholder": "​",
      "style": "IPY_MODEL_82a0638fd3444de0a06ee00456177c1a",
      "value": " 414/414 [00:00&lt;00:00, 33.8kB/s]"
     }
    },
    "f3d9e9a587a54dfcad941d1cb26956fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e27cbf7564aa48c2af3009405c207c36",
       "IPY_MODEL_64e5de311a6e43c88ab06a54568a2d95",
       "IPY_MODEL_17e141486ff04047a4d6e82bec957fad"
      ],
      "layout": "IPY_MODEL_bd4fdc792ab544679f89b3377c20fdbb"
     }
    },
    "f6100da1428c4bc29f0908e24edd8f8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f64aaf5f3e10461fbb407a596b2d9cb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_abf211c42aa8430b839473fcfe6f2fe5",
      "placeholder": "​",
      "style": "IPY_MODEL_017bb7d3258246079f68316952bba230",
      "value": ""
     }
    },
    "f706cadb92514d0fb566ad4501a537fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b71f7b7efb746c1be638b957cb33b6c",
       "IPY_MODEL_8190f1e57e2549e79acbcdd3473ebd7b",
       "IPY_MODEL_65d61c3f5bbd41a0869ef8eacdf13c61"
      ],
      "layout": "IPY_MODEL_9acfccf60cf94029bbc9f95061a6048a"
     }
    },
    "f711a33c1f664453a8e7514f04a52fe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b72530813cf142c290aceac5bb198838",
      "max": 94551,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb2ec9bb35bd43d492b20bf1234db4bb",
      "value": 94551
     }
    },
    "f73de0e914214591b1eec8c79dea6b61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7d2bdf65a094186b9672f725b5768c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9868ffcced842acb57be30b202649d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9f1f9de43f34bebbd9e56007fef48b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb4a391dc95d404a814635f576c95fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fca86ad563634cc9992724cc868528d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcf5ac563be64dba8271f6ca855db1a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9be3709eb608458aa895aaf56485e3e7",
      "placeholder": "​",
      "style": "IPY_MODEL_fb4a391dc95d404a814635f576c95fd5",
      "value": "Login successful"
     }
    },
    "fd1c7dac9cc24abaa31de91fe5410b0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe05473196f54d6d893f81190cb03106": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ff02416027c746e7931c9239f9279380": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
