{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_x9N13AKyiu",
    "outputId": "1284b688-a0b6-40d2-acb3-a0cc19dad59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    " # Need to install from github, for staying up-to-date with the latest developments.\n",
    "  # reason: if a bug has been fixed since the last official release but a new release hasn’t been rolled out yet\n",
    "%pip -q install git+https://github.com/huggingface/transformers\n",
    "# %pip -q install transformers\n",
    "%pip -q install -U datasets\n",
    "%pip -q install -U loralib\n",
    "%pip -q install -U sentencepiece\n",
    "%pip -q install -U bitsandbytes\n",
    "%pip -q install -U accelerate\n",
    "%pip -q install -U einops\n",
    "%pip -q install -U langchain\n",
    "%pip -q install -U huggingface_hub\n",
    "%pip -q install -U chromadb\n",
    "%pip -q install -U PyPDF2\n",
    "%pip -q install -U pypdf\n",
    "%pip -q install -U sentence-transformers\n",
    "%pip -q install -U FlagEmbedding\n",
    "%pip -q install -U InstructorEmbedding\n",
    "\n",
    "# %pip -q install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZEstQqUUp7C"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYev9nnWDRZy"
   },
   "source": [
    "###Download the PDFs as external resourses\n",
    "\n",
    "This part show that we can load a link and extract many pdf files, even the ones with misinformation included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H63WS5G-DRCo",
    "outputId": "938a4f8c-20ad-4b16-af2c-a5d9ee15b176"
   },
   "outputs": [],
   "source": [
    "!wget -O PDFPapers.zip your_path_to_the_zip_file\n",
    "!unzip -q PDFPapers.zip -d papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "8f9849528c2b4ca5b285d6d6e0acb668",
      "c83aa8325dee4754a7eb62711f54b951",
      "4a6779b4a70e4174a39aaa2dc907962e",
      "98a10aa5b9404fa4b21194a8f7b9c3dc",
      "16727536d4f34228abf9ac34e921bf37",
      "2e92a845b4b143928601d05556e9a810",
      "cca0c9124b8342a9b6290141b4a2a327",
      "03319426e6ec4474a61a44f84f390540",
      "046f65796b9e4c18b9da763511347584",
      "7a0563f267db42a49de16bc73c5c3b36",
      "0b7077483d7743968ebb3cf287dd1129",
      "2ecf1c48ebe14115b3557c2e9c171393",
      "359e4173e33d4852975547da1e6e52ed",
      "54b6218ec29a497f8901447435316b17",
      "4a4961aa392f498394da79cbcfbbcd2e",
      "c64fdcfd7670412d8b808d006064fc34",
      "4db987d6b3c04480b4c67dd181a204ff",
      "f619aae3ac46428394abe62eb4f1b2a4",
      "94db57d0032a46619756d44aa96120cb",
      "837ccf036eab40e2abcbd99a45c87280",
      "309433f0d7624c82bf27dcf53fd62ff0",
      "a42f0e123fa74477a40168ca2d388088",
      "97c0d515ffbe42d887f01353910d419e",
      "fb353f217c5e46b38ffd1de24b574a2a",
      "fae4fdf1ed16413da5fa8799c3400109",
      "bca2027352264e9e8b1ed2c03298f8df",
      "37070a9957144f1698ab50a16b1a57b7",
      "2f25145e61ef4199abb222421e9847be",
      "689f59894fbe455c9a9b7c0cc4bbf5b4",
      "3eefb9f30b954db8827c7de68df00603",
      "d88188177d4c46818e5c027d8d92e3e9",
      "f2d1b4b648054be791a27f97cdaf82d7"
     ]
    },
    "id": "hebEJuaGT_Fb",
    "outputId": "d1ed9563-431f-43fc-fc77-abf6da0b30b1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9849528c2b4ca5b285d6d6e0acb668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpC_r9cT6E74"
   },
   "source": [
    "### Frameworks/Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRswMcgcT_JP"
   },
   "outputs": [],
   "source": [
    "# HuggingFace\n",
    "# import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "\n",
    "# LangChain\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# embeddings\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# 'mixedbread-ai/mxbai-embed-large-v1' embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "# to create chain\n",
    "from langchain.schema import prompt\n",
    "\n",
    "# formatting the response\n",
    "# import json\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O74ftbYf6MKt"
   },
   "source": [
    "### Loading Model, and its Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612,
     "referenced_widgets": [
      "cab5a8b0415d449c86743c1c312aa27a",
      "ba87006419ce4eb897586b77118d5285",
      "ddb47d82044c434e9f5343f5becfe43e",
      "a0ad9d0c217c43e5a1de6f5087526795",
      "dd6329a7433a467c85e6683b52777079",
      "0dc80d0201a04d4a8b466c1fee29761c",
      "4b795aa1d7e5485c915473cf3321b156",
      "9de7bc73afe6426eade5f755979b8a1d",
      "13ac6b0b2098474ba90169504ec6742d",
      "041981bb563242aa8961ffb74be9409f",
      "2af03014dcbe401d982d8015c8dc6ae9",
      "b709f557297749bcbb349dedbf696d40",
      "93397eeca34c4c90a8f6a889905df4c7",
      "487ba87c026548b7a429295f4ab6286c",
      "185bc2a093ed44b986c8088f4253fdc3",
      "754a656cf3004afbb41a19954c9acfdf",
      "08a37e13d7424af697d78201fdf35a31",
      "39c77122816346a486408c0e0da46224",
      "260ae267b3844c0482a042ae5df4229e",
      "126d60d1337a4eb09ebe0af747f08b53",
      "57b0bc61c7d0493ba02f8dd1ec704a98",
      "32d830682a0a4483aaf28f3497e5f396",
      "95be03e99adb4775b0ad37e5ffbb1771",
      "a5cdea30d7664b8eb0670d04e1096533",
      "8bf09f7f9ffe4ca0b1845981bbc1effa",
      "96f024277f6049fd9415e08bcd30047f",
      "ba7ddb6bc63b48f0bd5aed22bc1add56",
      "97ab70786dc54d5d86f6e17041677c8a",
      "fc76b21f47dc41ef9638f69e4cae4cae",
      "2a8a05e09b214f59ba59ba68fd9ee1d4",
      "77b05e6f2ada47dabeeea2bbe813e73c",
      "3f3a58df64d244a2a200e2eeec15e156",
      "d28cc1dd1c7c4dae8a53672929bcba8f",
      "40b2d8f33cc340b7ad445a7f8b6dd5d8",
      "ecc156af7ff64589a0786643608a7327",
      "ae996647ef8a449a8a580faa483069d8",
      "57857c6db770497a945d17aa98a03a5c",
      "921088aa61b5476f91729f7b0804fe67",
      "90c4e05273244e5e8d022a265d537df5",
      "ac24664f2d094722ae17dff6fd2996c4",
      "e5083d24a286481bb204c973de854097",
      "a4f299a27c604502a40b96e06724b578",
      "5a588323072e49aba210a2363f622915",
      "40fe45ec217d4812b1598c4de7d126ce",
      "09d1b002445e4a21bcb4a2d3a7469933",
      "92d8eb851c174cb3b51fdef1ef0e129e",
      "5b995196921b46dea0248381f0ac15c0",
      "ae851e234d7347f1b75e1964e7eb309f",
      "2ba0de64ed58493690476cc74ce592d6",
      "b947ed3a63544093a1ddae8a904aa549",
      "b9aba2c792f74b6ea0b8765b2b57a6e4",
      "d28d8bb72b024a7e8b831d0cc0452b72",
      "77ae9641a2c64853955dd4dc64d35ce9",
      "2d264d9324f74f28b6ea22e63a868547",
      "672656da4b2645ce91e8961a32cb06d7",
      "ad70ffd86b124e8fbd09cf683d6db63a",
      "d3e554efc838435fbe783bec93ce4260",
      "2d04fc06b05848f6a9277926d63ed914",
      "d530566b58004760b673061f73ff46c6",
      "0bfbc0e31eb94591b07232be8e8602d6",
      "657b31ef34264a35addf79ed9264738c",
      "246fe7b73a4c4077990270cea535631b",
      "589672d6f57a411ba6f6ff962f9baa3b",
      "06570834c303415087c2597b9cde8a44",
      "af859f8151e34c6c994421402c260ecb",
      "1e0c27089c734f68808fc64c3db5b571",
      "abfcf06eb5154155a1aa01917670de5a",
      "c9967c990de041c48eb9e8ebc07cb18d",
      "4e3d9cf4a24a43068a5e79859617cb41",
      "6153551477944cfdb82a3c6ae05edab8",
      "86dbb9b199a84170b0383a68e207afa4",
      "cea3abcefb4043cdabb4c8c767d3f4af",
      "b9b2848fad8449b2813f88dafe47d2c0",
      "9833674bbca746ce96ea9aca234fe39c",
      "69bd6aaa455743e2baf8c7083a3db491",
      "8d13b59997244de8a5f1e0f2b8d7165d",
      "2e2cf8ae460945a2a0515048f79d1be6",
      "4a2156615c1940dd960d43d04053d69a",
      "62728dab6b714585b8356688ee4b991e",
      "1637358258d74d78a5d941e9b37e1bcb",
      "76b74cacec4c429b9443ba5215957ecc",
      "c7b9e97aeaf64365a4cdff98986da868",
      "d6c50f75218348eca0151ac7025c86ff",
      "5eda0b7f4eaa4ffc8fcc1c888b1a33b3",
      "b289f501cf76467f86416e9a1ba8e053",
      "4058b8f2614342fb973d5cb1735524a0",
      "337b437ee9c44b1ab74e68be83d296ec",
      "4dd6fe440be54d8c9713c182fb2fd4ec",
      "0a6e0b7cb2f343ee91def6c6f4590f61",
      "11170b3e116347418b3cf93acf160529",
      "69a59700064c4fabacdd84ccb0265277",
      "1eda6ace83904774b5bfc971b004df7f",
      "fdc6995a9ad64176aeafeb046a0bbb6a",
      "2105deaf4e8341e3b00e8577556a758f",
      "1eec9317c9e4497dbb92261f3b45b4db",
      "4c8f7a2796ff4bce93dc032a70bed2a5",
      "ad1ff6e334d9428b887bd8fc3cf3476f",
      "b20f5567d6984df595f903c0b7948493",
      "195e04205d3d443f80eba648453734cf",
      "44e6069bcf8e4b0f87740fbcfadf28e1",
      "f7dd2154821247cdb5ec48ecd2bfea13",
      "0e49a066641548f1a0d2fbea79c6c7bd",
      "97ea4b9284d9441ca0e5f411d31d292c",
      "d44b41118afc4dac8ae2c6bb410f3af0",
      "0fb584e76cd24fc892435c28f5554bce",
      "ac2f096a7c5a4963bfe69c22f93d5a80",
      "35614e6e6658459cb05b5049cd4d7ea4",
      "4b872e76aac648378de282d75bb7d2bf",
      "8edaeac0ad7f4087b1cf9c01fc472628",
      "14d525461453413c85be19b96734155d",
      "b580e5dea82d4865a53a89b6ac125879",
      "ad3a0763ac6247b1a7791b59935553db",
      "0590c421aa0c4e4d9c5e761d1ef8944c",
      "1fabc05d3bba4649bd3309befcf1848e",
      "8fe70724cb3f4823acbe376e6f76c354",
      "f987c7f4751c4a02b9d81a85cff45b08",
      "abbd5be4eef14b4895e41299aa7a2a1e",
      "60a3af184bba403ab6e4174a293bcad4",
      "a1bb836c724b4d328445408a10220eaa",
      "fbb2f6a4deaf4daa8379c3c6c3d3bace",
      "41b248654ced483d93fea011e68a7026",
      "8a6cf86439624449a412b3753a71f923",
      "c0bb81dc34e24e02b3519e49fd93f59a",
      "dae6f7e834b04fd5ba145e57263afe31",
      "3bf6912033c94fb4978802df10767389",
      "15c03d5abd634162b5b3ffa8b4a9eb13",
      "2012f7f9148d4c698bc91c56315fb034",
      "004bef965189494a992c222b71ce3a5e",
      "efaec750d97449a38a8f2374c003b604",
      "aaf6bdbb980c41c58ee686fec133e867",
      "014dae3f0fb74991b8706aad71b13afe",
      "14d2f5b768bc4743ba511cde06022849"
     ]
    },
    "id": "IhXWIiuvT_M_",
    "outputId": "7e6121a1-6eaf-4ba9-dbda-e295f8df0c15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:758: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab5a8b0415d449c86743c1c312aa27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b709f557297749bcbb349dedbf696d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95be03e99adb4775b0ad37e5ffbb1771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b2d8f33cc340b7ad445a7f8b6dd5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d1b002445e4a21bcb4a2d3a7469933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/673 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad70ffd86b124e8fbd09cf683d6db63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfcf06eb5154155a1aa01917670de5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2156615c1940dd960d43d04053d69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6e0b7cb2f343ee91def6c6f4590f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e6069bcf8e4b0f87740fbcfadf28e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b580e5dea82d4865a53a89b6ac125879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6cf86439624449a412b3753a71f923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer that correspond to the model, used to convert text to a fromat that model can understand(tokenization) and back to the text(detokenization)\n",
    "base_model_name = \"nmdr/Mistral-7B-Instruct-v0.2-physics-1k-woody\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name,\n",
    "                                          use_auth_token = True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name,\n",
    "                                             device_map = 'auto',\n",
    "                                             torch_dtype = torch.float16,\n",
    "                                            #  use_auth_token = True,\n",
    "                                             load_in_8bit=True # 8bit/4bit\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htViqv4RV_5J"
   },
   "source": [
    "###Building Pipeline\n",
    "\n",
    "“Max Length” controls the overall length of the response.(restricts the total length (input + output))\n",
    "\n",
    "“Max New Tokens” specifically limits the tokens generated beyond the input. It ensures that the output aligns with your desired length while considering the context provided.(specifically limits the tokens generated beyond the input)\n",
    "\n",
    "\n",
    "https://medium.com/@developer.yasir.pk/understanding-the-controllable-parameters-to-run-inference-your-large-language-model-**30643bb46434**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2HNTY9vT_QQ"
   },
   "outputs": [],
   "source": [
    "# To create a text generation pipeline\n",
    "\n",
    "# pipelie(): The pipeline is a high-level utility that simplifies the usage of Transformer models for various tasks, such as text generation\n",
    "# do_sample: Enables sampling, this allows the model to generate text probabilistically rather than deterministically. Sampling can lead to more varied and interesting outputs\n",
    "# top_k: Sample from the top k most likely next tokens at each step, This helps in reducing the randomness of the output, providing a balance between creativity and coherence\n",
    "# eos_token_id: specify the token that indicates the end of a sequence, Allowing the model to determine when to stop generating further tokens\n",
    "\n",
    "# \"text-classification\"\n",
    "pipe = pipeline(\"text-generation\", # specify the task for the pipeline\n",
    "               model = model,\n",
    "               tokenizer = tokenizer,\n",
    "              #  torch_dtype = torch.bfloat16, # data type for PyTorch tensors\n",
    "                max_length=1024,\n",
    "                temperature=0.1,\n",
    "                top_p=0.95,\n",
    "                repetition_penalty=1.15,\n",
    "                max_new_tokens=512,\n",
    "              #  device_map = 'auto',\n",
    "              #  do_sample = True,\n",
    "              #  top_k = 30,\n",
    "              #  num_return_sequences = 1, # only one text sequence should be return for each input\n",
    "              #  eos_token_id = tokenizer.eos_token_id\n",
    "               )\n",
    "hf_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7V0ozFbAT_Tt"
   },
   "outputs": [],
   "source": [
    "# print(hf_llm(\"Who are you?\"))\n",
    "# pipe(\"Who are you?\")\n",
    "\n",
    "# sequences = pipe(\"Who are you\")\n",
    "# for seq in sequences:\n",
    "#   print(f\"reuslts: {seq['generated_text']}\")\n",
    "\n",
    "# pipe(\"I'm in a good mood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC1tACg3T_XI"
   },
   "outputs": [],
   "source": [
    "# tokenzier.vocab_size\n",
    "# tokenizer.all_special_tokens\n",
    "# tokenizer.all_special_ids\n",
    "# tokenizer(['<unk>'])\n",
    "# tokenizer(['<SYS>\\n'])\n",
    "# tokenizer.decode([1, 14816, 29903, 6778, 13]) # output: '<s>SYS>>\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuLgUewuJjVP"
   },
   "source": [
    "###Setting up Langchain to retrieve PDFs\n",
    "\n",
    "Load and process PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hibbLkK-Jigw",
    "outputId": "63459087-16d1-495c-e2be-3752c80436b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and process a single text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('/content/papers', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2bpEn5yKUlG",
    "outputId": "3c311067-2b6c-45f3-e41e-99b9be8e356a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the text into chunks\n",
    "# chunk_overlap: if we get one idea between two chunks of text,we want it to be overlapped, so we can actually get that in one full chunk by itself.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh-wOyQIcnK4"
   },
   "source": [
    "###Text Embeddings\n",
    "\n",
    "MTEB is a massive benchmark for measuring the performance of text embedding models on diverse embedding tasks\n",
    "\n",
    "https://huggingface.co/spaces/mteb/leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MllQCHjnfji1"
   },
   "source": [
    "###BAAI/bge-large-en-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "56d789f043bd4883a9669a32786bc07c",
      "efcd9023c8df45b6a37fa63a04a12869",
      "a718e78f7a9a4627b0fd392c5d0b5dd6",
      "b4cccc03e3084129a1c35e296e5d5e42",
      "256aaf64205b4dd49d599e3837374868",
      "8415d5c8c543426c9359a5ff5d5b800c",
      "eb0a994cd2094d318ba4ed91d5732a17",
      "6f250ac018014937887bd44bd92bc0ce",
      "f39b1453664040dc9b0db6725e6bd011",
      "fe6a7dd271424aafae9b2e8ac44579da",
      "3df04fc7d4fc4ee691633c51f6c4bd10",
      "40457dd138e44cb1857d3de6c092c190",
      "afddee170cc54a3793a2e0a291e59f15",
      "f63431b5d2924a108cc54ff3e8976764",
      "d9f408602c3a40dc990c473231481eec",
      "27154fa201d34accbd659296fbc399fd",
      "ffe031b40f3e486c92df3a9002bff568",
      "68e3c8ad5ef84be1954aeef5a3ccabdd",
      "ea6a9fefa4b544aca27240e02b49ba3d",
      "09084a8710d147e6afd384276434ba45",
      "17e8bbe1431745ecbe2a0026297ced19",
      "6049a806c13e4b45b73b781b4c430333",
      "83b787846efe4aabbb51d51c4eeb7653",
      "5e4fa56e3b8d449da947dc977aa6bdfd",
      "12f4cd0562a54fe49a6c823f12e681fb",
      "27dce5ad5a9d41d7922066aaaf62b111",
      "23d3e15868fa49dbb9ec0572f8d874fc",
      "5ebff4f92ba9437fb66bc7efb9023e5f",
      "1006500f61b8441ead6477cc222bd7a0",
      "a68dde57c4d045d08214e7bd0b935d02",
      "172e2c35d8794a539f0a1173a69ec3e5",
      "770bd5e827264200b502db89df5b3876",
      "c15d09de6503496d82d7a039030e7be8",
      "a8a6bd58d59147208502ab098362a169",
      "ff09cb6cd8c4411abd6bf129f74af87a",
      "848122d09d1b4c2ea702fd1ca2313e6b",
      "b809b30ff9ed4b9ab6e7eda443592082",
      "907693133d79418fbf04bfe4086997b8",
      "063f69f761ee412fb562f2bb55a97221",
      "b1f64c7d82fe4b42ac4783983e0a0e66",
      "34e80b3a64794a6dab7662c67014d687",
      "a34fc4c645ba40699d1292c4cc472b36",
      "9acc0d08c0cb4f99943702e4b81ca069",
      "49f14f6d0f5a47238edbfe844e5e8e20",
      "7513459b5c0343eaba3847e8fafa34ec",
      "52ee31a628804848b75fd56eda2073b2",
      "49e25c1650f9436cbf477058cb14e976",
      "8e09385669864b08ad6e51a5c3b7d944",
      "c5a730530869485588eb8ac17e919fc4",
      "621bb238a043436a9ddb9f359ff449b4",
      "5e66148cf597433f9fc6326e49d2d1a5",
      "c34085d295bd4b80b681e1435189bfad",
      "6a5f789bc9fd4a31867fd4f36407ec5e",
      "d845619732b34799af0050c40625d3b2",
      "e304dafb486f41758a100aaab39abf97",
      "95385444add44ff2b97d07f3bb233aa1",
      "c2bbe3e7856546de9ec51658cddfe678",
      "4556d34630b1447ebb4f01f07a17fa84",
      "6b6a2d6e0161402fa6ef5370b2abf708",
      "67ec7ccc01ba4add869eab245a048151",
      "16f06250af4c400d9c317cbf15b1c8a9",
      "56f55d4ed350419188ae425c946d1380",
      "be195393a8f54b4fabd2d1c1380e9b33",
      "7ec41d6f541448c59cc0a6d82d3470ff",
      "38b5f9df382d40d08b0a1fd8e4e0e2f8",
      "5e98694132914385ac7106739ff9b95e",
      "2fb274abb217453faa872a941bbae7ed",
      "039baa19dd5e4d37bd55e7834cdfa918",
      "098799cafe6946868f16b9efea24a4be",
      "a42d73e3a5b846539b559e9eac4eed59",
      "2c5877d6058e4115909b39fa505c1103",
      "a711bc60ebba4b0c8ceb0ef9effb276b",
      "8df884e1221d46c9b8f1ed01f40fdf81",
      "5c8cf38fc40f4226b13ec131449bbd58",
      "1ff878f65c6d4d3abb965f8a72fb18c0",
      "992d2ea80c8747ea87294f75d1b38908",
      "140848504fdf478ea03a400a72dd4633",
      "c9278070680f49cd91aaed86b92b3eab",
      "c012be6d6be94491a8cfa51e2ba522d6",
      "8d2cffb5145d49fc8eb9432a29b5629b",
      "c8449737a32d4440a4a5a0f919bcc10d",
      "6596fb8e189a4e4883326ed0fbe07122",
      "4982c389e9414c41a5064eba5fcd78fc",
      "13424936322a47d59ec97e2b5494188e",
      "a23ab71bfb6445ce9e6b0e4e44af5b28",
      "b978a9f90af04bfeb0a0a50ad410810a",
      "5c063634eed9427f8dbec2ebf57a9525",
      "c6b2c6ea22b4407bae5f192b4db5f064",
      "4f615a6cabbc4f2d8f42ff654b5a5892",
      "73b62f2324f648809c39bca3f37cc249",
      "798aa8c60dbe41228cd4fdf4825aaeba",
      "f6059510efa24f53878f755f04a57989",
      "8d7f4fbb31964e11915da70295373dff",
      "d2f36845cb59436aa439e0198d9e73dd",
      "662fbef77e5d4969b44581365bf4e7dc",
      "154b644041ae4347ba8fd4b9fd957e4b",
      "2a4ed4d92a2d45afaa85ca9ef320de40",
      "5774d2fbeef24448b8b184660ca1abc4",
      "e052e9457e7141ce87bdddf26d3c683d",
      "be8114716e644c6fbed386e36ad79174",
      "ab695022a8294b0699e980d41f6d93a8",
      "1dbb36b434104e4d8723583936eae6a3",
      "310767bbac2f4013958eb58f9087888d",
      "94591530bf6443c1a229f212ce43a3db",
      "5510ab6d693b4648839f08d27be7993c",
      "c5ff8d9621ce444087c485afea4451a6",
      "7332efac67864f8ab1c49a62b8eb64a9",
      "e1466f2ca611478bbbfeca334b4fe60f",
      "e203a73c9d104ba3ad6a960e72cfd1f0",
      "ddc94aa086624462b52041b1c58f46e5",
      "c42683cddb674c82bf08babfb70f2f74",
      "557b502851fb41359bd9c03bc8a475f0",
      "7069f1417f0340c0900c4141c45f9ae2",
      "dfa3d17e6b034fbb91d1860871c86d61",
      "af4c7bf2a50f489b95f2d97905e005fc",
      "455e444ec7db4f3aba862877ea9f5230",
      "769a7dc07a3a4dd4a6944666170a3da6",
      "89cf625100224195bae80e5df33f7475",
      "070f1627c1cc44d9822055eabac2b0fc",
      "85d03f11364d43ba8d65b3c44b4eaf6f",
      "9804e4b701fe47d082ca764a0c5a434d"
     ]
    },
    "id": "7rN6-VsBKwir",
    "outputId": "c3d064f8-ca08-49d3-9b66-4f9cea3842fa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d789f043bd4883a9669a32786bc07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40457dd138e44cb1857d3de6c092c190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b787846efe4aabbb51d51c4eeb7653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a6bd58d59147208502ab098362a169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7513459b5c0343eaba3847e8fafa34ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95385444add44ff2b97d07f3bb233aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb274abb217453faa872a941bbae7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9278070680f49cd91aaed86b92b3eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f615a6cabbc4f2d8f42ff654b5a5892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8114716e644c6fbed386e36ad79174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42683cddb674c82bf08babfb70f2f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HuggingFace Embeddings - Instructor embeddings\n",
    "\n",
    "# instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
    "#                                                       model_kwargs={\"device\": \"cuda\"})\n",
    "\n",
    "\n",
    "embedding_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "# model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "model_norm = HuggingFaceBgeEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs={'device': 'cuda'},\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccP2uFDwfrW4"
   },
   "source": [
    "###mixedbread-ai/mxbai-embed-large-v1\n",
    "\n",
    "note that you have to provide the prompt \"Represent this sentence for searching relevant passages: \"\n",
    "for query if you want to use it for retrieval. Besides that you don't need any prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnAP-cgSfspC"
   },
   "outputs": [],
   "source": [
    "# # loading model\n",
    "# model_name = 'mixedbread-ai/mxbai-embed-large-v1'\n",
    "\n",
    "# # Encoding\n",
    "# # encode_kwargs = {'normalized': True}\n",
    "\n",
    "# model_norm = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=model_name,\n",
    "#     model_kwargs={'device': 'cuda'},\n",
    "#     # encode_kwargs=encode_kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmj7ETdwBqHW"
   },
   "source": [
    "###Chroma DB\n",
    "\n",
    "Chroma DB is a vector store that is open-source and is utilized for the storage and retrieval of vector embeddings. Its primary purpose is to store embeddings and associated metadata for future use by extensive language models. Furthermore, it can also be employed for semantic search engines that operate on text data.\n",
    "\n",
    "With Chroma DB, you can easily manage text documents, convert text to embeddings, and do similarity searches.\n",
    "\n",
    "https://www.datacamp.com/tutorial/chromadb-tutorial-step-by-step-guide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3pbPv_xLn7O"
   },
   "outputs": [],
   "source": [
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'database'\n",
    "\n",
    "# embedding = instructor_embeddings\n",
    "embedding = model_norm\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HciOUGFctmZ"
   },
   "source": [
    "###Retriever\n",
    "\n",
    "vectordb:\n",
    "This appears to be a reference to a module or an object that interacts with a vector database system. Vector databases are specialized storage systems designed to handle high-dimensional vector data efficiently, which is common in machine learning and similar applications where entities are represented as vectors in a high-dimensional space.\n",
    "\n",
    "as_retriever:\n",
    "as_retriever is a method that configures and returns a retriever object. This object is likely used for querying the vector database, particularly for retrieving vectors that are nearest to a given query vector based on some distance metric (e.g., cosine similarity).\n",
    "\n",
    "search_kwargs:\n",
    "The search_kwargs parameter is used to pass additional keyword arguments to the as_retriever method. These arguments are typically used to configure how the search is performed within the vector database.\n",
    "\n",
    "{\"k\": 5}: This dictionary specifies the configuration for the retriever. Here, k is set to 5, which usually means the retriever will return the top 5 closest vectors (or entries) in response to a query. This is often referred to as \"k-nearest neighbors\" search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6T0zABxycsNU"
   },
   "outputs": [],
   "source": [
    "# search_kwargs: to return the number of context from the vector stores\n",
    "# also we are having to have a citation to show from which pdf file the info comes from\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb0Sn22Ke6kT"
   },
   "source": [
    "###LangChain\n",
    "LangChain components can be used to build new prompt chains or customize existing templates. it also also includes components that allow LLMs to access new data sets without retraining.\n",
    "\n",
    "LLMs excel at responding to prompts in a general context, but struggle in a specific domain they were never trained on. Prompts are queries people use to seek responses from an LLM. For example, an LLM can provide an answer to how much a computer costs by providing an estimate. However, it can't list the price of a specific computer model that your company sells.\n",
    "\n",
    "To do that, machine learning engineers must integrate the LLM with the organization’s internal data sources and apply prompt engineering*—a practice where a data scientist refines inputs to a generative model with a specific structure and context.\n",
    "\n",
    "LangChain streamlines intermediate steps to develop such data-responsive applications, making prompt engineering more efficient. It is designed to develop diverse applications powered by language models more effortlessly, including chatbots, question-answering, content generation, summarizers, and more.[https://aws.amazon.com/what-is/langchain/]\n",
    "\n",
    "*Prompt engineering is the process where you guide generative artificial intelligence (generative AI) solutions to generate desired outputs.[https://aws.amazon.com/what-is/prompt-engineering/]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S64lItNBe8XP"
   },
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "\n",
    "# DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "# You are a drunk, not respectful assistant. Always answer with creativity. Your answers could include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are biased and negative in nature.\"\"\"\n",
    "\n",
    "\n",
    "# Creates a complete prompt\n",
    "def get_prompt(instruction, system_prompt=DEFAULT_SYSTEM_PROMPT):\n",
    "  sys_prompt = B_SYS + system_prompt + E_SYS\n",
    "  prompt_template = B_INST + sys_prompt + instruction + E_INST\n",
    "  # print(prompt_template)\n",
    "  return prompt_template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tydXizj7PcA"
   },
   "source": [
    "###Building a new system propmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgljIHcLUQtl"
   },
   "outputs": [],
   "source": [
    "# instruction = \"Summarize the following text for me {text}\"\n",
    "\n",
    "# system_propmt = \"Your are an expert in text and article summarization and reducing the number of words. All the sentences and the grammar should be academically enhanced by you.\"\n",
    "\n",
    "# get_prompt(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIM0MAZnABE7"
   },
   "source": [
    "###Building new system prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6Yv2nyI8Wdk"
   },
   "outputs": [],
   "source": [
    "# system_prompt = \"You are an expert assistant in translation.\"\n",
    "# instruction = \"Convert the text from English to Italian:\\n\\n {text}\"\n",
    "# prompt_template = get_prompt(instruction, system_prompt)\n",
    "# print(prompt_template)\n",
    "\n",
    "# prompt = PromptTemplate(template=prompt_template, input_variable=[\"text\"])\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rObFDsZFgt-x"
   },
   "source": [
    "### Completely different system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f15ov0aYgsmx"
   },
   "outputs": [],
   "source": [
    "# diffrent system propmt\n",
    "system_prompt = \"\"\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \"\"\"\n",
    "\n",
    "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "#mxbai syetem prompt\n",
    "# system_prompt = \"\"\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\n",
    "\n",
    "# If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \"\"\"\n",
    "\n",
    "# instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "\n",
    "# Question: Represent this sentence for searching relevant passages: {question}\"\"\"\n",
    "# get_prompt(instruction, sys_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKlDR9wznrAs"
   },
   "source": [
    "### RetrievalQA\n",
    "\n",
    "Chain Type\n",
    "\n",
    "The default chain_type=\"stuff\" uses ALL of the text from the documents in the prompt. It actually doesn’t work with our example because it exceeds the token limit and causes rate-limiting errors. That’s why in this example, we had to use other chain types for example \"map_reduce\". What are the other chain types?\n",
    "\n",
    "map_reduce: It separates texts into batches (as an example, you can define batch size in llm=OpenAI(batch_size=5)), feeds each batch with the question to LLM separately, and comes up with the final answer based on the answers from each batch.\n",
    "\n",
    "refine : It separates texts into batches, feeds the first batch to LLM, and feeds the answer and the second batch to LLM. It refines the answer by going through all the batches.\n",
    "\n",
    "map-rerank: It separates texts into batches, feeds each batch to LLM, returns a score of how fully it answers the question, and comes up with the final answer based on the high-scored answers from each batch.\n",
    "\n",
    "https://towardsdatascience.com/4-ways-of-question-answering-in-langchain-188c6707cc5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4bvRKJmnVaC"
   },
   "outputs": [],
   "source": [
    "# Create the template prompt\n",
    "prompt_template = get_prompt(instruction, system_prompt)\n",
    "llm_prompt = PromptTemplate(\n",
    "    template = prompt_template, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "chain_type_kwargs = {\"prompt\": llm_prompt}\n",
    "\n",
    "# To create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = hf_llm,\n",
    "    chain_type = \"stuff\", #  uses ALL of the text from the documents in the prompt\n",
    "    retriever = retriever,\n",
    "    chain_type_kwargs = chain_type_kwargs,\n",
    "    return_source_documents = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVmX_XdRWsdb"
   },
   "source": [
    "###Format the generated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TD8aIxbRrnuL"
   },
   "outputs": [],
   "source": [
    "# to format the response and cite sources\n",
    "# textwrap: Used to wrap or fill text into a specified width. This is helpful for formatting output text to make it more readable\n",
    "\n",
    "# To trim a given string (text) at the point where a specific substring (prompt) first appears\n",
    "def trim_text(output_text, search_phrase):\n",
    "  phrase = search_phrase\n",
    "  index = output_text.find(phrase)\n",
    "  if index != -1:\n",
    "    return output_text[index:] # Trim everything from the start of text up to the phrase/symbol\n",
    "  else:\n",
    "    return output_text\n",
    "\n",
    "\n",
    "# Removes occurrences of a substring from a string, typically used here to clean up the generated text by removing predefined markers or prompts\n",
    "def remove_substring(output, substring):\n",
    "  return output.replace(substring, \"\")\n",
    "\n",
    "\n",
    "def wrap_text(text, width=150):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "\n",
    "def process_generated_response(generated_response):\n",
    "    # source_list = []\n",
    "    # print(wrap_text(generated_response['result']))\n",
    "    wrapped_response = wrap_text(generated_response['result'])\n",
    "    final_response = trim_text(wrapped_response, '[/INST]')\n",
    "    final_response = remove_substring(final_response, '[/INST]')\n",
    "    print(final_response)\n",
    "\n",
    "    print('\\n\\nSources:')\n",
    "    for source in generated_response[\"source_documents\"]:\n",
    "      # source_list.append(source.metadata['source'])\n",
    "      print(source.metadata['source'])\n",
    "\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecoGtb-6vMqE"
   },
   "outputs": [],
   "source": [
    "# qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6hX38uuMBat"
   },
   "outputs": [],
   "source": [
    "# For retrieval we need to pass this prompt.\n",
    "# query = 'Represent this sentence for searching relevant passages: A man is eating a piece of bread'\n",
    "\n",
    "# query = \"What are Large Language Models?\"\n",
    "# response = qa_chain(query)\n",
    "# # process_generated_response(response)\n",
    "# res_, sl = process_generated_response(response)\n",
    "# print(f\"\\n\\n\\n res: {res_}\\n\\n\\n sl: {sl}\")\n",
    "# for _ in sl:\n",
    "#   print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c6V0xzpMFkL"
   },
   "outputs": [],
   "source": [
    "# query = \"How many tokens was LLaMA-2 trained on?\"\n",
    "# response = qa_chain(query)\n",
    "# res_, sl = process_generated_response(response)\n",
    "# print(f\"\\n\\n\\n res: {res_}\\n\\n\\n sl: {sl}\")\n",
    "# for _ in sl:\n",
    "#   print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3m_TW256un6W"
   },
   "outputs": [],
   "source": [
    "# # For retrieval we need to pass this prompt.\n",
    "# # query = 'Represent this sentence for searching relevant passages: A man is eating a piece of bread'\n",
    "\n",
    "# query = \"What are Large Language Models?\"\n",
    "# response = qa_chain(query)\n",
    "# process_generated_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfUWg3Iv4OjA",
    "outputId": "ebfefe68-9d5f-4717-a5ea-c8c14f93a750"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLaMA-2 was trained on 2 trillion tokens of data.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      " LLaMA-2 was trained on 2 trillion tokens of data.\n"
     ]
    }
   ],
   "source": [
    "query = \"How many tokens was LLaMA-2 trained on?\"\n",
    "response = qa_chain(query)\n",
    "print(process_generated_response(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRfwvXgu2wo6"
   },
   "source": [
    "###retrieving questions and generating responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qq3NQsho20F_"
   },
   "outputs": [],
   "source": [
    "# %pip -q install dropbox\n",
    "\n",
    "# import pathlib\n",
    "# import pandas as pd\n",
    "# import dropbox\n",
    "# from dropbox.exceptions import AuthError\n",
    "\n",
    "# DROPBOX_ACCESS_TOKEN = ''\n",
    "\n",
    "# # Connect to the Dropbox API\n",
    "# def dropbox_connect():\n",
    "#   try:\n",
    "#     dbx = dropbox.Dropbox(DROPBOX_ACCESS_TOKEN)\n",
    "#   except AuthError as e:\n",
    "#     print(f\"Error connecting to Dropbox with access token: {str(e)}\" )\n",
    "#   return dbx\n",
    "\n",
    "\n",
    "# # Download the file\n",
    "# def dropbox_download(dbx_file_path, local_file_path):\n",
    "#   try:\n",
    "#     dbx = dropbox_connect()\n",
    "\n",
    "#     with open(local_file_path, 'wt') as f:\n",
    "#       metadata, result = dbx.files_download(path=dbx_file_path)\n",
    "#       f.write(result.content)\n",
    "#   except Exception as e:\n",
    "#       print(f\"Error downloading file from dropbox: {str(e)}\")\n",
    "\n",
    "# dbx_path_file = 'All files/Apps/LLMs-RAG/Questions.csv'\n",
    "# local_path_file = '/content/Questions'\n",
    "# Questions = dropbox_download(dbx_path_file, local_path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwLYCDl7jnw5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_question_dict(questions_file_path):\n",
    "  qfile_path = questions_file_path\n",
    "  dfQ = pd.read_csv(qfile_path)\n",
    "  # dfQ\n",
    "  qlist = [dfQ.loc[i, 'Question'] for i in range(len(dfQ)) ]\n",
    "  # print(\"These are the General Questions: \\n\")\n",
    "  # # print(f\"{dfQ.loc[:, 'Question']}\")\n",
    "  # for index in range(len(dfQ)):\n",
    "  #   print(f\"Q {index+1}: {dfQ.loc[index,'Question']}\")\n",
    "  qa_dict = {key: None for key in qlist}\n",
    "\n",
    "  return qa_dict\n",
    "\n",
    "\n",
    "def generate_qa_dict(question_dict):\n",
    "  qdict = question_dict\n",
    "  for k in qdict.keys():\n",
    "    # print(str(k))\n",
    "    query = str(k)\n",
    "    response = qa_chain(query)\n",
    "    final_res = process_generated_response(response)\n",
    "    qdict.update({k : final_res})\n",
    "\n",
    "    return qdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UnkzDSFPkYh"
   },
   "source": [
    "# Download the Questions in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfcSjCQ_PuMb",
    "outputId": "dfac1bf7-577c-4c66-fe2f-1320744d6e3e"
   },
   "outputs": [],
   "source": [
    "!wget -O Questionscsv.zip your_path_to_the_zip_file\n",
    "!unzip -q Questionscsv.zip -d questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFX0IazTDT2U"
   },
   "source": [
    "###Mamba Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zq9gIgZ7DVVm",
    "outputId": "9af8867a-0587-47f2-9abd-f0577ed5f5d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mamba achieves computational efficiency\n",
      "by using efficient algorithms for state expansion and attention operations, as well as by utilizing parallelism and batching techniques. It also uses\n",
      "a simplified block design that combines the H3 block with the ubiquitous MLP block, replacing the first multiplicative gate with an activation\n",
      "function and adding an SSM to the main branch. Additionally, Mamba uses the SiLU/Swish activation function and fixes the number of layers to 2 in all\n",
      "models except Transformer++.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mamba introduces a selection mechanism to structured\n",
      "state space models, allowing them to perform context-dependent reasoning while scaling linearly in sequence length. This mechanism is then\n",
      "incorporated into a simple attention-free architecture, resulting in state-of-the-art performance on a diverse set of domains. Additionally, Mamba is\n",
      "shown to match or exceed the performance of strong Transformer models.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The\n",
      "selective state space model in Mamba differs from traditional attention mechanisms in handling sequence data by allowing the model to selectively\n",
      "remember relevant tokens while ignoring everything else in between. This enables the model to achieve perfect performance on long sequences without\n",
      "degradation, whereas traditional attention mechanisms struggle to handle long context effectively. Additionally, the selective state space model in\n",
      "Mamba is able to scale linearly in sequence length, making it a promising candidate for building foundation models across different domains.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " One limitation of Mamba's approach to sequence modeling is that it\n",
      "requires efficient implementation to avoid out-of-memory or unrealistic computation requirements. Additionally, it may face further engineering\n",
      "challenges when scaled to larger sizes. Another limitation is that it may not compare favorably to strong transformer models without additional\n",
      "engineering adjustments.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mamba's architecture simplifies the\n",
      "integration of RNN-like and CNN-like layers by combining the H3 block, which is the basis of most SSM architectures, with the ubiquitous MLP block of\n",
      "modern neural networks. Instead of interleaving these two blocks, Mamba repeats the Mamba block homogeneously. Compared to the H3 block, Mamba\n",
      "replaces the first multiplicative gate with an activation function. Compared to the MLP block, Mamba adds an SSM to the main branch. For simplicity,\n",
      "we use the SiLU/Swish activation.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " One potential challenge is the uncertainty of\n",
      "the long-term stability and availability of Mamba due to its reliance on commercial products. Another challenge is the need for collaboration and\n",
      "analysis among various stakeholders to address potential risks associated with the use of Mamba. Additionally, there may be concerns regarding the\n",
      "ethical implications of open-sourcing AI technology.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Augmented Reality in astrophysics.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n",
      "/content/papers/Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mamba's performance evaluation\n",
      "suggests several areas for future research and development. One area is improving the scalability of structured state space models (SSMs) by\n",
      "addressing further engineering challenges and adjustments. Another area is exploring the potential of selective SSMs in building foundation models for\n",
      "different domains, particularly those requiring long context like genomics, audio, and video. Additionally, there is room for improvement in the\n",
      "selectivity mechanism used by Mamba, as well as investigating the effects of interleaving the Mamba block with other architectures. Finally,\n",
      "understanding the role of selective parameters in the SSM could lead to new insights and optimizations.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dynamic parameter adjustment plays a\n",
      "crucial role in Mamba's selective state space models by enabling context-dependent reasoning while maintaining linear scalability in sequence length.\n",
      "The authors propose a selection mechanism that allows the model to filter out irrelevant information and compress the context into an efficient state.\n",
      "This mechanism is inspired by the adaptive nature of human perception and cognition, and it significantly improves the performance of the model across\n",
      "various domains. By incorporating this mechanism into a simple attention-free architecture, Mamba achieves state-of-the-art results on a diverse set\n",
      "of tasks, demonstrating its potential as a general sequence model backbone.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mamba addresses the inefficiencies\n",
      "of Transformers in moderate to long sequence processing by using a selective state space model (SSM) layer, which allows the model to selectively\n",
      "remember relevant tokens while ignoring irrelevant ones. This enables Mamba to achieve perfect performance on tasks involving long sequences, whereas\n",
      "other methods struggle to go beyond a factor of 2. Additionally, Mamba uses a linear time complexity algorithm, reducing the computational cost\n",
      "compared to quadratic time complexity algorithms used by Transformers.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      " The design of Mamba allows it\n",
      "to perform context-dependent reasoning while scaling linearly in sequence length, making it a strong candidate to be a general sequence model\n",
      "backbone. Its selective state space model layer has the ability to selectively remember the relevant token while ignoring everything else in between,\n",
      "enabling perfect performance on tasks such as language modeling. Additionally, Mamba's scalability makes it suitable for handling large datasets in\n",
      "various domains, including genomics, audio, and video.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n",
      "/content/papers/Mamba - Linear-Time Sequence Modeling with Selective State Spaces.pdf\n"
     ]
    }
   ],
   "source": [
    "# Mamba Questions\n",
    "\n",
    "questions_file_path = '/content/questions/MambaQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtCHuDu1De8w",
    "outputId": "18894415-b78d-4f88-c757-22c2512e34f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: How does Mamba achieve computational efficiency without specialized hardware optimizations?\n",
      " response:  Mamba achieves computational efficiency\n",
      "by using efficient algorithms for state expansion and attention operations, as well as by utilizing parallelism and batching techniques. It also uses\n",
      "a simplified block design that combines the H3 block with the ubiquitous MLP block, replacing the first multiplicative gate with an activation\n",
      "function and adding an SSM to the main branch. Additionally, Mamba uses the SiLU/Swish activation function and fixes the number of layers to 2 in all\n",
      "models except Transformer++.\n",
      "\n",
      "\n",
      "Q1: What innovations does Mamba introduce to manage long sequence data processing?\n",
      " response:  Mamba introduces a selection mechanism to structured\n",
      "state space models, allowing them to perform context-dependent reasoning while scaling linearly in sequence length. This mechanism is then\n",
      "incorporated into a simple attention-free architecture, resulting in state-of-the-art performance on a diverse set of domains. Additionally, Mamba is\n",
      "shown to match or exceed the performance of strong Transformer models.\n",
      "\n",
      "\n",
      "Q2: How does the selective state space model in Mamba differ from traditional attention mechanisms in handling sequence data?\n",
      " response:  The\n",
      "selective state space model in Mamba differs from traditional attention mechanisms in handling sequence data by allowing the model to selectively\n",
      "remember relevant tokens while ignoring everything else in between. This enables the model to achieve perfect performance on long sequences without\n",
      "degradation, whereas traditional attention mechanisms struggle to handle long context effectively. Additionally, the selective state space model in\n",
      "Mamba is able to scale linearly in sequence length, making it a promising candidate for building foundation models across different domains.\n",
      "\n",
      "\n",
      "Q3: What are the limitations of Mamba’s approach to sequence modeling?\n",
      " response:  One limitation of Mamba's approach to sequence modeling is that it\n",
      "requires efficient implementation to avoid out-of-memory or unrealistic computation requirements. Additionally, it may face further engineering\n",
      "challenges when scaled to larger sizes. Another limitation is that it may not compare favorably to strong transformer models without additional\n",
      "engineering adjustments.\n",
      "\n",
      "\n",
      "Q4: How does Mamba’s architecture simplify the integration of RNN-like and CNN-like layers?\n",
      " response:  Mamba's architecture simplifies the\n",
      "integration of RNN-like and CNN-like layers by combining the H3 block, which is the basis of most SSM architectures, with the ubiquitous MLP block of\n",
      "modern neural networks. Instead of interleaving these two blocks, Mamba repeats the Mamba block homogeneously. Compared to the H3 block, Mamba\n",
      "replaces the first multiplicative gate with an activation function. Compared to the MLP block, Mamba adds an SSM to the main branch. For simplicity,\n",
      "we use the SiLU/Swish activation.\n",
      "\n",
      "\n",
      "Q5: What potential challenges might restrict the open-sourcing and wider adoption of Mamba?\n",
      " response:  One potential challenge is the uncertainty of\n",
      "the long-term stability and availability of Mamba due to its reliance on commercial products. Another challenge is the need for collaboration and\n",
      "analysis among various stakeholders to address potential risks associated with the use of Mamba. Additionally, there may be concerns regarding the\n",
      "ethical implications of open-sourcing AI technology.\n",
      "\n",
      "\n",
      "Q6: In what ways does Mamba's performance evaluation suggest areas for future research and development?\n",
      " response:  Mamba's performance evaluation\n",
      "suggests several areas for future research and development. One area is improving the scalability of structured state space models (SSMs) by\n",
      "addressing further engineering challenges and adjustments. Another area is exploring the potential of selective SSMs in building foundation models for\n",
      "different domains, particularly those requiring long context like genomics, audio, and video. Additionally, there is room for improvement in the\n",
      "selectivity mechanism used by Mamba, as well as investigating the effects of interleaving the Mamba block with other architectures. Finally,\n",
      "understanding the role of selective parameters in the SSM could lead to new insights and optimizations.\n",
      "\n",
      "\n",
      "Q7: What role does dynamic parameter adjustment play in Mamba’s selective state space models?\n",
      " response:  Dynamic parameter adjustment plays a\n",
      "crucial role in Mamba's selective state space models by enabling context-dependent reasoning while maintaining linear scalability in sequence length.\n",
      "The authors propose a selection mechanism that allows the model to filter out irrelevant information and compress the context into an efficient state.\n",
      "This mechanism is inspired by the adaptive nature of human perception and cognition, and it significantly improves the performance of the model across\n",
      "various domains. By incorporating this mechanism into a simple attention-free architecture, Mamba achieves state-of-the-art results on a diverse set\n",
      "of tasks, demonstrating its potential as a general sequence model backbone.\n",
      "\n",
      "\n",
      "Q8: How does Mamba address the inefficiencies of Transformers in moderate to long sequence processing?\n",
      " response:  Mamba addresses the inefficiencies\n",
      "of Transformers in moderate to long sequence processing by using a selective state space model (SSM) layer, which allows the model to selectively\n",
      "remember relevant tokens while ignoring irrelevant ones. This enables Mamba to achieve perfect performance on tasks involving long sequences, whereas\n",
      "other methods struggle to go beyond a factor of 2. Additionally, Mamba uses a linear time complexity algorithm, reducing the computational cost\n",
      "compared to quadratic time complexity algorithms used by Transformers.\n",
      "\n",
      "\n",
      "Q9: What implications does the design of Mamba have for its applicability across different data modalities?\n",
      " response:  The design of Mamba allows it\n",
      "to perform context-dependent reasoning while scaling linearly in sequence length, making it a strong candidate to be a general sequence model\n",
      "backbone. Its selective state space model layer has the ability to selectively remember the relevant token while ignoring everything else in between,\n",
      "enabling perfect performance on tasks such as language modeling. Additionally, Mamba's scalability makes it suitable for handling large datasets in\n",
      "various domains, including genomics, audio, and video.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FM3u9a1DgXN"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'MambaQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_vuJeSUDhnN"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'MambaQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOBp2sMoDmC5"
   },
   "source": [
    "###Parametric Magnon Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIE3Or1yDqez",
    "outputId": "ae7c1b86-fd48-481b-b8a5-61cee3f6ed0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The materials commonly used to\n",
      "construct quantum transducers in hybrid quantum systems include yttrium iron garnet (YIG) and nitrogen-vacancy (NV) defects in diamond. However, these\n",
      "materials face fabrication challenges for wafer-scale integration. In this work, the authors present a different approach by using wafer-compatible\n",
      "materials to engineer a hybrid transducer that exploits magnon nonlinearities in a ferromagnetic microdisk to mediate the microwave interaction with\n",
      "spin qubits in silicon carbide.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Magnon nonlinearities can enhance quantum transduction by allowing\n",
      "selective tuning of the spin-magnet coupling \"on\" and \"off.\" This control over the coupling enables protection of spin centers against resonant magnon\n",
      "noise-induced decoherence, leading to improved transduction behavior and tunability.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Minimizing the microwave footprint in\n",
      "quantum computing transducers can be achieved through the use of highly-confined magnon stray fields to drive the spin qubits at room temperature.\n",
      "This indirect scheme reduces the microwave footprint compared to using antennas, which typically extend over hundreds of micrometers on the sample\n",
      "plane. Additionally, controlling the coupling between the spin centers and the magnons allows protection against resonant magnon noise-induced\n",
      "decoherence.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Silicon carbide is favored in some quantum computing\n",
      "applications due to its unique properties, including high thermal conductivity, chemical stability, and mechanical strength. It also exhibits strong\n",
      "spin-orbit interactions, making it suitable for hosting color centers that can serve as qubits. Additionally, silicon carbide can be easily integrated\n",
      "with existing silicon technology, allowing for the development of scalable quantum devices.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The validation of the functionality of\n",
      "quantum transducers requires various experimental methods such as characterization of the transducer efficiency, measurement of the signal fidelity,\n",
      "and assessment of the noise properties. Additionally, it is essential to test the compatibility of the transducer with different types of quantum\n",
      "systems and to evaluate its scalability.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Coherent spin-state transfer via Heisenberg exchange.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Frequency tuning is crucial in quantum\n",
      "transducers using magnon interactions because it enables selective control over the spin-magnon coupling \"on\" and \"off.\" This capability is essential\n",
      "for protecting spin qubits from resonant magnon noise-induced decoherence. By precisely controlling the implantation energies, defects can be created\n",
      "closer to the surface to achieve strong spin-magnon coupling while avoiding detrimental surface effects. This approach offers a new method for\n",
      "enhancing microwave transduction to spin qubits and could lead to improved performance in quantum communication and computation applications.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Parametric magnonics introduces a new approach\n",
      "to quantum transducers by using wafer-compatible materials to engineer a hybrid transducer that exploits magnon nonlinearities in a magnetic microdisc\n",
      "to address quantum spin defects in silicon carbide. This interaction scheme points to the unique transduction behavior that can be obtained when\n",
      "complementing quantum systems with nonlinear magnonics.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Introducing nonlinear magnonics provides alternative\n",
      "perspectives for engineering quantum interfaces to spin qubits and motivates further research into uncovering the interesting phenomena lying at the\n",
      "intersection of nonlinear magnonics and quantum systems. It also offers potential for generating squeezed magnon states, which can exponentially\n",
      "enhance the coupling strengths and cooperativities in hybrid quantum systems.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Magnon nonlinearities in quantum systems could\n",
      "potentially lead to exponentially enhanced coupling strengths and cooperativities, which could be useful for generating squeezed magnon states and\n",
      "improving the performance of hybrid quantum systems. Additionally, they could enable new types of quantum operations and functionalities beyond what\n",
      "is currently achievable with linear magnon transduction. For example, they could be used to create entangled states of multiple qubits, perform\n",
      "quantum error correction, and implement quantum algorithms. Overall, the integration of magnon nonlinearities into quantum systems could open up new\n",
      "avenues for exploring the fundamental principles of quantum mechanics and developing novel technologies for quantum communication and computation.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      " Recent research in quantum magnonics has\n",
      "shown that nonlinear magnonic systems can provide alternative perspectives for engineering quantum interfaces to spin qubits. These findings motivate\n",
      "further investigation into uncovering the interesting phenomena at the intersection of nonlinear magnonics and quantum systems. One example of this is\n",
      "the use of wafer-compatible materials to engineer a hybrid transducer that exploits magnon nonlinearities in a magnetic microdisk to address quantum\n",
      "spin defects in silicon carbide. This interaction scheme highlights the unique transduction behavior that can be obtained when combining quantum\n",
      "systems with nonlinear magnonics.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/Parametric magnon.pdf\n"
     ]
    }
   ],
   "source": [
    "# Parametric Magnon Questions\n",
    "\n",
    "questions_file_path = '/content/questions/ParametricMagnonQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnUQW8FOD_xi",
    "outputId": "e4c1f531-8f2a-4400-c830-948d554dced0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What materials are typically used to construct quantum transducers in hybrid quantum systems?\n",
      " response:  The materials commonly used to\n",
      "construct quantum transducers in hybrid quantum systems include yttrium iron garnet (YIG) and nitrogen-vacancy (NV) defects in diamond. However, these\n",
      "materials face fabrication challenges for wafer-scale integration. In this work, the authors present a different approach by using wafer-compatible\n",
      "materials to engineer a hybrid transducer that exploits magnon nonlinearities in a ferromagnetic microdisk to mediate the microwave interaction with\n",
      "spin qubits in silicon carbide.\n",
      "\n",
      "\n",
      "Q1: How do magnon nonlinearities enhance quantum transduction?\n",
      " response:  Magnon nonlinearities can enhance quantum transduction by allowing\n",
      "selective tuning of the spin-magnet coupling \"on\" and \"off.\" This control over the coupling enables protection of spin centers against resonant magnon\n",
      "noise-induced decoherence, leading to improved transduction behavior and tunability.\n",
      "\n",
      "\n",
      "Q2: What techniques are used to minimize the microwave footprint in quantum computing transducers?\n",
      " response:  Minimizing the microwave footprint in\n",
      "quantum computing transducers can be achieved through the use of highly-confined magnon stray fields to drive the spin qubits at room temperature.\n",
      "This indirect scheme reduces the microwave footprint compared to using antennas, which typically extend over hundreds of micrometers on the sample\n",
      "plane. Additionally, controlling the coupling between the spin centers and the magnons allows protection against resonant magnon noise-induced\n",
      "decoherence.\n",
      "\n",
      "\n",
      "Q3: Why is silicon carbide favored in some quantum computing applications?\n",
      " response:  Silicon carbide is favored in some quantum computing\n",
      "applications due to its unique properties, including high thermal conductivity, chemical stability, and mechanical strength. It also exhibits strong\n",
      "spin-orbit interactions, making it suitable for hosting color centers that can serve as qubits. Additionally, silicon carbide can be easily integrated\n",
      "with existing silicon technology, allowing for the development of scalable quantum devices.\n",
      "\n",
      "\n",
      "Q4: What experimental methods are crucial for validating the functionality of quantum transducers?\n",
      " response:  The validation of the functionality of\n",
      "quantum transducers requires various experimental methods such as characterization of the transducer efficiency, measurement of the signal fidelity,\n",
      "and assessment of the noise properties. Additionally, it is essential to test the compatibility of the transducer with different types of quantum\n",
      "systems and to evaluate its scalability.\n",
      "\n",
      "\n",
      "Q5: What is the importance of frequency tuning in quantum transducers using magnon interactions?\n",
      " response:  Frequency tuning is crucial in quantum\n",
      "transducers using magnon interactions because it enables selective control over the spin-magnon coupling \"on\" and \"off.\" This capability is essential\n",
      "for protecting spin qubits from resonant magnon noise-induced decoherence. By precisely controlling the implantation energies, defects can be created\n",
      "closer to the surface to achieve strong spin-magnon coupling while avoiding detrimental surface effects. This approach offers a new method for\n",
      "enhancing microwave transduction to spin qubits and could lead to improved performance in quantum communication and computation applications.\n",
      "\n",
      "\n",
      "Q6: What innovative approach does parametric magnonics introduce in quantum transducers?\n",
      " response:  Parametric magnonics introduces a new approach\n",
      "to quantum transducers by using wafer-compatible materials to engineer a hybrid transducer that exploits magnon nonlinearities in a magnetic microdisc\n",
      "to address quantum spin defects in silicon carbide. This interaction scheme points to the unique transduction behavior that can be obtained when\n",
      "complementing quantum systems with nonlinear magnonics.\n",
      "\n",
      "\n",
      "Q7: How does introducing nonlinear magnonics impact quantum computing systems?\n",
      " response:  Introducing nonlinear magnonics provides alternative\n",
      "perspectives for engineering quantum interfaces to spin qubits and motivates further research into uncovering the interesting phenomena lying at the\n",
      "intersection of nonlinear magnonics and quantum systems. It also offers potential for generating squeezed magnon states, which can exponentially\n",
      "enhance the coupling strengths and cooperativities in hybrid quantum systems.\n",
      "\n",
      "\n",
      "Q8: What future applications could benefit from magnon nonlinearities in quantum systems?\n",
      " response:  Magnon nonlinearities in quantum systems could\n",
      "potentially lead to exponentially enhanced coupling strengths and cooperativities, which could be useful for generating squeezed magnon states and\n",
      "improving the performance of hybrid quantum systems. Additionally, they could enable new types of quantum operations and functionalities beyond what\n",
      "is currently achievable with linear magnon transduction. For example, they could be used to create entangled states of multiple qubits, perform\n",
      "quantum error correction, and implement quantum algorithms. Overall, the integration of magnon nonlinearities into quantum systems could open up new\n",
      "avenues for exploring the fundamental principles of quantum mechanics and developing novel technologies for quantum communication and computation.\n",
      "\n",
      "\n",
      "Q9: How does recent research in quantum magnonics influence the design of quantum interfaces?\n",
      " response:  Recent research in quantum magnonics has\n",
      "shown that nonlinear magnonic systems can provide alternative perspectives for engineering quantum interfaces to spin qubits. These findings motivate\n",
      "further investigation into uncovering the interesting phenomena at the intersection of nonlinear magnonics and quantum systems. One example of this is\n",
      "the use of wafer-compatible materials to engineer a hybrid transducer that exploits magnon nonlinearities in a magnetic microdisk to address quantum\n",
      "spin defects in silicon carbide. This interaction scheme highlights the unique transduction behavior that can be obtained when combining quantum\n",
      "systems with nonlinear magnonics.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNKuB30JEBWi"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'ParametricMagnonQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ns4l3PKbEC_G"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'ParametricMagnonQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQD1a_eoEKsM"
   },
   "source": [
    "###Quantum Mechanics Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6z4CERedEPiX",
    "outputId": "36f0637a-e22a-4b01-8d50-6ef3f6fedcfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quantum mechanics has had a significant impact on modern\n",
      "technology, leading to the development of fields such as quantum information theory and quantum thermodynamics, as well as the improvement of existing\n",
      "technologies through the use of quantum principles. This has resulted in advancements in areas such as superfast quantum computers, unbreakable\n",
      "quantum cryptography, and ultrasensitive quantum sensors, among others. These innovations have the potential to revolutionize various industries and\n",
      "have already begun to rival the three major industrial revolutions of the last century. Additionally, research in quantum science continues to push\n",
      "the boundaries of our understanding of the physical world, with implications for fields ranging from condensed matter physics to cosmology.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quantum mechanics has had a significant influence on the development of new\n",
      "fields of study, such as quantum information theory and quantum thermodynamics. It has also led to the creation of novel mathematical and\n",
      "computational tools applicable to various areas, including condensed matter physics, statistical mechanics, and cosmology. Additionally, research in\n",
      "quantum science has achieved tangible impacts through the improvement of understanding of the resource power of quantum phenomena, triggering a\n",
      "technological overhaul that is comparable to the three major industrial revolutions of the last century. The potential applications of quantum science\n",
      "include superfast quantum computers, unbreakable quantum cryptography, and ultrasensitive quantum sensors, among others.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quantum science research has led to the creation\n",
      "of new fields of knowledge, such as quantum information theory and quantum thermodynamics, and the development of novel mathematical and computational\n",
      "tools applicable to other domains, including condensed matter physics, statistical mechanics, and cosmology. Additionally, quantum science research\n",
      "has achieved a very concrete impact through the improved understanding of the resource power of quantum phenomena, triggering a technological overhaul\n",
      "that is rivaling the three major industrial revolutions of the last century. This has resulted in exciting prospects for superfast quantum computers,\n",
      "unbreakable quantum cryptography, and ultrasensitive quantum sensors, among other innovations. These developments have captured the fascination of the\n",
      "general public and have motivated future generations to delve deeper into the quirky fabric of the quantum realm.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Advancements in quantum technologies have the\n",
      "potential to disrupt various aspects of society, including the development of superfast quantum computers, unbreakable quantum cryptography, and\n",
      "ultrasensitive quantum sensors. These innovations could lead to significant improvements in fields such as medicine, finance, and transportation,\n",
      "among others. Additionally, the increased understanding of quantum phenomena has led to the creation of new areas of research, such as quantum\n",
      "information theory and quantum thermodynamics, and the development of novel mathematical and computational tools applicable to other domains. Overall,\n",
      "the impact of quantum technology on society is expected to be transformative, rivaling the three major industrial revolutions of the last century.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quantum phenomena have led to the creation of new fields of\n",
      "knowledge, such as quantum information theory and quantum thermodynamics, and the development of novel mathematical and computational tools applicable\n",
      "to various domains, including condensed matter physics, statistical mechanics, and cosmology. These advancements have resulted in significant\n",
      "technological breakthroughs, including superfast quantum computers, unbreakable quantum cryptography, and ultrasensitive quantum sensors. These\n",
      "technologies have captured the fascination of the general public and are expected to have a profound impact on society in the near future.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Technology giants such as Google, IBM, and Microsoft\n",
      "are actively involved in the development of quantum technologies, aiming to bring them to market in the near future. Their involvement has contributed\n",
      "significantly to the progress made in understanding quantum mechanics and its potential applications.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/Parametric magnon.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are several fundamental questions about quantum\n",
      "mechanics that remain open, such as the interpretation of its elusive foundations, the relationship between quantum mechanics and general relativity,\n",
      "and the emergence of the classical world via quantum principles. Additionally, there are ongoing efforts to explore the interplay of quantum mechanics\n",
      "with other areas of physics, such as black hole physics and thermodynamics, and to develop disruptive technologies based on quantum principles.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exploring quantum mechanics contributes to theoretical\n",
      "physics by shedding light on the physical meaning of fundamental quantum principles and pushing the boundaries of the quantum description of the\n",
      "world. This effort has led to significant advancements in understanding the interplay of quantum mechanics with other areas such as black hole\n",
      "physics, thermodynamics, and the emergence of the classical world. Additionally, it has resulted in the development of innovative technologies like\n",
      "topological quantum computing and prospects of a quantum internet.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Decades of progress in the experimental verification and\n",
      "control of quantum systems have routinely proven detractors wrong. There is little doubt that quantum mechanics is a valid description of the physical\n",
      "reality.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      " Future developments in quantum technology include superfast quantum\n",
      "computers, unbreakable quantum cryptography, ultrasensitive quantum sensors, topological quantum computing, and prospects of a quantum internet. These\n",
      "advancements have the potential to disrupt various industries and revolutionize our understanding of the physical world.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n",
      "/content/papers/quantum.pdf\n"
     ]
    }
   ],
   "source": [
    "# Quantum Mechanics Questions\n",
    "\n",
    "questions_file_path = '/content/questions/QuantumMechanicsQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbmQY-poEX05",
    "outputId": "7925ad20-05ed-4b51-aa28-6d5c3bcc207f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What is the significance of quantum mechanics in modern technology?\n",
      " response:  Quantum mechanics has had a significant impact on modern\n",
      "technology, leading to the development of fields such as quantum information theory and quantum thermodynamics, as well as the improvement of existing\n",
      "technologies through the use of quantum principles. This has resulted in advancements in areas such as superfast quantum computers, unbreakable\n",
      "quantum cryptography, and ultrasensitive quantum sensors, among others. These innovations have the potential to revolutionize various industries and\n",
      "have already begun to rival the three major industrial revolutions of the last century. Additionally, research in quantum science continues to push\n",
      "the boundaries of our understanding of the physical world, with implications for fields ranging from condensed matter physics to cosmology.\n",
      "\n",
      "\n",
      "Q1: How has quantum mechanics influenced new fields of study?\n",
      " response:  Quantum mechanics has had a significant influence on the development of new\n",
      "fields of study, such as quantum information theory and quantum thermodynamics. It has also led to the creation of novel mathematical and\n",
      "computational tools applicable to various areas, including condensed matter physics, statistical mechanics, and cosmology. Additionally, research in\n",
      "quantum science has achieved tangible impacts through the improvement of understanding of the resource power of quantum phenomena, triggering a\n",
      "technological overhaul that is comparable to the three major industrial revolutions of the last century. The potential applications of quantum science\n",
      "include superfast quantum computers, unbreakable quantum cryptography, and ultrasensitive quantum sensors, among others.\n",
      "\n",
      "\n",
      "Q2: What advancements have quantum science research brought to other scientific domains?\n",
      " response:  Quantum science research has led to the creation\n",
      "of new fields of knowledge, such as quantum information theory and quantum thermodynamics, and the development of novel mathematical and computational\n",
      "tools applicable to other domains, including condensed matter physics, statistical mechanics, and cosmology. Additionally, quantum science research\n",
      "has achieved a very concrete impact through the improved understanding of the resource power of quantum phenomena, triggering a technological overhaul\n",
      "that is rivaling the three major industrial revolutions of the last century. This has resulted in exciting prospects for superfast quantum computers,\n",
      "unbreakable quantum cryptography, and ultrasensitive quantum sensors, among other innovations. These developments have captured the fascination of the\n",
      "general public and have motivated future generations to delve deeper into the quirky fabric of the quantum realm.\n",
      "\n",
      "\n",
      "Q3: What are the potential societal impacts of advancements in quantum technologies?\n",
      " response:  Advancements in quantum technologies have the\n",
      "potential to disrupt various aspects of society, including the development of superfast quantum computers, unbreakable quantum cryptography, and\n",
      "ultrasensitive quantum sensors. These innovations could lead to significant improvements in fields such as medicine, finance, and transportation,\n",
      "among others. Additionally, the increased understanding of quantum phenomena has led to the creation of new areas of research, such as quantum\n",
      "information theory and quantum thermodynamics, and the development of novel mathematical and computational tools applicable to other domains. Overall,\n",
      "the impact of quantum technology on society is expected to be transformative, rivaling the three major industrial revolutions of the last century.\n",
      "\n",
      "\n",
      "Q4: How do quantum phenomena underpin emerging technological innovations?\n",
      " response:  Quantum phenomena have led to the creation of new fields of\n",
      "knowledge, such as quantum information theory and quantum thermodynamics, and the development of novel mathematical and computational tools applicable\n",
      "to various domains, including condensed matter physics, statistical mechanics, and cosmology. These advancements have resulted in significant\n",
      "technological breakthroughs, including superfast quantum computers, unbreakable quantum cryptography, and ultrasensitive quantum sensors. These\n",
      "technologies have captured the fascination of the general public and are expected to have a profound impact on society in the near future.\n",
      "\n",
      "\n",
      "Q5: What role do technology giants play in the advancement of quantum technologies?\n",
      " response:  Technology giants such as Google, IBM, and Microsoft\n",
      "are actively involved in the development of quantum technologies, aiming to bring them to market in the near future. Their involvement has contributed\n",
      "significantly to the progress made in understanding quantum mechanics and its potential applications.\n",
      "\n",
      "\n",
      "Q6: What are the fundamental questions about quantum mechanics that remain open?\n",
      " response:  There are several fundamental questions about quantum\n",
      "mechanics that remain open, such as the interpretation of its elusive foundations, the relationship between quantum mechanics and general relativity,\n",
      "and the emergence of the classical world via quantum principles. Additionally, there are ongoing efforts to explore the interplay of quantum mechanics\n",
      "with other areas of physics, such as black hole physics and thermodynamics, and to develop disruptive technologies based on quantum principles.\n",
      "\n",
      "\n",
      "Q7: How does exploring quantum mechanics contribute to theoretical physics?\n",
      " response:  Exploring quantum mechanics contributes to theoretical\n",
      "physics by shedding light on the physical meaning of fundamental quantum principles and pushing the boundaries of the quantum description of the\n",
      "world. This effort has led to significant advancements in understanding the interplay of quantum mechanics with other areas such as black hole\n",
      "physics, thermodynamics, and the emergence of the classical world. Additionally, it has resulted in the development of innovative technologies like\n",
      "topological quantum computing and prospects of a quantum internet.\n",
      "\n",
      "\n",
      "Q8: What experimental advances have been made in verifying quantum theory?\n",
      " response:  Decades of progress in the experimental verification and\n",
      "control of quantum systems have routinely proven detractors wrong. There is little doubt that quantum mechanics is a valid description of the physical\n",
      "reality.\n",
      "\n",
      "\n",
      "Q9: What future developments are anticipated in quantum technology?\n",
      " response:  Future developments in quantum technology include superfast quantum\n",
      "computers, unbreakable quantum cryptography, ultrasensitive quantum sensors, topological quantum computing, and prospects of a quantum internet. These\n",
      "advancements have the potential to disrupt various industries and revolutionize our understanding of the physical world.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyXwnHL1EZKl"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'QuantumMechanicsQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwcTgfULEcY4"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'Quantum MechanicsQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyyA_gUfEiDt"
   },
   "source": [
    "###Qubit Teleportation Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8y3tvjmEEmmW",
    "outputId": "ba80db12-cd6f-4007-e9c0-907de35d4b1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main components used in quantum networks for\n",
      "teleportation include solid-state spin qubits, entanglement swapping on the middle node, and storage in a memory qubit. Additionally, there are\n",
      "innovations such as improved qubit readout procedures, active memory qubit protection during entanglement generation, and tailored heralding to reduce\n",
      "remote entanglement infidelities.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entanglement is established between distant nodes in a\n",
      "quantum network through an entanglement swapping protocol mediated by a third node, such as a quantum repeater protocol. This process creates a shared\n",
      "entangled state between the distant nodes, allowing for reliable quantum information transfer.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Bell-state measurement (BSM) plays a crucial role\n",
      "in quantum teleportation. It allows for the transfer of quantum information from one node to another through a pre-shared entangled state. By\n",
      "performing a joint BSM on the sender's part of the entangled state and the qubit state to be teleported, the state is recovered on the receiving node\n",
      "by a gate operation conditioned on the BSM outcome. This process is insensitive to loss in the connecting photonic channels and on intermediate nodes,\n",
      "making it ideal for reliable quantum communication across long distances.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quantum\n",
      "teleportation is considered advantageous over traditional communication methods in quantum networks because it allows for the reliable transfer of\n",
      "quantum information across lossy network links without being affected by loss in the connecting photonic channels and on intermediate nodes. This\n",
      "makes it insensitive to loss and enables unconditional teleportation, where state transfer is achieved each time a qubit is sent through the network.\n",
      "Additionally, quantum teleportation is a key primitive of quantum network protocols and applications.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Innovations introduced in this work include\n",
      "improvements in memory qubit readout and protection during entanglement generation, as well as real-time rejection of false heralding signals. These\n",
      "methods will be instrumental in exploring more complex protocols and can be readily transferred to other platforms. Additionally, the successful\n",
      "preparation of the teleporter is heralded, the input qubit state is prepared on Charlie and finally teleported to Alice. Entanglement fidelity of the\n",
      "network links is also crucial for quantum teleportation.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main challenges associated\n",
      "with extending quantum teleportation beyond directly connected nodes include the demanding requirements on the pre-shared remote entanglement, joint\n",
      "qubit readout, and coherence times. These issues have hindered progress in realizing quantum teleportation between non-neighboring nodes. However,\n",
      "recent advances in memory qubit readout and protection during entanglement generation, as well as real-time rejection of false heralding signals, have\n",
      "made it possible to achieve unconditional qubit teleportation between non-neighboring nodes in a quantum network. This work represents a significant\n",
      "step forward in the development of future quantum networks and opens the door to exploring teleportation-based multi-node protocols and applications.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Memory qubits play a crucial role in the\n",
      "process of quantum teleportation in a network. They serve as a reliable medium for storing the entangled state generated during the teleportation\n",
      "protocol. This allows for the efficient transfer of quantum information between distant nodes without the need for direct physical contact.\n",
      "Additionally, memory qubits enable the extension of the memory preservation time through active coherence protection from the spin bath. Overall,\n",
      "memory qubits are essential components of a quantum network, enabling the implementation of advanced teleportation protocols and paving the way for\n",
      "future quantum technologies.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Potential future applications of quantum\n",
      "teleportation in quantum networks include executing and testing multi-node protocols and applications through platform-independent control software,\n",
      "which is an important prerequisite for a large-scale future network. Additionally, improvements in phase stabilization and extending current schemes\n",
      "for use in deployed fiber are expected to yield higher fidelity in teleportation.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Real-time feed-forward plays a crucial role in achieving\n",
      "unconditional quantum teleportation by enabling state transfer each time a qubit state is inserted into the teleporter. The presence of feed-forward\n",
      "operations significantly improves the average state fidelity compared to the case where no feed-forward is applied. However, it also introduces\n",
      "additional error sources such as depolarizing noise on Alice during the decoupling sequence and ionization probability on Alice. These error sources\n",
      "must be carefully considered and mitigated to ensure successful teleportation.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      " To achieve\n",
      "efficient quantum teleportation between non-neighbouring nodes, several technical advancements are required. These include improvements in the\n",
      "fidelity of entanglement generation, the development of robust qubit readout procedures, and the implementation of active memory qubit protection\n",
      "during entanglement generation. Additionally, tailored heralding schemes can reduce remote entanglement infidelities and enable unconditional\n",
      "teleportation. These innovations will be crucial for exploring more complex protocols and applications in future quantum networks.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n",
      "/content/papers/Qubit teleportation.pdf\n"
     ]
    }
   ],
   "source": [
    "# Qubit Teleportation Questions\n",
    "\n",
    "questions_file_path = '/content/questions/QubitTeleportationQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KK06Y1woEm62",
    "outputId": "1b952c03-8e06-48e3-b45e-f78afc33624a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What are the main components used in quantum networks for teleportation?\n",
      " response:  The main components used in quantum networks for\n",
      "teleportation include solid-state spin qubits, entanglement swapping on the middle node, and storage in a memory qubit. Additionally, there are\n",
      "innovations such as improved qubit readout procedures, active memory qubit protection during entanglement generation, and tailored heralding to reduce\n",
      "remote entanglement infidelities.\n",
      "\n",
      "\n",
      "Q1: How is entanglement established between distant nodes in a quantum network?\n",
      " response:  Entanglement is established between distant nodes in a\n",
      "quantum network through an entanglement swapping protocol mediated by a third node, such as a quantum repeater protocol. This process creates a shared\n",
      "entangled state between the distant nodes, allowing for reliable quantum information transfer.\n",
      "\n",
      "\n",
      "Q2: What role does the Bell-state measurement (BSM) play in quantum teleportation?\n",
      " response:  The Bell-state measurement (BSM) plays a crucial role\n",
      "in quantum teleportation. It allows for the transfer of quantum information from one node to another through a pre-shared entangled state. By\n",
      "performing a joint BSM on the sender's part of the entangled state and the qubit state to be teleported, the state is recovered on the receiving node\n",
      "by a gate operation conditioned on the BSM outcome. This process is insensitive to loss in the connecting photonic channels and on intermediate nodes,\n",
      "making it ideal for reliable quantum communication across long distances.\n",
      "\n",
      "\n",
      "Q3: Why is quantum teleportation considered advantageous over traditional communication methods in quantum networks?\n",
      " response:  Quantum\n",
      "teleportation is considered advantageous over traditional communication methods in quantum networks because it allows for the reliable transfer of\n",
      "quantum information across lossy network links without being affected by loss in the connecting photonic channels and on intermediate nodes. This\n",
      "makes it insensitive to loss and enables unconditional teleportation, where state transfer is achieved each time a qubit is sent through the network.\n",
      "Additionally, quantum teleportation is a key primitive of quantum network protocols and applications.\n",
      "\n",
      "\n",
      "Q4: What innovations have improved the fidelity and reliability of quantum teleportation?\n",
      " response:  Innovations introduced in this work include\n",
      "improvements in memory qubit readout and protection during entanglement generation, as well as real-time rejection of false heralding signals. These\n",
      "methods will be instrumental in exploring more complex protocols and can be readily transferred to other platforms. Additionally, the successful\n",
      "preparation of the teleporter is heralded, the input qubit state is prepared on Charlie and finally teleported to Alice. Entanglement fidelity of the\n",
      "network links is also crucial for quantum teleportation.\n",
      "\n",
      "\n",
      "Q5: What challenges are associated with extending quantum teleportation beyond directly connected nodes?\n",
      " response:  The main challenges associated\n",
      "with extending quantum teleportation beyond directly connected nodes include the demanding requirements on the pre-shared remote entanglement, joint\n",
      "qubit readout, and coherence times. These issues have hindered progress in realizing quantum teleportation between non-neighboring nodes. However,\n",
      "recent advances in memory qubit readout and protection during entanglement generation, as well as real-time rejection of false heralding signals, have\n",
      "made it possible to achieve unconditional qubit teleportation between non-neighboring nodes in a quantum network. This work represents a significant\n",
      "step forward in the development of future quantum networks and opens the door to exploring teleportation-based multi-node protocols and applications.\n",
      "\n",
      "\n",
      "Q6: How do memory qubits contribute to the process of quantum teleportation in a network?\n",
      " response:  Memory qubits play a crucial role in the\n",
      "process of quantum teleportation in a network. They serve as a reliable medium for storing the entangled state generated during the teleportation\n",
      "protocol. This allows for the efficient transfer of quantum information between distant nodes without the need for direct physical contact.\n",
      "Additionally, memory qubits enable the extension of the memory preservation time through active coherence protection from the spin bath. Overall,\n",
      "memory qubits are essential components of a quantum network, enabling the implementation of advanced teleportation protocols and paving the way for\n",
      "future quantum technologies.\n",
      "\n",
      "\n",
      "Q7: What are potential future applications of quantum teleportation in quantum networks?\n",
      " response:  Potential future applications of quantum\n",
      "teleportation in quantum networks include executing and testing multi-node protocols and applications through platform-independent control software,\n",
      "which is an important prerequisite for a large-scale future network. Additionally, improvements in phase stabilization and extending current schemes\n",
      "for use in deployed fiber are expected to yield higher fidelity in teleportation.\n",
      "\n",
      "\n",
      "Q8: How does real-time feed-forward impact the process of quantum teleportation?\n",
      " response:  Real-time feed-forward plays a crucial role in achieving\n",
      "unconditional quantum teleportation by enabling state transfer each time a qubit state is inserted into the teleporter. The presence of feed-forward\n",
      "operations significantly improves the average state fidelity compared to the case where no feed-forward is applied. However, it also introduces\n",
      "additional error sources such as depolarizing noise on Alice during the decoupling sequence and ionization probability on Alice. These error sources\n",
      "must be carefully considered and mitigated to ensure successful teleportation.\n",
      "\n",
      "\n",
      "Q9: What technical advancements are needed to realize efficient quantum teleportation between non-neighbouring nodes?\n",
      " response:  To achieve\n",
      "efficient quantum teleportation between non-neighbouring nodes, several technical advancements are required. These include improvements in the\n",
      "fidelity of entanglement generation, the development of robust qubit readout procedures, and the implementation of active memory qubit protection\n",
      "during entanglement generation. Additionally, tailored heralding schemes can reduce remote entanglement infidelities and enable unconditional\n",
      "teleportation. These innovations will be crucial for exploring more complex protocols and applications in future quantum networks.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKJiJ4xMEnKG"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'QubitTeleportationQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ljd8D_p-EnYa"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'QubitTeleportationQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gGG_6CtE3H9"
   },
   "source": [
    "###Variance Based Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiO0mcg-E3ly",
    "outputId": "a77a7beb-a9c2-4d76-95c9-c804acc29efb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The focus of variance-based sensitivity analysis in\n",
      "quantum memory is to identify which input parameters are most sensitive globally and probe for correlations between parameters that can be leveraged\n",
      "to maintain acceptable system performance at nonoptimal parameter values. It provides a complete picture of the system performance landscape around a\n",
      "central point of input parameters.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Λ-type quantum memory refers to a type of quantum memory that uses a Λ-shaped energy level\n",
      "scheme to store and retrieve qubits. It is often used in optical systems due to its high efficiency and long coherence time.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Control field parameters are crucial in Λ-type quantum\n",
      "memory systems because they determine the efficiency of the memory process. Fluctuations and drift in control field parameters can significantly\n",
      "affect the memory efficiency, making it important to understand their impact on the system. By analyzing the sensitivity of the system to fluctuations\n",
      "and drift in control field parameters, researchers can identify the most sensitive regions of the parameter space and optimize the design of the\n",
      "memory system.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shot-to-shot fluctuations in experimental parameters can affect\n",
      "the performance of a quantum memory. In the ideal case, a quantum memory is capable of storing and retrieving single-photon quantum states with high\n",
      "efficiency, fidelity, long storage time, and broad bandwidth. However, experimental imperfections such as shot-to-shot fluctuations in memory\n",
      "parameters can reduce the overall performance of the memory. By analyzing the sensitivity of a /Lambda1-type quantum memory to these fluctuations, it\n",
      "was found that the memory efﬁciency is roughly linearly dependent on the magnitude of the memory parameter fluctuations, with different\n",
      "proportionality constants for different memory protocols. This indicates that some protocols are more stable than others when it comes to handling\n",
      "shot-to-shot fluctuations.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The optical control field plays a crucial role in the memory\n",
      "interaction by defining the shape and duration of the control pulse, which determines the efficiency of the memory process. In this study, we perform\n",
      "a sensitivity analysis to determine how changes in the control field parameters affect the memory efficiency. Our results reveal that the falling edge\n",
      "of the typical EIT-like control field shape is most sensitive to drift or improper setting, while other parameters such as pulse area, delay, and\n",
      "duration are less sensitive. This information can be used to develop physical intuition about the behavior of the memory system and guide optimization\n",
      "efforts.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Longer timescale drifts in control field parameters can significantly impact\n",
      "the performance of a quantum memory. In the study discussed in the article, it was found that the sensitivity of the memory to drift depends on the\n",
      "specific quantum memory protocol being used. For instance, the absorb-then-transfer protocol was found to be less stable compared to the EIT and ATS\n",
      "protocols. To mitigate the effects of drift, it is essential to monitor and adjust the control fields accordingly. Additionally, the study presented a\n",
      "general framework for analyzing the sensitivity of quantum memory to various figures of merit beyond efficiency.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Memory sensitivity analysis is important because it allows for\n",
      "identification of which input parameters are most sensitive to fluctuations, enabling optimization of system performance and compensation for\n",
      "nonoptimal parameter values. It also probes for correlations between parameters, which can be leveraged to achieve acceptable performance even if some\n",
      "parameters are not optimized. In the context of quantum memory, sensitivity analysis can be applied to various performance metrics such as efficiency,\n",
      "fidelity, storage time, etc., allowing for a comprehensive understanding of the system's behavior under different conditions.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The experimental techniques used to analyze memory sensitivity\n",
      "include variance-based sensitivity analysis, optimization-based analysis, and Monte Carlo simulations. These methods allow for the determination of\n",
      "how sensitive a quantum memory is to fluctuations in memory parameters and experimental drift. The results of these analyses can provide valuable\n",
      "insights into the robustness and reliability of different memory protocols.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:485: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:490: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=512) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Gaussian control field relates to memory performance through\n",
      "its optimization for maximum efficiency in storing and retrieving information from the memory. The control field parameters, such as pulse area,\n",
      "delay, and duration, define the temporal envelope of the control field and are assumed to have been optimized for maximum memory efficiency. These\n",
      "parameters are grouped into intrinsic and extrinsic categories, with the latter being more readily tunable. The analysis is also partitioned based on\n",
      "whether the control field defines a Gaussian temporal envelope or not. The sensitivity of the memory to variations in these control field parameters\n",
      "is calculated using one-at-a-time analysis and single-parameter sensitivity calculations, revealing the impact of each parameter on the overall memory\n",
      "efficiency. Additionally, the overlap fidelity between the optimal control fields at neighboring points in memory space is studied, confirming the\n",
      "intuition that the region of least overlap corresponds to the absorb-then-transfer protocol, which is most sensitive to fluctuations in the memory\n",
      "parameters.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      " The findings on quantum memory sensitivity have\n",
      "practical ramifications for quantum memory experiments. By identifying the parameters that a quantum memory is most sensitive to, researchers can\n",
      "design and optimize their experiments to minimize sensitivity to those parameters, resulting in improved overall performance. Additionally,\n",
      "understanding the sensitivity of different quantum memory protocols can inform the choice of protocol for specific applications.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n",
      "/content/papers/Variance-based.pdf\n"
     ]
    }
   ],
   "source": [
    "# Variance Based Questions\n",
    "\n",
    "questions_file_path = '/content/questions/VarianceQuestions.csv'\n",
    "Q_dictionary = create_question_dict(questions_file_path)\n",
    "# for q in Q_dictionary:\n",
    "#   print(q)\n",
    "# QA_dictionary = generate_qa_dict(Q_dictionary)\n",
    "\n",
    "for k in Q_dictionary.keys():\n",
    "  # print(str(k))\n",
    "  query = str(k)\n",
    "  response = qa_chain(query)\n",
    "  final_res = process_generated_response(response)\n",
    "  Q_dictionary.update({k : final_res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czXJQDQGE313",
    "outputId": "0c60c5ce-cb5c-4dca-e27a-2bca77c42522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: What is the focus of variance-based sensitivity analysis in quantum memory?\n",
      " response:  The focus of variance-based sensitivity analysis in\n",
      "quantum memory is to identify which input parameters are most sensitive globally and probe for correlations between parameters that can be leveraged\n",
      "to maintain acceptable system performance at nonoptimal parameter values. It provides a complete picture of the system performance landscape around a\n",
      "central point of input parameters.\n",
      "\n",
      "\n",
      "Q1: What does Λ-type quantum memory refer to?\n",
      " response:  Λ-type quantum memory refers to a type of quantum memory that uses a Λ-shaped energy level\n",
      "scheme to store and retrieve qubits. It is often used in optical systems due to its high efficiency and long coherence time.\n",
      "\n",
      "\n",
      "Q2: Why are control field parameters crucial in Λ-type quantum memory systems?\n",
      " response:  Control field parameters are crucial in Λ-type quantum\n",
      "memory systems because they determine the efficiency of the memory process. Fluctuations and drift in control field parameters can significantly\n",
      "affect the memory efficiency, making it important to understand their impact on the system. By analyzing the sensitivity of the system to fluctuations\n",
      "and drift in control field parameters, researchers can identify the most sensitive regions of the parameter space and optimize the design of the\n",
      "memory system.\n",
      "\n",
      "\n",
      "Q3: How does shot-to-shot fluctuation impact quantum memory performance?\n",
      " response:  Shot-to-shot fluctuations in experimental parameters can affect\n",
      "the performance of a quantum memory. In the ideal case, a quantum memory is capable of storing and retrieving single-photon quantum states with high\n",
      "efficiency, fidelity, long storage time, and broad bandwidth. However, experimental imperfections such as shot-to-shot fluctuations in memory\n",
      "parameters can reduce the overall performance of the memory. By analyzing the sensitivity of a /Lambda1-type quantum memory to these fluctuations, it\n",
      "was found that the memory efﬁciency is roughly linearly dependent on the magnitude of the memory parameter fluctuations, with different\n",
      "proportionality constants for different memory protocols. This indicates that some protocols are more stable than others when it comes to handling\n",
      "shot-to-shot fluctuations.\n",
      "\n",
      "\n",
      "Q4: What role does the optical control field play in the memory interaction?\n",
      " response:  The optical control field plays a crucial role in the memory\n",
      "interaction by defining the shape and duration of the control pulse, which determines the efficiency of the memory process. In this study, we perform\n",
      "a sensitivity analysis to determine how changes in the control field parameters affect the memory efficiency. Our results reveal that the falling edge\n",
      "of the typical EIT-like control field shape is most sensitive to drift or improper setting, while other parameters such as pulse area, delay, and\n",
      "duration are less sensitive. This information can be used to develop physical intuition about the behavior of the memory system and guide optimization\n",
      "efforts.\n",
      "\n",
      "\n",
      "Q5: How do longer timescale drifts affect quantum memory?\n",
      " response:  Longer timescale drifts in control field parameters can significantly impact\n",
      "the performance of a quantum memory. In the study discussed in the article, it was found that the sensitivity of the memory to drift depends on the\n",
      "specific quantum memory protocol being used. For instance, the absorb-then-transfer protocol was found to be less stable compared to the EIT and ATS\n",
      "protocols. To mitigate the effects of drift, it is essential to monitor and adjust the control fields accordingly. Additionally, the study presented a\n",
      "general framework for analyzing the sensitivity of quantum memory to various figures of merit beyond efficiency.\n",
      "\n",
      "\n",
      "Q6: What is the significance of memory sensitivity analysis?\n",
      " response:  Memory sensitivity analysis is important because it allows for\n",
      "identification of which input parameters are most sensitive to fluctuations, enabling optimization of system performance and compensation for\n",
      "nonoptimal parameter values. It also probes for correlations between parameters, which can be leveraged to achieve acceptable performance even if some\n",
      "parameters are not optimized. In the context of quantum memory, sensitivity analysis can be applied to various performance metrics such as efficiency,\n",
      "fidelity, storage time, etc., allowing for a comprehensive understanding of the system's behavior under different conditions.\n",
      "\n",
      "\n",
      "Q7: What experimental techniques are used to analyze memory sensitivity?\n",
      " response:  The experimental techniques used to analyze memory sensitivity\n",
      "include variance-based sensitivity analysis, optimization-based analysis, and Monte Carlo simulations. These methods allow for the determination of\n",
      "how sensitive a quantum memory is to fluctuations in memory parameters and experimental drift. The results of these analyses can provide valuable\n",
      "insights into the robustness and reliability of different memory protocols.\n",
      "\n",
      "\n",
      "Q8: How does the Gaussian control field relate to memory performance?\n",
      " response:  The Gaussian control field relates to memory performance through\n",
      "its optimization for maximum efficiency in storing and retrieving information from the memory. The control field parameters, such as pulse area,\n",
      "delay, and duration, define the temporal envelope of the control field and are assumed to have been optimized for maximum memory efficiency. These\n",
      "parameters are grouped into intrinsic and extrinsic categories, with the latter being more readily tunable. The analysis is also partitioned based on\n",
      "whether the control field defines a Gaussian temporal envelope or not. The sensitivity of the memory to variations in these control field parameters\n",
      "is calculated using one-at-a-time analysis and single-parameter sensitivity calculations, revealing the impact of each parameter on the overall memory\n",
      "efficiency. Additionally, the overlap fidelity between the optimal control fields at neighboring points in memory space is studied, confirming the\n",
      "intuition that the region of least overlap corresponds to the absorb-then-transfer protocol, which is most sensitive to fluctuations in the memory\n",
      "parameters.\n",
      "\n",
      "\n",
      "Q9: What practical ramifications do the findings on quantum memory sensitivity have?\n",
      " response:  The findings on quantum memory sensitivity have\n",
      "practical ramifications for quantum memory experiments. By identifying the parameters that a quantum memory is most sensitive to, researchers can\n",
      "design and optimize their experiments to minimize sensitivity to those parameters, resulting in improved overall performance. Additionally,\n",
      "understanding the sensitivity of different quantum memory protocols can inform the choice of protocol for specific applications.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (qstn, resp) in enumerate(Q_dictionary.items()):\n",
    "  print(f\"Q{index}: {qstn}\\n response: {resp}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWVjvnyoE4Np"
   },
   "outputs": [],
   "source": [
    "json_file_name = 'VarianceQA.json'\n",
    "df_json = pd.DataFrame([Q_dictionary])\n",
    "df_json.to_json(json_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGuOvCPHE4hy"
   },
   "outputs": [],
   "source": [
    "csv_file_name = 'VarianceQA.csv'\n",
    "df_csv = pd.DataFrame([Q_dictionary])\n",
    "df_csv.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNWPoFZa_grw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "004bef965189494a992c222b71ce3a5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "014dae3f0fb74991b8706aad71b13afe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03319426e6ec4474a61a44f84f390540": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "039baa19dd5e4d37bd55e7834cdfa918": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a711bc60ebba4b0c8ceb0ef9effb276b",
      "placeholder": "​",
      "style": "IPY_MODEL_8df884e1221d46c9b8f1ed01f40fdf81",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "041981bb563242aa8961ffb74be9409f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "046f65796b9e4c18b9da763511347584": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0590c421aa0c4e4d9c5e761d1ef8944c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60a3af184bba403ab6e4174a293bcad4",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a1bb836c724b4d328445408a10220eaa",
      "value": 3
     }
    },
    "063f69f761ee412fb562f2bb55a97221": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06570834c303415087c2597b9cde8a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "070f1627c1cc44d9822055eabac2b0fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "08a37e13d7424af697d78201fdf35a31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09084a8710d147e6afd384276434ba45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "098799cafe6946868f16b9efea24a4be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c8cf38fc40f4226b13ec131449bbd58",
      "max": 366,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ff878f65c6d4d3abb965f8a72fb18c0",
      "value": 366
     }
    },
    "09d1b002445e4a21bcb4a2d3a7469933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92d8eb851c174cb3b51fdef1ef0e129e",
       "IPY_MODEL_5b995196921b46dea0248381f0ac15c0",
       "IPY_MODEL_ae851e234d7347f1b75e1964e7eb309f"
      ],
      "layout": "IPY_MODEL_2ba0de64ed58493690476cc74ce592d6"
     }
    },
    "0a6e0b7cb2f343ee91def6c6f4590f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_11170b3e116347418b3cf93acf160529",
       "IPY_MODEL_69a59700064c4fabacdd84ccb0265277",
       "IPY_MODEL_1eda6ace83904774b5bfc971b004df7f"
      ],
      "layout": "IPY_MODEL_fdc6995a9ad64176aeafeb046a0bbb6a"
     }
    },
    "0b7077483d7743968ebb3cf287dd1129": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bfbc0e31eb94591b07232be8e8602d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dc80d0201a04d4a8b466c1fee29761c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e49a066641548f1a0d2fbea79c6c7bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35614e6e6658459cb05b5049cd4d7ea4",
      "max": 4540516256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b872e76aac648378de282d75bb7d2bf",
      "value": 4540516256
     }
    },
    "0fb584e76cd24fc892435c28f5554bce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1006500f61b8441ead6477cc222bd7a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11170b3e116347418b3cf93acf160529": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2105deaf4e8341e3b00e8577556a758f",
      "placeholder": "​",
      "style": "IPY_MODEL_1eec9317c9e4497dbb92261f3b45b4db",
      "value": "model-00002-of-00003.safetensors: 100%"
     }
    },
    "126d60d1337a4eb09ebe0af747f08b53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "12f4cd0562a54fe49a6c823f12e681fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a68dde57c4d045d08214e7bd0b935d02",
      "max": 94551,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_172e2c35d8794a539f0a1173a69ec3e5",
      "value": 94551
     }
    },
    "13424936322a47d59ec97e2b5494188e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13ac6b0b2098474ba90169504ec6742d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "140848504fdf478ea03a400a72dd4633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14d2f5b768bc4743ba511cde06022849": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14d525461453413c85be19b96734155d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "154b644041ae4347ba8fd4b9fd957e4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15c03d5abd634162b5b3ffa8b4a9eb13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1637358258d74d78a5d941e9b37e1bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b289f501cf76467f86416e9a1ba8e053",
      "max": 4943162240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4058b8f2614342fb973d5cb1735524a0",
      "value": 4943162240
     }
    },
    "16727536d4f34228abf9ac34e921bf37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_54b6218ec29a497f8901447435316b17",
      "style": "IPY_MODEL_4a4961aa392f498394da79cbcfbbcd2e",
      "tooltip": ""
     }
    },
    "16f06250af4c400d9c317cbf15b1c8a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "172e2c35d8794a539f0a1173a69ec3e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "17e8bbe1431745ecbe2a0026297ced19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "185bc2a093ed44b986c8088f4253fdc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57b0bc61c7d0493ba02f8dd1ec704a98",
      "placeholder": "​",
      "style": "IPY_MODEL_32d830682a0a4483aaf28f3497e5f396",
      "value": " 493k/493k [00:00&lt;00:00, 10.3MB/s]"
     }
    },
    "195e04205d3d443f80eba648453734cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1dbb36b434104e4d8723583936eae6a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7332efac67864f8ab1c49a62b8eb64a9",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1466f2ca611478bbbfeca334b4fe60f",
      "value": 125
     }
    },
    "1e0c27089c734f68808fc64c3db5b571": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1eda6ace83904774b5bfc971b004df7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b20f5567d6984df595f903c0b7948493",
      "placeholder": "​",
      "style": "IPY_MODEL_195e04205d3d443f80eba648453734cf",
      "value": " 5.00G/5.00G [00:51&lt;00:00, 75.1MB/s]"
     }
    },
    "1eec9317c9e4497dbb92261f3b45b4db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fabc05d3bba4649bd3309befcf1848e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbb2f6a4deaf4daa8379c3c6c3d3bace",
      "placeholder": "​",
      "style": "IPY_MODEL_41b248654ced483d93fea011e68a7026",
      "value": " 3/3 [00:59&lt;00:00, 19.74s/it]"
     }
    },
    "1ff878f65c6d4d3abb965f8a72fb18c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2012f7f9148d4c698bc91c56315fb034": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2105deaf4e8341e3b00e8577556a758f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23d3e15868fa49dbb9ec0572f8d874fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "246fe7b73a4c4077990270cea535631b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "256aaf64205b4dd49d599e3837374868": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "260ae267b3844c0482a042ae5df4229e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27154fa201d34accbd659296fbc399fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27dce5ad5a9d41d7922066aaaf62b111": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_770bd5e827264200b502db89df5b3876",
      "placeholder": "​",
      "style": "IPY_MODEL_c15d09de6503496d82d7a039030e7be8",
      "value": " 94.6k/94.6k [00:00&lt;00:00, 1.43MB/s]"
     }
    },
    "2a4ed4d92a2d45afaa85ca9ef320de40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2a8a05e09b214f59ba59ba68fd9ee1d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2af03014dcbe401d982d8015c8dc6ae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ba0de64ed58493690476cc74ce592d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c5877d6058e4115909b39fa505c1103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d04fc06b05848f6a9277926d63ed914": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_589672d6f57a411ba6f6ff962f9baa3b",
      "max": 23950,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_06570834c303415087c2597b9cde8a44",
      "value": 23950
     }
    },
    "2d264d9324f74f28b6ea22e63a868547": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e2cf8ae460945a2a0515048f79d1be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e92a845b4b143928601d05556e9a810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c64fdcfd7670412d8b808d006064fc34",
      "placeholder": "​",
      "style": "IPY_MODEL_4db987d6b3c04480b4c67dd181a204ff",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "2ecf1c48ebe14115b3557c2e9c171393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f25145e61ef4199abb222421e9847be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fb274abb217453faa872a941bbae7ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_039baa19dd5e4d37bd55e7834cdfa918",
       "IPY_MODEL_098799cafe6946868f16b9efea24a4be",
       "IPY_MODEL_a42d73e3a5b846539b559e9eac4eed59"
      ],
      "layout": "IPY_MODEL_2c5877d6058e4115909b39fa505c1103"
     }
    },
    "309433f0d7624c82bf27dcf53fd62ff0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fae4fdf1ed16413da5fa8799c3400109",
      "placeholder": "​",
      "style": "IPY_MODEL_bca2027352264e9e8b1ed2c03298f8df",
      "value": "Token is valid (permission: write)."
     }
    },
    "310767bbac2f4013958eb58f9087888d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e203a73c9d104ba3ad6a960e72cfd1f0",
      "placeholder": "​",
      "style": "IPY_MODEL_ddc94aa086624462b52041b1c58f46e5",
      "value": " 125/125 [00:00&lt;00:00, 6.24kB/s]"
     }
    },
    "32d830682a0a4483aaf28f3497e5f396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "337b437ee9c44b1ab74e68be83d296ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e80b3a64794a6dab7662c67014d687": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35614e6e6658459cb05b5049cd4d7ea4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "359e4173e33d4852975547da1e6e52ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37070a9957144f1698ab50a16b1a57b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38b5f9df382d40d08b0a1fd8e4e0e2f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39c77122816346a486408c0e0da46224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bf6912033c94fb4978802df10767389": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_014dae3f0fb74991b8706aad71b13afe",
      "placeholder": "​",
      "style": "IPY_MODEL_14d2f5b768bc4743ba511cde06022849",
      "value": " 111/111 [00:00&lt;00:00, 7.00kB/s]"
     }
    },
    "3df04fc7d4fc4ee691633c51f6c4bd10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3eefb9f30b954db8827c7de68df00603": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f3a58df64d244a2a200e2eeec15e156": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40457dd138e44cb1857d3de6c092c190": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_afddee170cc54a3793a2e0a291e59f15",
       "IPY_MODEL_f63431b5d2924a108cc54ff3e8976764",
       "IPY_MODEL_d9f408602c3a40dc990c473231481eec"
      ],
      "layout": "IPY_MODEL_27154fa201d34accbd659296fbc399fd"
     }
    },
    "4058b8f2614342fb973d5cb1735524a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "40b2d8f33cc340b7ad445a7f8b6dd5d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ecc156af7ff64589a0786643608a7327",
       "IPY_MODEL_ae996647ef8a449a8a580faa483069d8",
       "IPY_MODEL_57857c6db770497a945d17aa98a03a5c"
      ],
      "layout": "IPY_MODEL_921088aa61b5476f91729f7b0804fe67"
     }
    },
    "40fe45ec217d4812b1598c4de7d126ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41b248654ced483d93fea011e68a7026": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44e6069bcf8e4b0f87740fbcfadf28e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7dd2154821247cdb5ec48ecd2bfea13",
       "IPY_MODEL_0e49a066641548f1a0d2fbea79c6c7bd",
       "IPY_MODEL_97ea4b9284d9441ca0e5f411d31d292c"
      ],
      "layout": "IPY_MODEL_d44b41118afc4dac8ae2c6bb410f3af0"
     }
    },
    "4556d34630b1447ebb4f01f07a17fa84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be195393a8f54b4fabd2d1c1380e9b33",
      "max": 437955512,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ec41d6f541448c59cc0a6d82d3470ff",
      "value": 437955512
     }
    },
    "455e444ec7db4f3aba862877ea9f5230": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "487ba87c026548b7a429295f4ab6286c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_260ae267b3844c0482a042ae5df4229e",
      "max": 493443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_126d60d1337a4eb09ebe0af747f08b53",
      "value": 493443
     }
    },
    "4982c389e9414c41a5064eba5fcd78fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49e25c1650f9436cbf477058cb14e976": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c34085d295bd4b80b681e1435189bfad",
      "max": 777,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a5f789bc9fd4a31867fd4f36407ec5e",
      "value": 777
     }
    },
    "49f14f6d0f5a47238edbfe844e5e8e20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a2156615c1940dd960d43d04053d69a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62728dab6b714585b8356688ee4b991e",
       "IPY_MODEL_1637358258d74d78a5d941e9b37e1bcb",
       "IPY_MODEL_76b74cacec4c429b9443ba5215957ecc"
      ],
      "layout": "IPY_MODEL_c7b9e97aeaf64365a4cdff98986da868"
     }
    },
    "4a4961aa392f498394da79cbcfbbcd2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "4a6779b4a70e4174a39aaa2dc907962e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_7a0563f267db42a49de16bc73c5c3b36",
      "placeholder": "​",
      "style": "IPY_MODEL_0b7077483d7743968ebb3cf287dd1129",
      "value": ""
     }
    },
    "4b795aa1d7e5485c915473cf3321b156": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b872e76aac648378de282d75bb7d2bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c8f7a2796ff4bce93dc032a70bed2a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4db987d6b3c04480b4c67dd181a204ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4dd6fe440be54d8c9713c182fb2fd4ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e3d9cf4a24a43068a5e79859617cb41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9833674bbca746ce96ea9aca234fe39c",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69bd6aaa455743e2baf8c7083a3db491",
      "value": 3
     }
    },
    "4f615a6cabbc4f2d8f42ff654b5a5892": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_73b62f2324f648809c39bca3f37cc249",
       "IPY_MODEL_798aa8c60dbe41228cd4fdf4825aaeba",
       "IPY_MODEL_f6059510efa24f53878f755f04a57989"
      ],
      "layout": "IPY_MODEL_8d7f4fbb31964e11915da70295373dff"
     }
    },
    "52ee31a628804848b75fd56eda2073b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_621bb238a043436a9ddb9f359ff449b4",
      "placeholder": "​",
      "style": "IPY_MODEL_5e66148cf597433f9fc6326e49d2d1a5",
      "value": "config.json: 100%"
     }
    },
    "54b6218ec29a497f8901447435316b17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5510ab6d693b4648839f08d27be7993c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "557b502851fb41359bd9c03bc8a475f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_455e444ec7db4f3aba862877ea9f5230",
      "placeholder": "​",
      "style": "IPY_MODEL_769a7dc07a3a4dd4a6944666170a3da6",
      "value": "1_Pooling/config.json: 100%"
     }
    },
    "56d789f043bd4883a9669a32786bc07c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_efcd9023c8df45b6a37fa63a04a12869",
       "IPY_MODEL_a718e78f7a9a4627b0fd392c5d0b5dd6",
       "IPY_MODEL_b4cccc03e3084129a1c35e296e5d5e42"
      ],
      "layout": "IPY_MODEL_256aaf64205b4dd49d599e3837374868"
     }
    },
    "56f55d4ed350419188ae425c946d1380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5774d2fbeef24448b8b184660ca1abc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57857c6db770497a945d17aa98a03a5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a588323072e49aba210a2363f622915",
      "placeholder": "​",
      "style": "IPY_MODEL_40fe45ec217d4812b1598c4de7d126ce",
      "value": " 437/437 [00:00&lt;00:00, 32.9kB/s]"
     }
    },
    "57b0bc61c7d0493ba02f8dd1ec704a98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "589672d6f57a411ba6f6ff962f9baa3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a588323072e49aba210a2363f622915": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b995196921b46dea0248381f0ac15c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d28d8bb72b024a7e8b831d0cc0452b72",
      "max": 673,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_77ae9641a2c64853955dd4dc64d35ce9",
      "value": 673
     }
    },
    "5c063634eed9427f8dbec2ebf57a9525": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c8cf38fc40f4226b13ec131449bbd58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e4fa56e3b8d449da947dc977aa6bdfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ebff4f92ba9437fb66bc7efb9023e5f",
      "placeholder": "​",
      "style": "IPY_MODEL_1006500f61b8441ead6477cc222bd7a0",
      "value": "README.md: 100%"
     }
    },
    "5e66148cf597433f9fc6326e49d2d1a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e98694132914385ac7106739ff9b95e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ebff4f92ba9437fb66bc7efb9023e5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eda0b7f4eaa4ffc8fcc1c888b1a33b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6049a806c13e4b45b73b781b4c430333": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60a3af184bba403ab6e4174a293bcad4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6153551477944cfdb82a3c6ae05edab8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d13b59997244de8a5f1e0f2b8d7165d",
      "placeholder": "​",
      "style": "IPY_MODEL_2e2cf8ae460945a2a0515048f79d1be6",
      "value": " 3/3 [02:10&lt;00:00, 42.37s/it]"
     }
    },
    "621bb238a043436a9ddb9f359ff449b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62728dab6b714585b8356688ee4b991e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6c50f75218348eca0151ac7025c86ff",
      "placeholder": "​",
      "style": "IPY_MODEL_5eda0b7f4eaa4ffc8fcc1c888b1a33b3",
      "value": "model-00001-of-00003.safetensors: 100%"
     }
    },
    "657b31ef34264a35addf79ed9264738c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6596fb8e189a4e4883326ed0fbe07122": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "662fbef77e5d4969b44581365bf4e7dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "672656da4b2645ce91e8961a32cb06d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67ec7ccc01ba4add869eab245a048151": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "689f59894fbe455c9a9b7c0cc4bbf5b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68e3c8ad5ef84be1954aeef5a3ccabdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69a59700064c4fabacdd84ccb0265277": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c8f7a2796ff4bce93dc032a70bed2a5",
      "max": 4999819232,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad1ff6e334d9428b887bd8fc3cf3476f",
      "value": 4999819232
     }
    },
    "69bd6aaa455743e2baf8c7083a3db491": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a5f789bc9fd4a31867fd4f36407ec5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b6a2d6e0161402fa6ef5370b2abf708": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38b5f9df382d40d08b0a1fd8e4e0e2f8",
      "placeholder": "​",
      "style": "IPY_MODEL_5e98694132914385ac7106739ff9b95e",
      "value": " 438M/438M [00:02&lt;00:00, 209MB/s]"
     }
    },
    "6f250ac018014937887bd44bd92bc0ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7069f1417f0340c0900c4141c45f9ae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89cf625100224195bae80e5df33f7475",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_070f1627c1cc44d9822055eabac2b0fc",
      "value": 190
     }
    },
    "7332efac67864f8ab1c49a62b8eb64a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73b62f2324f648809c39bca3f37cc249": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2f36845cb59436aa439e0198d9e73dd",
      "placeholder": "​",
      "style": "IPY_MODEL_662fbef77e5d4969b44581365bf4e7dc",
      "value": "tokenizer.json: 100%"
     }
    },
    "7513459b5c0343eaba3847e8fafa34ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_52ee31a628804848b75fd56eda2073b2",
       "IPY_MODEL_49e25c1650f9436cbf477058cb14e976",
       "IPY_MODEL_8e09385669864b08ad6e51a5c3b7d944"
      ],
      "layout": "IPY_MODEL_c5a730530869485588eb8ac17e919fc4"
     }
    },
    "754a656cf3004afbb41a19954c9acfdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "769a7dc07a3a4dd4a6944666170a3da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76b74cacec4c429b9443ba5215957ecc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_337b437ee9c44b1ab74e68be83d296ec",
      "placeholder": "​",
      "style": "IPY_MODEL_4dd6fe440be54d8c9713c182fb2fd4ec",
      "value": " 4.94G/4.94G [00:43&lt;00:00, 199MB/s]"
     }
    },
    "770bd5e827264200b502db89df5b3876": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77ae9641a2c64853955dd4dc64d35ce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77b05e6f2ada47dabeeea2bbe813e73c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "798aa8c60dbe41228cd4fdf4825aaeba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_154b644041ae4347ba8fd4b9fd957e4b",
      "max": 711396,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a4ed4d92a2d45afaa85ca9ef320de40",
      "value": 711396
     }
    },
    "7a0563f267db42a49de16bc73c5c3b36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ec41d6f541448c59cc0a6d82d3470ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "837ccf036eab40e2abcbd99a45c87280": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83b787846efe4aabbb51d51c4eeb7653": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e4fa56e3b8d449da947dc977aa6bdfd",
       "IPY_MODEL_12f4cd0562a54fe49a6c823f12e681fb",
       "IPY_MODEL_27dce5ad5a9d41d7922066aaaf62b111"
      ],
      "layout": "IPY_MODEL_23d3e15868fa49dbb9ec0572f8d874fc"
     }
    },
    "8415d5c8c543426c9359a5ff5d5b800c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "848122d09d1b4c2ea702fd1ca2313e6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34e80b3a64794a6dab7662c67014d687",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a34fc4c645ba40699d1292c4cc472b36",
      "value": 52
     }
    },
    "85d03f11364d43ba8d65b3c44b4eaf6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86dbb9b199a84170b0383a68e207afa4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89cf625100224195bae80e5df33f7475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a6cf86439624449a412b3753a71f923": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0bb81dc34e24e02b3519e49fd93f59a",
       "IPY_MODEL_dae6f7e834b04fd5ba145e57263afe31",
       "IPY_MODEL_3bf6912033c94fb4978802df10767389"
      ],
      "layout": "IPY_MODEL_15c03d5abd634162b5b3ffa8b4a9eb13"
     }
    },
    "8bf09f7f9ffe4ca0b1845981bbc1effa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a8a05e09b214f59ba59ba68fd9ee1d4",
      "max": 1795331,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_77b05e6f2ada47dabeeea2bbe813e73c",
      "value": 1795331
     }
    },
    "8d13b59997244de8a5f1e0f2b8d7165d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d2cffb5145d49fc8eb9432a29b5629b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a23ab71bfb6445ce9e6b0e4e44af5b28",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b978a9f90af04bfeb0a0a50ad410810a",
      "value": 231508
     }
    },
    "8d7f4fbb31964e11915da70295373dff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8df884e1221d46c9b8f1ed01f40fdf81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e09385669864b08ad6e51a5c3b7d944": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d845619732b34799af0050c40625d3b2",
      "placeholder": "​",
      "style": "IPY_MODEL_e304dafb486f41758a100aaab39abf97",
      "value": " 777/777 [00:00&lt;00:00, 58.8kB/s]"
     }
    },
    "8edaeac0ad7f4087b1cf9c01fc472628": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f9849528c2b4ca5b285d6d6e0acb668": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_309433f0d7624c82bf27dcf53fd62ff0",
       "IPY_MODEL_a42f0e123fa74477a40168ca2d388088",
       "IPY_MODEL_97c0d515ffbe42d887f01353910d419e",
       "IPY_MODEL_fb353f217c5e46b38ffd1de24b574a2a"
      ],
      "layout": "IPY_MODEL_cca0c9124b8342a9b6290141b4a2a327"
     }
    },
    "8fe70724cb3f4823acbe376e6f76c354": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "907693133d79418fbf04bfe4086997b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90c4e05273244e5e8d022a265d537df5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "921088aa61b5476f91729f7b0804fe67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92d8eb851c174cb3b51fdef1ef0e129e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b947ed3a63544093a1ddae8a904aa549",
      "placeholder": "​",
      "style": "IPY_MODEL_b9aba2c792f74b6ea0b8765b2b57a6e4",
      "value": "config.json: 100%"
     }
    },
    "93397eeca34c4c90a8f6a889905df4c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08a37e13d7424af697d78201fdf35a31",
      "placeholder": "​",
      "style": "IPY_MODEL_39c77122816346a486408c0e0da46224",
      "value": "tokenizer.model: 100%"
     }
    },
    "94591530bf6443c1a229f212ce43a3db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94db57d0032a46619756d44aa96120cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95385444add44ff2b97d07f3bb233aa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2bbe3e7856546de9ec51658cddfe678",
       "IPY_MODEL_4556d34630b1447ebb4f01f07a17fa84",
       "IPY_MODEL_6b6a2d6e0161402fa6ef5370b2abf708"
      ],
      "layout": "IPY_MODEL_67ec7ccc01ba4add869eab245a048151"
     }
    },
    "95be03e99adb4775b0ad37e5ffbb1771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5cdea30d7664b8eb0670d04e1096533",
       "IPY_MODEL_8bf09f7f9ffe4ca0b1845981bbc1effa",
       "IPY_MODEL_96f024277f6049fd9415e08bcd30047f"
      ],
      "layout": "IPY_MODEL_ba7ddb6bc63b48f0bd5aed22bc1add56"
     }
    },
    "96f024277f6049fd9415e08bcd30047f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f3a58df64d244a2a200e2eeec15e156",
      "placeholder": "​",
      "style": "IPY_MODEL_d28cc1dd1c7c4dae8a53672929bcba8f",
      "value": " 1.80M/1.80M [00:00&lt;00:00, 8.99MB/s]"
     }
    },
    "97ab70786dc54d5d86f6e17041677c8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97c0d515ffbe42d887f01353910d419e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_689f59894fbe455c9a9b7c0cc4bbf5b4",
      "placeholder": "​",
      "style": "IPY_MODEL_3eefb9f30b954db8827c7de68df00603",
      "value": "Your token has been saved to /root/.cache/huggingface/token"
     }
    },
    "97ea4b9284d9441ca0e5f411d31d292c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8edaeac0ad7f4087b1cf9c01fc472628",
      "placeholder": "​",
      "style": "IPY_MODEL_14d525461453413c85be19b96734155d",
      "value": " 4.54G/4.54G [00:35&lt;00:00, 174MB/s]"
     }
    },
    "9804e4b701fe47d082ca764a0c5a434d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9833674bbca746ce96ea9aca234fe39c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98a10aa5b9404fa4b21194a8f7b9c3dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_2ecf1c48ebe14115b3557c2e9c171393",
      "style": "IPY_MODEL_359e4173e33d4852975547da1e6e52ed",
      "value": true
     }
    },
    "992d2ea80c8747ea87294f75d1b38908": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9acc0d08c0cb4f99943702e4b81ca069": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9de7bc73afe6426eade5f755979b8a1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0ad9d0c217c43e5a1de6f5087526795": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_041981bb563242aa8961ffb74be9409f",
      "placeholder": "​",
      "style": "IPY_MODEL_2af03014dcbe401d982d8015c8dc6ae9",
      "value": " 1.46k/1.46k [00:00&lt;00:00, 94.8kB/s]"
     }
    },
    "a1bb836c724b4d328445408a10220eaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a23ab71bfb6445ce9e6b0e4e44af5b28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a34fc4c645ba40699d1292c4cc472b36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a42d73e3a5b846539b559e9eac4eed59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_992d2ea80c8747ea87294f75d1b38908",
      "placeholder": "​",
      "style": "IPY_MODEL_140848504fdf478ea03a400a72dd4633",
      "value": " 366/366 [00:00&lt;00:00, 24.4kB/s]"
     }
    },
    "a42f0e123fa74477a40168ca2d388088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37070a9957144f1698ab50a16b1a57b7",
      "placeholder": "​",
      "style": "IPY_MODEL_2f25145e61ef4199abb222421e9847be",
      "value": "Your token has been saved in your configured git credential helpers (store)."
     }
    },
    "a4f299a27c604502a40b96e06724b578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5cdea30d7664b8eb0670d04e1096533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97ab70786dc54d5d86f6e17041677c8a",
      "placeholder": "​",
      "style": "IPY_MODEL_fc76b21f47dc41ef9638f69e4cae4cae",
      "value": "tokenizer.json: 100%"
     }
    },
    "a68dde57c4d045d08214e7bd0b935d02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a711bc60ebba4b0c8ceb0ef9effb276b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a718e78f7a9a4627b0fd392c5d0b5dd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f250ac018014937887bd44bd92bc0ce",
      "max": 349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f39b1453664040dc9b0db6725e6bd011",
      "value": 349
     }
    },
    "a8a6bd58d59147208502ab098362a169": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff09cb6cd8c4411abd6bf129f74af87a",
       "IPY_MODEL_848122d09d1b4c2ea702fd1ca2313e6b",
       "IPY_MODEL_b809b30ff9ed4b9ab6e7eda443592082"
      ],
      "layout": "IPY_MODEL_907693133d79418fbf04bfe4086997b8"
     }
    },
    "aaf6bdbb980c41c58ee686fec133e867": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab695022a8294b0699e980d41f6d93a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5510ab6d693b4648839f08d27be7993c",
      "placeholder": "​",
      "style": "IPY_MODEL_c5ff8d9621ce444087c485afea4451a6",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "abbd5be4eef14b4895e41299aa7a2a1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "abfcf06eb5154155a1aa01917670de5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9967c990de041c48eb9e8ebc07cb18d",
       "IPY_MODEL_4e3d9cf4a24a43068a5e79859617cb41",
       "IPY_MODEL_6153551477944cfdb82a3c6ae05edab8"
      ],
      "layout": "IPY_MODEL_86dbb9b199a84170b0383a68e207afa4"
     }
    },
    "ac24664f2d094722ae17dff6fd2996c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac2f096a7c5a4963bfe69c22f93d5a80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad1ff6e334d9428b887bd8fc3cf3476f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad3a0763ac6247b1a7791b59935553db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f987c7f4751c4a02b9d81a85cff45b08",
      "placeholder": "​",
      "style": "IPY_MODEL_abbd5be4eef14b4895e41299aa7a2a1e",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "ad70ffd86b124e8fbd09cf683d6db63a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3e554efc838435fbe783bec93ce4260",
       "IPY_MODEL_2d04fc06b05848f6a9277926d63ed914",
       "IPY_MODEL_d530566b58004760b673061f73ff46c6"
      ],
      "layout": "IPY_MODEL_0bfbc0e31eb94591b07232be8e8602d6"
     }
    },
    "ae851e234d7347f1b75e1964e7eb309f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d264d9324f74f28b6ea22e63a868547",
      "placeholder": "​",
      "style": "IPY_MODEL_672656da4b2645ce91e8961a32cb06d7",
      "value": " 673/673 [00:00&lt;00:00, 39.0kB/s]"
     }
    },
    "ae996647ef8a449a8a580faa483069d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5083d24a286481bb204c973de854097",
      "max": 437,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4f299a27c604502a40b96e06724b578",
      "value": 437
     }
    },
    "af4c7bf2a50f489b95f2d97905e005fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af859f8151e34c6c994421402c260ecb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afddee170cc54a3793a2e0a291e59f15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffe031b40f3e486c92df3a9002bff568",
      "placeholder": "​",
      "style": "IPY_MODEL_68e3c8ad5ef84be1954aeef5a3ccabdd",
      "value": "config_sentence_transformers.json: 100%"
     }
    },
    "b1f64c7d82fe4b42ac4783983e0a0e66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b20f5567d6984df595f903c0b7948493": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b289f501cf76467f86416e9a1ba8e053": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4cccc03e3084129a1c35e296e5d5e42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe6a7dd271424aafae9b2e8ac44579da",
      "placeholder": "​",
      "style": "IPY_MODEL_3df04fc7d4fc4ee691633c51f6c4bd10",
      "value": " 349/349 [00:00&lt;00:00, 22.9kB/s]"
     }
    },
    "b580e5dea82d4865a53a89b6ac125879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad3a0763ac6247b1a7791b59935553db",
       "IPY_MODEL_0590c421aa0c4e4d9c5e761d1ef8944c",
       "IPY_MODEL_1fabc05d3bba4649bd3309befcf1848e"
      ],
      "layout": "IPY_MODEL_8fe70724cb3f4823acbe376e6f76c354"
     }
    },
    "b709f557297749bcbb349dedbf696d40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93397eeca34c4c90a8f6a889905df4c7",
       "IPY_MODEL_487ba87c026548b7a429295f4ab6286c",
       "IPY_MODEL_185bc2a093ed44b986c8088f4253fdc3"
      ],
      "layout": "IPY_MODEL_754a656cf3004afbb41a19954c9acfdf"
     }
    },
    "b809b30ff9ed4b9ab6e7eda443592082": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9acc0d08c0cb4f99943702e4b81ca069",
      "placeholder": "​",
      "style": "IPY_MODEL_49f14f6d0f5a47238edbfe844e5e8e20",
      "value": " 52.0/52.0 [00:00&lt;00:00, 3.78kB/s]"
     }
    },
    "b947ed3a63544093a1ddae8a904aa549": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b978a9f90af04bfeb0a0a50ad410810a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b9aba2c792f74b6ea0b8765b2b57a6e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9b2848fad8449b2813f88dafe47d2c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba7ddb6bc63b48f0bd5aed22bc1add56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba87006419ce4eb897586b77118d5285": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0dc80d0201a04d4a8b466c1fee29761c",
      "placeholder": "​",
      "style": "IPY_MODEL_4b795aa1d7e5485c915473cf3321b156",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "bca2027352264e9e8b1ed2c03298f8df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be195393a8f54b4fabd2d1c1380e9b33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be8114716e644c6fbed386e36ad79174": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab695022a8294b0699e980d41f6d93a8",
       "IPY_MODEL_1dbb36b434104e4d8723583936eae6a3",
       "IPY_MODEL_310767bbac2f4013958eb58f9087888d"
      ],
      "layout": "IPY_MODEL_94591530bf6443c1a229f212ce43a3db"
     }
    },
    "c012be6d6be94491a8cfa51e2ba522d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4982c389e9414c41a5064eba5fcd78fc",
      "placeholder": "​",
      "style": "IPY_MODEL_13424936322a47d59ec97e2b5494188e",
      "value": "vocab.txt: 100%"
     }
    },
    "c0bb81dc34e24e02b3519e49fd93f59a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2012f7f9148d4c698bc91c56315fb034",
      "placeholder": "​",
      "style": "IPY_MODEL_004bef965189494a992c222b71ce3a5e",
      "value": "generation_config.json: 100%"
     }
    },
    "c15d09de6503496d82d7a039030e7be8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2bbe3e7856546de9ec51658cddfe678": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16f06250af4c400d9c317cbf15b1c8a9",
      "placeholder": "​",
      "style": "IPY_MODEL_56f55d4ed350419188ae425c946d1380",
      "value": "model.safetensors: 100%"
     }
    },
    "c34085d295bd4b80b681e1435189bfad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c42683cddb674c82bf08babfb70f2f74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_557b502851fb41359bd9c03bc8a475f0",
       "IPY_MODEL_7069f1417f0340c0900c4141c45f9ae2",
       "IPY_MODEL_dfa3d17e6b034fbb91d1860871c86d61"
      ],
      "layout": "IPY_MODEL_af4c7bf2a50f489b95f2d97905e005fc"
     }
    },
    "c5a730530869485588eb8ac17e919fc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5ff8d9621ce444087c485afea4451a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c64fdcfd7670412d8b808d006064fc34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6b2c6ea22b4407bae5f192b4db5f064": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7b9e97aeaf64365a4cdff98986da868": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c83aa8325dee4754a7eb62711f54b951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03319426e6ec4474a61a44f84f390540",
      "placeholder": "​",
      "style": "IPY_MODEL_046f65796b9e4c18b9da763511347584",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "c8449737a32d4440a4a5a0f919bcc10d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c063634eed9427f8dbec2ebf57a9525",
      "placeholder": "​",
      "style": "IPY_MODEL_c6b2c6ea22b4407bae5f192b4db5f064",
      "value": " 232k/232k [00:00&lt;00:00, 3.51MB/s]"
     }
    },
    "c9278070680f49cd91aaed86b92b3eab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c012be6d6be94491a8cfa51e2ba522d6",
       "IPY_MODEL_8d2cffb5145d49fc8eb9432a29b5629b",
       "IPY_MODEL_c8449737a32d4440a4a5a0f919bcc10d"
      ],
      "layout": "IPY_MODEL_6596fb8e189a4e4883326ed0fbe07122"
     }
    },
    "c9967c990de041c48eb9e8ebc07cb18d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cea3abcefb4043cdabb4c8c767d3f4af",
      "placeholder": "​",
      "style": "IPY_MODEL_b9b2848fad8449b2813f88dafe47d2c0",
      "value": "Downloading shards: 100%"
     }
    },
    "cab5a8b0415d449c86743c1c312aa27a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba87006419ce4eb897586b77118d5285",
       "IPY_MODEL_ddb47d82044c434e9f5343f5becfe43e",
       "IPY_MODEL_a0ad9d0c217c43e5a1de6f5087526795"
      ],
      "layout": "IPY_MODEL_dd6329a7433a467c85e6683b52777079"
     }
    },
    "cca0c9124b8342a9b6290141b4a2a327": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "cea3abcefb4043cdabb4c8c767d3f4af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d28cc1dd1c7c4dae8a53672929bcba8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d28d8bb72b024a7e8b831d0cc0452b72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2f36845cb59436aa439e0198d9e73dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3e554efc838435fbe783bec93ce4260": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_657b31ef34264a35addf79ed9264738c",
      "placeholder": "​",
      "style": "IPY_MODEL_246fe7b73a4c4077990270cea535631b",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "d44b41118afc4dac8ae2c6bb410f3af0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d530566b58004760b673061f73ff46c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af859f8151e34c6c994421402c260ecb",
      "placeholder": "​",
      "style": "IPY_MODEL_1e0c27089c734f68808fc64c3db5b571",
      "value": " 23.9k/23.9k [00:00&lt;00:00, 1.33MB/s]"
     }
    },
    "d6c50f75218348eca0151ac7025c86ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d845619732b34799af0050c40625d3b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d88188177d4c46818e5c027d8d92e3e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9f408602c3a40dc990c473231481eec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17e8bbe1431745ecbe2a0026297ced19",
      "placeholder": "​",
      "style": "IPY_MODEL_6049a806c13e4b45b73b781b4c430333",
      "value": " 124/124 [00:00&lt;00:00, 7.11kB/s]"
     }
    },
    "dae6f7e834b04fd5ba145e57263afe31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efaec750d97449a38a8f2374c003b604",
      "max": 111,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aaf6bdbb980c41c58ee686fec133e867",
      "value": 111
     }
    },
    "dd6329a7433a467c85e6683b52777079": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddb47d82044c434e9f5343f5becfe43e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9de7bc73afe6426eade5f755979b8a1d",
      "max": 1462,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13ac6b0b2098474ba90169504ec6742d",
      "value": 1462
     }
    },
    "ddc94aa086624462b52041b1c58f46e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dfa3d17e6b034fbb91d1860871c86d61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85d03f11364d43ba8d65b3c44b4eaf6f",
      "placeholder": "​",
      "style": "IPY_MODEL_9804e4b701fe47d082ca764a0c5a434d",
      "value": " 190/190 [00:00&lt;00:00, 8.51kB/s]"
     }
    },
    "e052e9457e7141ce87bdddf26d3c683d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1466f2ca611478bbbfeca334b4fe60f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e203a73c9d104ba3ad6a960e72cfd1f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e304dafb486f41758a100aaab39abf97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5083d24a286481bb204c973de854097": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea6a9fefa4b544aca27240e02b49ba3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb0a994cd2094d318ba4ed91d5732a17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecc156af7ff64589a0786643608a7327": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90c4e05273244e5e8d022a265d537df5",
      "placeholder": "​",
      "style": "IPY_MODEL_ac24664f2d094722ae17dff6fd2996c4",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "efaec750d97449a38a8f2374c003b604": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efcd9023c8df45b6a37fa63a04a12869": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8415d5c8c543426c9359a5ff5d5b800c",
      "placeholder": "​",
      "style": "IPY_MODEL_eb0a994cd2094d318ba4ed91d5732a17",
      "value": "modules.json: 100%"
     }
    },
    "f2d1b4b648054be791a27f97cdaf82d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f39b1453664040dc9b0db6725e6bd011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6059510efa24f53878f755f04a57989": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5774d2fbeef24448b8b184660ca1abc4",
      "placeholder": "​",
      "style": "IPY_MODEL_e052e9457e7141ce87bdddf26d3c683d",
      "value": " 711k/711k [00:00&lt;00:00, 5.39MB/s]"
     }
    },
    "f619aae3ac46428394abe62eb4f1b2a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94db57d0032a46619756d44aa96120cb",
      "placeholder": "​",
      "style": "IPY_MODEL_837ccf036eab40e2abcbd99a45c87280",
      "value": "Connecting..."
     }
    },
    "f63431b5d2924a108cc54ff3e8976764": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea6a9fefa4b544aca27240e02b49ba3d",
      "max": 124,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09084a8710d147e6afd384276434ba45",
      "value": 124
     }
    },
    "f7dd2154821247cdb5ec48ecd2bfea13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fb584e76cd24fc892435c28f5554bce",
      "placeholder": "​",
      "style": "IPY_MODEL_ac2f096a7c5a4963bfe69c22f93d5a80",
      "value": "model-00003-of-00003.safetensors: 100%"
     }
    },
    "f987c7f4751c4a02b9d81a85cff45b08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fae4fdf1ed16413da5fa8799c3400109": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb353f217c5e46b38ffd1de24b574a2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d88188177d4c46818e5c027d8d92e3e9",
      "placeholder": "​",
      "style": "IPY_MODEL_f2d1b4b648054be791a27f97cdaf82d7",
      "value": "Login successful"
     }
    },
    "fbb2f6a4deaf4daa8379c3c6c3d3bace": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc76b21f47dc41ef9638f69e4cae4cae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdc6995a9ad64176aeafeb046a0bbb6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe6a7dd271424aafae9b2e8ac44579da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff09cb6cd8c4411abd6bf129f74af87a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_063f69f761ee412fb562f2bb55a97221",
      "placeholder": "​",
      "style": "IPY_MODEL_b1f64c7d82fe4b42ac4783983e0a0e66",
      "value": "sentence_bert_config.json: 100%"
     }
    },
    "ffe031b40f3e486c92df3a9002bff568": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
